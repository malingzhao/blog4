<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/blog4/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/blog4/lib/pace/pace-theme-center-atom.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/blog4/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/blog4/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/blog4/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/blog4/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/blog4/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/blog4/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/blog4/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="面试,">










<meta name="description" content="了解自己的技术水平===================================================================（1）技术广度技术广度 为什么要考察一个人的技术广度呢假设 团队有一个系统 Dubbo作为服务框架 MQ（RocketMQ） kafka，SpringCloud缓存Redis 搜索（ElasticSearch） 在互联网行业 ，非互联网的公司，本省">
<meta name="keywords" content="面试">
<meta property="og:type" content="article">
<meta property="og:title" content="面试突击">
<meta property="og:url" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/index.html">
<meta property="og:site_name" content="我的个人博客">
<meta property="og:description" content="了解自己的技术水平===================================================================（1）技术广度技术广度 为什么要考察一个人的技术广度呢假设 团队有一个系统 Dubbo作为服务框架 MQ（RocketMQ） kafka，SpringCloud缓存Redis 搜索（ElasticSearch） 在互联网行业 ，非互联网的公司，本省">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/1571566294313.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/1571582674788.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/1571660432991.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/1571660498549.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/1571660734359.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/1571661593946.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/1571661715001.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/1571661776518.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/1571661932961.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/1571662111632.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/1571662256516.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/1571662468695.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/1571662565958.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/images/hystrix-thread-pool-queue.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/1571662862056.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/1571663234245.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/images/hystrix-request-cache.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/1571663532026.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/images/220px-Internet_dog.jpg">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/1571663708231.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/1571663735460.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/1571663912457.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/database-shard-method-1.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/database-shard-method-2.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/es-cluster-0.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/es-index-type-mapping-document-field.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/es-cluster.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/es-search-process.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/es-write.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/es-write-detail.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/mq-1.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/mq-2.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/mq-3.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/mq-4.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/mq-6.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/high-concurrency-system-design.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/mq-7.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/mq-8.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/kafka-before.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/kafka-after.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/mq-10.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/mq-11.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/rabbitmq-order-01.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/kafka-order-01.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/rabbitmq-order-02.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/images/kafka-order-02.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/D:/%25E5%25B0%259A%25E7%25A1%2585%25E8%25B0%25B7%2520%2520java%2520EE/%25E9%259D%25A2%25E8%25AF%2595/Java-Interview-Advanced/docs/high-concurrency/images/rabbitmq-order-01.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/D:/%25E5%25B0%259A%25E7%25A1%2585%25E8%25B0%25B7%2520%2520java%2520EE/%25E9%259D%25A2%25E8%25AF%2595/Java-Interview-Advanced/docs/high-concurrency/images/kafka-order-01.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/D:/%25E5%25B0%259A%25E7%25A1%2585%25E8%25B0%25B7%2520%2520java%2520EE/%25E9%259D%25A2%25E8%25AF%2595/Java-Interview-Advanced/docs/high-concurrency/images/rabbitmq-order-02.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/1571665034985.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/mysql-master-slave.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/redis-caching-avalanche.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/redis-caching-avalanche-solution.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/redis-caching-penetration.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/zookeeper-distributed-lock.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/zookeeper-centralized-storage.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/redis-gossip.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/images/hash.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/consistent-hashing-algorithm.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/hash-slot.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/redis-junior-inconsistent.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/redis-master-slave.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/redis-master-slave-replication.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/redis-master-slave-replication-detail.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/async-replication-data-lose-case.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/redis-cluster-split-brain.png">
<meta property="og:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/redis-single-thread-model.png">
<meta property="og:updated_time" content="2019-11-05T10:52:08.144Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="面试突击">
<meta name="twitter:description" content="了解自己的技术水平===================================================================（1）技术广度技术广度 为什么要考察一个人的技术广度呢假设 团队有一个系统 Dubbo作为服务框架 MQ（RocketMQ） kafka，SpringCloud缓存Redis 搜索（ElasticSearch） 在互联网行业 ，非互联网的公司，本省">
<meta name="twitter:image" content="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/1571566294313.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/blog4/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/">





  <title>面试突击 | 我的个人博客</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
<a href="https://github.com/malingzhao" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewbox="0 0 250 250" style="fill:#70B7FD; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/blog4/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">我的个人博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description"></h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/blog4/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/blog4/about/Introduce.html" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/blog4/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/blog4/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/blog4/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-schedule">
          <a href="/blog4/schedule.html" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-calendar"></i> <br>
            
            日程表
          </a>
        </li>
      
        
        <li class="menu-item menu-item-sitemap">
          <a href="/blog4/sitemap.html" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br>
            
            站点地图
          </a>
        </li>
      
        
        <li class="menu-item menu-item-commonweal">
          <a href="/blog4/404.html" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br>
            
            公益404
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://malingzhao.github.io/blog4/blog4/2019/10/20/javaInterview2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="MaLingZhao">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/blog4/images/dongman.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="我的个人博客">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">面试突击</h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-20T18:21:28+08:00">
                2019-10-20
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/blog4/categories/javaEE/" itemprop="url" rel="index">
                    <span itemprop="name">javaEE</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/blog4/2019/10/20/javaInterview2/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/blog4/2019/10/20/javaInterview2/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  71.9k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  258
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="了解自己的技术水平"><a href="#了解自己的技术水平" class="headerlink" title="了解自己的技术水平"></a>了解自己的技术水平</h1><p>===================================================================<br>（1）技术广度<br>技术广度 为什么要考察一个人的技术广度呢<br>假设 团队有一个系统 Dubbo作为服务框架 MQ（RocketMQ） kafka，SpringCloud<br>缓存Redis 搜索（ElasticSearch）</p>
<p>在互联网行业 ，非互联网的公司，本省是有主流的技术栈的</p>
<p>假设，业务发挥在那特别的额迅猛需要团队扩招5个人，跟猎头合作找一些合适的人出来</p>
<p>最最起码的你应该从那个角度考察候选人 职位的最低要求工作经验在3到5年有一定的社会工作经验的</p>
<p>技术广度进行考察</p>
<p>招过来一个有几年经验的人，这样就不用再去培养了</p>
<p>候选人的整个技术栈是比较陪我们团队的技术展的<br>从光度上吧各种技术都考察一下，尤其我们团队涉及到的技术</p>
<p>Dubbo你熟悉吗 之前你们公司也是 从服务的注册与发现他是怎么运行呢<br>你们当时的服务的注册中心用的什么技术跟dubbo搭配起来的</p>
<p>看你的简历上写了RocketMQ 先说说你们公司为什么用RocketMQ<br>集群架构 高可用是如何保证的rocketMQ核心的架构原理 工作原理<br>当时有没有考虑过发送到rocketMQ的消息会丢失 ？</p>
<p>缓存（Redis）整个集群怎么部署的 Redis的高可用 Redis为什么是单线程  高并发 聊聊ES, 你们的ES是如何优化的</p>
<p>到此为止，确定，然进来的话like就可以上手熟悉你们的架构，系统和代码，技术上不用特殊的培养，很快就可以上手干活，给予你们现有的架构，现有的技术栈，上手就可以开发各种业务功能模块</p>
<p>常见的技术方案涉及 常见的一些问题可以自己处理 常见的一些优化可以自己做<br>20k差不多</p>
<p>jvm数据库和高并发 必考</p>
<p>我们希望你对jvm的基本原理都有一定的理解没如果你们的团队出现了内存溢出GC的问题<br>希望你能独立的分析和解决</p>
<p>数据库 mysql 包括事务的问题常见的SQL</p>
<p>并发，java编程语言最基本的一个功能，并发本身有一定的深度和广度<br>写出高效率的并发程序有一定的难度</p>
<p>（2）  项目经验</p>
<p>你平常用的各项技术  如何对业务进行落地  架构优化 生产实践是怎么来做的</p>
<p>分库分表  简历用了springdata -jdbc首先跟我说说你们的系统有那些库哪些表对应的是哪些业务呢<br>新增的数据量有多少  单标百万级 千万级 你们是什么时候分表什么时候分的库 为什么<br>在没有分表之前 sql的性能大该如何 分表之后sql的性能大概如何<br>分库之前服务器上放多少GB的数据 ，一台服务器可以放所少数据？分库之后拆分到几台服务器上去？<br>每台服务器方所少GB的数据</p>
<p>很多同学出去面试学了很多的技术，学习了很多的技术无理论是视频金科城  培训课程 买了一些书<br>积累了很多的知识，Sharding_jdbc，分库分表的原理，常见的分库分表的技术方案，<br>旺旺是为了面试去准备的技术，从来没有在项目中实践过，从你的项目落地的各种细节是如何实现的</p>
<p>面试的时候，旺旺被面试官问项目的各个细节，然后直接就死了</p>
<p>（3）生产经验<br> 分布式 微服务 模块 你说你用网关 调研了哪几种技术，说说你们的的优缺点？<br> 最后你们是如何技术选型，你们系统的每天的访问呢量多高，你们的我那个管矿多高的GPS 网关是如何部署的 部署了几台机器  每台机器的饿配置如何 几个核 几个cpu</p>
<p>你的服务器增加了一个新的接口，你不能每次手动在网关里配置一些新的接口和服务的对应关系，网关的动态路由是怎么做的 每次上线服务或者断点额接口 跟你的网关动态路由是如何搭配起来的</p>
<p>线上机器 在生产环境下 访问压力下 平常的高峰期的CPU负载 如何<br>有没有考虑过网观点额扩容</p>
<p>有没有进行请求路由的性能如何  一般请求一个w网关的路由的开销量有多少</p>
<p>现在的话，假设说，弯管方式在线上部署有没有遇到过什么问题，比如并发问题，新能问题？如果要对你们生产环境的网关进行高并发高性能的优化  你们是怎么做的呢  如果要做 从哪些角度入手做<br>总结： 项目经验 + 生产经验 28k 30k 32k(5-8年)<br>希望您能带一个小组，当一个小小的team leader</p>
<p>肯定希望你能将整个</p>
<p>项目经验  技术在 项目中如何落地<br>带几个小弟，对那你负责的项目进行所有细节的把控 结合业务和项目的而细节考虑技术如何落地</p>
<p>生产经验：能够把控住项目部署之后的生产环境的情况对各种开发环境做出优化的手段<br>全面负责自己的项目</p>
<p>很多的大厂3到5年经验也回来考察你的项目经验</p>
<p>越是大厂越希望你的技术能力强能够独挡一面</p>
<p>（4）技术的深度</p>
<p>你有没有读过哪些开源项目的源码  你能说一下rocketMQ的源码<br>如果你精通技术的源码的话 为什么特别的有竞争力</p>
<p>技术深度 决定了技术的工地功底 你的声场环境随时肯可能会遇到异常<br>kafka ES Dubbo  RocketMQ 队列时可能会报错 RocketMQ异常无法写入消息<br>ES突然巨慢 一次查询需要10几秒的时间</p>
<p>必须需要哪些金共同源码的同学，现场根据异常去分析技术的源码，从源码级别定位问题的所在，然后解决问题</p>
<p>大厂，很可能考察你的技术的深度，如果你没有那个技术的深度，那么可能你没有太大的技术优势</p>
<p>（5）系统设计<br>简单了说，让你设计一个秒杀系统<br>设计一个12306的火车票购票系统支撑10亿用户买火车票<br>你会如何设计<br>设计一个微信的红包系统<br>越是大厂越是对你的要求高，独立的去负责一块东西<br>能够把技术落地的更加的合理</p>
<p>大厂，独立的设计一块系统 独立设计一个小的架构 </p>
<p>此时就会要求你有一定的独立的系统设计的能力30k,40k都会考察</p>
<p>30k,40k 50k更高薪资的 技术专家架构师<br>要求本来在你们公司负责一大块系统的加厚<br>生产经验 项目架构 技术广度 技术深度 系统架构 </p>
<p>都很丰富</p>
<p>发布过《《互联网java工程师面试突击（第一季）》》<br>spring springMVC Lucence Activity OA系统  财务系统  CRM系统 工厂管理<br>类似这样的一些东西</p>
<p>国内的主流技术栈</p>
<p>MQ 消息第十 消息重复 高可用的部署 原理 缓存  数据库和缓存双鞋如何保证一致性<br>分布式锁实现原理  分布式事务的常见方案  Dubbo SpringCloud</p>
<p>定位 面试突击第一季常见的主流的技术方案分析一下 扫盲 避免出去面试一问三不知 </p>
<p>数据库的而一些原理优化  jvm的原理优化 并发的原理和优化</p>
<p>已经帮助了数以千计的同学，不完全统计看过面试第一季的同学至少5000人以上，快速扫盲，积累很多的互联网主流的技术栈，很多人发感谢信</p>
<p>收到反馈，面试突击第一季，但是还是有很多的问题，项目经验，生产经验技术的深度</p>
<p>面试突击第一季 常见的计数原理 常见的技术方案</p>
<p>项目经验 分库分表  死磕项目经验</p>
<p>(1) 项目经验 分库分表  死磕项目经验<br>(2) 生产经验  Zuul网关在生产环如何优化 分布式锁会不会导致并发能力降低，如何优化<br>分布式事务会不会导致TPS降低，如何优化，服务注册中心如果发现过慢如何解决怎么部署的需要多少台机器 </p>
<p>（3）技术深度  kafka基本原理 rocketMQ基本原理  技术深度的话，kafka分底层的技术架构 推还是拉 生产者底层的网络通信机制</p>
<p>（4）面试现场给系统设计问题，让我结合哪些场景设计什么</p>
<p>github地址<br><a href="https://github.com/shihan100/Java-Interview-advanced" target="_blank" rel="noopener">https://github.com/shihan100/Java-Interview-advanced</a></p>
<p>1 Dubbo和SpirngCloud 技术深度</p>
<p>2 服务注册中心与服务网关世间</p>
<ol start="3">
<li>网关 动态路由  超高并发   经典 典型 生产环境遇到的问题</li>
</ol>
<p>画一画整个系统的架构图</p>
<p>接口   防重幂等性</p>
<p>分布式事务</p>
<p>具体业务落地 选型  原理 抗高并发  分布式锁</p>
<p>Redis 锁  zookeeper锁</p>
<p>你的分布式锁</p>
<p>淘宝京东库存是如何设计的</p>
<p>面试的常用的额项目经验 生产经验 技术深度</p>
<p>面试常见的技术问题</p>
<p>尽可能把学到的 东西落地到公司的项目中去</p>
<p>作业分析一下自己的差距和大厂的差距有多大<br>结合自身的情<br>自己况来分析一下 结合面试突击第一季的课程</p>
<p>面试突击第一季</p>
<p>技术广度的一些 ，各种技术<br>（1）自己在技术广度上做的如何<br>     对主流的技术栈哪些技术有一定的了解<br>      包括核心原理和解决方案<br>（2） 自己在项目经验生产经验上做的如何？你会的这些技术自己字啊项目中到底用到过多少<br>用的到底有多复杂，用的时候考虑了哪些项目细节和生产细节</p>
<p>(3) 你现在对那些技术是除了核心原理以及基础知识之外，对一些技术的底层概念和原理有一定的了解</p>
<p>（4）系统设计，你目前自己独立负责过射及的消退给你何家沟有多复杂，如果让你来独立设计秒杀胸膛，红包系统，12306系统火者 其他的大型的架构 你会怎么去设计呢</p>
<p>能力 差距在哪里，第一周是预售周，除了四讲是看，其他的是不更新的，从第一周预售结束之后，可以把面试突击第一季巩固一下<br>对自己的能力模型做一个详细的梳理自己现在的能力有多强 差距在哪里</p>
<p>技术深度 你对那些技术是除了核心原理和基础知识之外，对一些技术和概念有一定的理解</p>
<p>系统性分析大厂对工程师的要求，数据结构和算法 ，软素质，工程素养，履历北京，真正在找人的时候，会考虑很多的方面，技术深度，技术广度，项目经验，系统设计，技术上的要求，带团队管理</p>
<p>=======================================================================</p>
<p>针对 面试突击第一季做的总结</p>
<p>面试第一季40到50讲 技术专题</p>
<h1 id="回顾"><a href="#回顾" class="headerlink" title="回顾"></a>回顾</h1><ol>
<li>为什么把系统拆分成哪个分布式的，为啥用dubbo？<br>分布式的架构 拆分成了哪些架构</li>
</ol>
<ol start="2">
<li>dubbo的工作原理是啥？注册中心挂了还可以继续通信吗</li>
</ol>
<ol start="3">
<li>dubbo都支持哪些通信协议和序列化协议 </li>
</ol>
<ol start="4">
<li>dubbo支持哪些负载均衡、高可用以及动态代理的策略？</li>
</ol>
<ol start="5">
<li>spm是啥意思？dubbo的spm机制是怎么玩的</li>
</ol>
<ol start="6">
<li>基于dubbo如何做服务治理，服务降级以及容错</li>
</ol>
<p>这些问题都是非常简单的问题  合格的工程师  大系统拆分成了多少子系统 多少服务框架<br>多个服务</p>
<p>肯定用到服务框架   Dubbo  RPC  SpringCloud  Thirft<br>服务的注册与发现  负载均衡<br>算法负载机制 负载策略<br>通信协议<br>请求超时  请求重试</p>
<ol start="7">
<li><p>分布式系统接口的幂等性该如何保证，比如不能重复扣款？</p>
</li>
<li><p>分布式系统的结构调用如何保证顺序性</p>
</li>
</ol>
<p>   接口幂等性  服务的接口的 如果不保证 是否会会发生重复下单<br>   重复加载之类的问题</p>
<ol start="9">
<li>如何设计一个类似dubbo的rpc框架，架构上该如何考虑<br>自己看过一些 dubbo，springclodu 对一款服务框架有一定的了解和认识，此时如果说<br> 它希望深入的考察你一下，看看你的水平，这个时候就有可能会问你这个问题</li>
</ol>
<p>10 .说说zookeeper一般有哪些使用场景</p>
<ol start="11">
<li>分布式锁是啥？对比redis和zk两种分布式锁的优劣</li>
</ol>
<p>拆分成了很多子系统，就说明有很多子系统在同时再运行， 如果两个子系统都需要对某个数据资源进行一系列复杂的操作在复杂的操作期间，不能让数据被其他任何人来改变，分布式锁，技术实现原理</p>
<ol start="12">
<li><p>说说你们的分布式session方案是啥？怎么做的<br>  前后端分离 一般是前端来care session之类的问题 后端比较少了</p>
</li>
<li><p>了解分布式事务方案吗？你们咋做的？有啥坑？</p>
<p>服务框架  服务注册中心 网关  最基本的分布式系统<br>技术的调研和选型 落地如何做  分布式出现问题 </p>
</li>
</ol>
<p>=============================================================</p>
<h1 id="SpringCloud基础"><a href="#SpringCloud基础" class="headerlink" title="SpringCloud基础"></a>SpringCloud基础</h1><p>分布式围绕dubbo来讨论的 最流行的是springcloud  dubbo和springCloud 正在融合，SpringCloudAlibaba 只不过现在用的公司没有这么多<br>作为合格的工程师  行业的主流的技术栈  Dubbo和SpringCLoud<br>有的用SpirngCloud 不用Dubbo  用Dubbo不用SpringCloud<br>java工程师，dubbo和springCloud的基础原理都有一定的了解</p>
<p>大白话+现场画图</p>
<p>博客资料   书  第一天用非常通俗的语言  把一个系统如果用springcloud的分布式架构的额话，<br>那么他需要用到SpringCLou的哪些组件 为什么</p>
<p>书 博客  demo 描述的不是很清楚</p>
<p>应该先讲解核心架构原理  </p>
<p>Dubbo和SpringCLoud做两个最基本的工程  电商的工程搭建几个服务端的</p>
<p>SpringCLoud的核心架构原理<br>我们一个电商系统 用户需要下单购买一些东西 </p>
<p>订单系统  库存系统  仓储系统 、积分系统 不太可能说用单块的架构，电商消退给你支撑多少用户量  日活100用户还行</p>
<p>购买  注册的用户多的话  百万级用户  十万日货量 就不合适了 背后几十个人在开发<br>此时单块系统是不合适的</p>
<p>重新梳理和明确一个概念 电商系统 拆分成了多个子系统  一次订单的请求</p>
<p>分布式系统</p>
<p><img src="/blog4/2019/10/20/javaInterview2/1571566294313.png" alt="1571566294313"></p>
<p>SpringCLoud的核心架构原理<br>我们一个电商系统 用户需要下单购买一些东西<br>订单系统  库存系统  仓储系统 、积分系统 </p>
<p>不太可能说用单块的架构，电商消退给你支撑多少用户量  日活100用户<br>购买  注册的用户多的话  百万级用户  十万日货量 就不合适了 背后几十个人在开发<br>此时单块系统是不合适的</p>
<p>重新梳理和明确一个概念 电商系统 拆分成了多个子系统  一次订单的请求</p>
<p>思考问题</p>
<p>SpringCloud的核心技术 </p>
<p>四个最基本的组件</p>
<p>Eureka 服务注册中心  </p>
<p>Feign 服务调用 在底层将请求 转换成http的请求</p>
<p>Ribboon：负载均衡</p>
<p>Zuul/SpringCloud GateWay 网关</p>
<p>这么多的系统 电商系统包好了20个子系统 每个子系统里面有20个核心接口<br>一共电商系统400个接口 直接对外暴露，前后端分离的架构，难道你让前端同学必须记住你的20个系统部署的机器的接口，让他们去负载均衡<br>网关</p>
<p>Hystrix  链路追踪  stream 很多组件</p>
<p>Hystrix 高可用的环节 一个普通的系统 没有用好的话 反而会出问题 必须设计对应一整套的方案 限流方案，熔断方案 配合降级机制</p>
<p>微服务 网关</p>
<p>灰度发布   统一限流 统一授权认证<br>网关将所有的接口配置在网关里</p>
<p>前端不用管库存，xxxx，yyyyy部署到什么地方</p>
<h1 id="dubbo的基础架构"><a href="#dubbo的基础架构" class="headerlink" title="dubbo的基础架构"></a>dubbo的基础架构</h1><p><img src="/blog4/2019/10/20/javaInterview2/1571582674788.png" alt="1571582674788"></p>
<p>动态代理 Proxy</p>
<p>负载均衡：Cluster，负载均衡，故障转移</p>
<p>注册中心：Registry</p>
<p>通信协议：Protocol，filter机制，http、rmi、dubbo等协议</p>
<p>http、rmi、dubbo</p>
<p>网络通信：Transport，netty、mina</p>
<p>序列化：封装好的请求如何序列化成二进制数组，通过netty/mina发送出去</p>
<p>网络通信：Transport，基于netty/mina实现的Server</p>
<p>信息交换：Exchange，Response</p>
<p>通信协议：Protocol，filter机制</p>
<p>动态代理：Proxy</p>
<p>网络通信的一些东西，是如何通过<strong>NIO</strong>的方式，<strong>多线程</strong>的方式，让一个服务提供者被多个服务消费者去并发的调用和请求</p>
<p>从整体架构原理的角度，说了一下如何进行扩展的</p>
<p><strong>Dubbo</strong>一次服务请求调用，牵扯到了哪些组件，<strong>负载均衡组件</strong>、<strong>注册中心</strong>、<strong>协议层</strong>、<strong>转换层</strong>、<strong>网络层（netty开发）</strong>、<strong>动态代理</strong>，服务提供者也是类似的</p>
<h2 id="你对dubbo真的熟悉吗"><a href="#你对dubbo真的熟悉吗" class="headerlink" title="你对dubbo真的熟悉吗"></a>你对dubbo真的熟悉吗</h2><p>dubbo 负载均衡策略和集群容错策略都有哪些？动态代理策略呢？</p>
<ul>
<li>dubbo 工作原理：服务注册、注册中心、消费者、代理通信、负载均衡；</li>
<li>网络通信、序列化：dubbo 协议、长连接、NIO、hessian 序列化协议；</li>
<li>负载均衡策略、集群容错策略、动态代理策略：dubbo 跑起来的时候一些功能是如何运转的？怎么做负载均衡？怎么做集群容错？怎么生成动态代理？</li>
<li>dubbo SPI 机制：你了解不了解 dubbo 的 SPI 机制？如何基于 SPI 机制对 dubbo 进行扩展？</li>
</ul>
<h3 id="dubbo-负载均衡策略"><a href="#dubbo-负载均衡策略" class="headerlink" title="dubbo 负载均衡策略"></a>dubbo 负载均衡策略</h3><h4 id="1-random-loadbalance"><a href="#1-random-loadbalance" class="headerlink" title="1 random loadbalance"></a>1 random loadbalance</h4><p>默认情况下，dubbo 是 random load balance ，即<strong>随机</strong>调用实现负载均衡，可以对 provider 不同实例<strong>设置不同的权重</strong>，会按照权重来负载均衡，权重越大分配流量越高，一般就用这个默认的就可以了。</p>
<p>roundrobin loadbalance</p>
<p>这个的话默认就是均匀地将流量打到各个机器上去，但是如果各个机器的性能不一样，容易导致性能差的机器负载过高。所以此时需要调整权重，让性能差的机器承载权重小一些，流量少一些。</p>
<p>跟运维同学申请机器，有的时候，我们运气好，正好公司资源比较充足，刚刚有一批热气腾腾、刚刚做好的虚拟机新鲜出炉，配置都比较高：8 核 + 16G 机器，申请到 2 台。过了一段时间，我们感觉 2 台机器有点不太够，我就去找运维同学说，“哥儿们，你能不能再给我一台机器”，但是这时只剩下一台 4 核 + 8G 的机器。我要还是得要。</p>
<p>这个时候，可以给两台 8 核 16G 的机器设置权重 4，给剩余 1 台 4 核 8G 的机器设置权重 2。</p>
<h4 id="leastactive-loadbalance"><a href="#leastactive-loadbalance" class="headerlink" title="leastactive loadbalance"></a>leastactive loadbalance</h4><p>这个就是自动感知一下，如果某个机器性能越差，那么接收的请求越少，越不活跃，此时就会给<strong>不活跃的性能差的机器更少的请求</strong>。</p>
<h4 id="consistanthash-loadbalance"><a href="#consistanthash-loadbalance" class="headerlink" title="consistanthash loadbalance"></a>consistanthash loadbalance</h4><p>一致性 Hash 算法，相同参数的请求一定分发到一个 provider 上去，provider 挂掉的时候，会基于虚拟节点均匀分配剩余的流量，抖动不会太大。<strong>如果你需要的不是随机负载均衡</strong>，是要一类请求都到一个节点，那就走这个一致性 Hash 策略。</p>
<h3 id="dubbo-集群容错策略"><a href="#dubbo-集群容错策略" class="headerlink" title="dubbo 集群容错策略"></a>dubbo 集群容错策略</h3><h4 id="failover-cluster-模式"><a href="#failover-cluster-模式" class="headerlink" title="failover cluster 模式"></a>failover cluster 模式</h4><p>失败自动切换，自动重试其他机器，<strong>默认</strong>就是这个，常见于读操作。（失败重试其它机器）</p>
<p>可以通过以下几种方式配置重试次数：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dubbo:service</span> <span class="attr">retries</span>=<span class="string">"2"</span> /&gt;</span></span><br></pre></td></tr></table></figure>

<p>或者</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dubbo:reference</span> <span class="attr">retries</span>=<span class="string">"2"</span> /&gt;</span></span><br></pre></td></tr></table></figure>

<p>或者</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dubbo:reference</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dubbo:method</span> <span class="attr">name</span>=<span class="string">"findFoo"</span> <span class="attr">retries</span>=<span class="string">"2"</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dubbo:reference</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="failfast-cluster-模式"><a href="#failfast-cluster-模式" class="headerlink" title="failfast cluster 模式"></a>failfast cluster 模式</h4><p>一次调用失败就立即失败，常见于非幂等性的写操作，比如新增一条记录（调用失败就立即失败）</p>
<h4 id="failsafe-cluster-模式"><a href="#failsafe-cluster-模式" class="headerlink" title="failsafe cluster 模式"></a>failsafe cluster 模式</h4><p><strong>并行调用</strong>多个 provider，只要一个成功就立即返回。常用于实时性要求比较高的读操作，但是会浪费更多的服务资源，可通过 <code>forks=&quot;2&quot;</code> 来设置最大并行数。</p>
<h4 id="broadcacst-cluster"><a href="#broadcacst-cluster" class="headerlink" title="broadcacst cluster"></a>broadcacst cluster</h4><p>逐个调用所有的 provider。任何一个 provider 出错则报错（从<code>2.1.0</code> 版本开始支持）。通常用于通知所有提供者更新缓存或日志等本地资源信息。</p>
<h3 id="dubbo动态代理策略"><a href="#dubbo动态代理策略" class="headerlink" title="dubbo动态代理策略"></a>dubbo动态代理策略</h3><p>默认使用 javassist 动态字节码生成，创建代理类。但是可以通过 spi 扩展机制配置自己的动态代理策略。</p>
<h1 id="幂等性"><a href="#幂等性" class="headerlink" title="幂等性"></a>幂等性</h1><p>接口幂等性实现起来非常的简单</p>
<p>（1）数据库唯一索引<br>（2）基于Redis实现一套幂等性防重框架</p>
<p>对于插入类的操作建议数据库表中设计一些唯一索引</p>
<p>你如果有一个订单被支付了，此时就要通知wms创建一个对应发货单，也是数据库里的一个表，仓库里的人会看到这个发货单，此时他就会根据发货单的信息从仓库里进行拣货，打包，封装，交给物流公司</p>
<p>发货单</p>
<p>id order_id 订单金额 发货地址 xxxx</p>
<p>对order_id就可以建立一个唯一索引，你插入发货单的时候，同一个order_id最多只能对应一个发货单，不可能说同样的一个order_id对应了多个发货单</p>
<p>订单服务 -&gt; wms服务，出现了重试，导致第二次请求再次让人家创建这个订单的发货单，create语句，order_id触发了唯一索引约束</p>
<p>扣减库存、累加积分，更新，很难通过数据库唯一索引来保证</p>
<p>基于Redis实现一套接口的防重框架</p>
<p>你得做一个类似spring mvc里的拦截器这样的东西，在这个拦截器里，他会拦截所有的请求，对所有的请求都会提取请求对应的参数，GET请求、POST请求、PUT请求，有些参数是跟在URL地址里的，?xx=xx&amp;xx=xx</p>
<p>POST、PUT，可能是请求体里的，可能是一个JSON格式</p>
<p>把参数拼接在一起，作为key去redis中判断一下，是否存在这个key，之前附加这些参数的请求是否发起过，如果没有的话，此时就可以把这些参数+接口名称，作为一个key，存储到redis中去</p>
<p>然后呢，把请求放行，去执行这个请求</p>
<p>如果说人家重试再次发起一个这个请求，此时就可以判断出来，参数组成的key在redis中已经存在了，此时就不让执行这个请求了，认为是重复调用了</p>
<p>考虑很多问题，幂等不幂等，通用框架，需要一个公司所有的接口都按照指定的参数来传递，还有很多业务语义的问题</p>
<p>第一次发起一个请求，直接把请求key放入redis，但是他执行的过程中失败了，而且还阻塞了一段时间，此时人家再次重试发起第二次请求，这个时候按照上述的框架逻辑，就会把请求拦截下来了</p>
<p>到底是不是要对所有接口都开启这么一个东西呢？</p>
<p>每个接口如果执行成功了之后，我可以设置一个每个接口调用的时候执行成功之后，做一个后拦截器，如果成功了，就把请求对应的参数拼接为key放入redis中</p>
<p>有没有可能是第一次请求发送过来，在执行过程中，时间长了，比如需要1.3秒才执行完毕；此时人家发现超过1s了，直接重试，第二次请求过来了，也在正常的执行</p>
<p>第一次请求1.3秒之后执行成功了，第二次请求也执行成功了</p>
<p>只要一个服务希望对自己的接口开启幂等性防重功能，就把你开发好的拦截器对应的jar包，通过maven引入一个依赖就可以了</p>
<p>中大型互联网公司里也没做一个统一的防重幂等框架，其实一般都是各个服务对自己核心的接口，如果要保证幂等性的话，每个服务根据自己的业务逻辑来实现，而且仅仅是对少数核心接口做幂等性保障</p>
<p>核心接口，库存服务，扣减库存接口</p>
<p>定制化的去针对接口开发幂等性的机制，比如说一旦库存扣减成功之后，就立马要写一条数据到redis里去，order_id_11356_stock_deduct，写入redis中，如果写入成功，就说明之前这个订单的库存扣减，没人执行过</p>
<p>但是如果此时有一些重试的请求过来了，调用了你的库存扣减接口，他同时也进行了库存的扣减，但是他用同样的一个key，order_id_11356_stock_deduct，写入redis中，此时会发现已经有人写过key，key已经存在了</p>
<p>此时你就应该直接对刚才的库存扣减逻辑做一个反向的回滚逻辑，update product_stock set stock = stock - 100，update product_stock set stock = stock + 100，反向逻辑，回滚掉，自己避免说重复扣减库存</p>
<p>核心接口，幂等性都是自己保证的，人家可能会重试调用你的接口，对于create类的操作，用唯一索引来保证；对update类的操作，建议在核心接口里基于自己的业务逻辑，配合上redis，来保证幂等性</p>
<h3 id="Dubbo，Spring-Cloud，服务注册中心，你们当时是怎么选型和调研的，你们最终是选择了哪块技术呢？你选择这块技术的原因和理由是什么呢？"><a href="#Dubbo，Spring-Cloud，服务注册中心，你们当时是怎么选型和调研的，你们最终是选择了哪块技术呢？你选择这块技术的原因和理由是什么呢？" class="headerlink" title="Dubbo，Spring Cloud，服务注册中心，你们当时是怎么选型和调研的，你们最终是选择了哪块技术呢？你选择这块技术的原因和理由是什么呢？"></a><strong>Dubbo，Spring Cloud，服务注册中心</strong>，你们当时是怎么选型和调研的，你们最终是选择了哪块技术呢？你选择这块技术的原因和理由是什么呢？</h3><p>(1)服务注册发现的原理</p>
<p>集群模式</p>
<p><img src="/blog4/2019/10/20/javaInterview2/1571660432991.png" alt="1571660432991"></p>
<p><strong>Eureka，peer-to-pee</strong>r，部署一个集群，但是集群里每个机器的地位是对等的，各个服务可以向任何一个Eureka实例服务注册和服务发现，集群里任何一个Euerka实例接收到写请求之后，会自动同步给其他所有的Eureka实例</p>
<p><img src="/blog4/2019/10/20/javaInterview2/1571660498549.png" alt="1571660498549"></p>
<p>ZooKeeper，服务注册和发现的原理，Leader + Follower两种角色，只有Leader可以负责写也就是服务注册，他可以把数据同步给Follower，读的时候leader/follower都可以读</p>
<p>(2)一致性保障：CP or AP</p>
<p>**CAP，C是一致性，A是可用性，P是分区容</p>
<p><strong>CP，AP</strong></p>
<p>ZooKeeper是有一个leader节点会接收数据， 然后同步写其他节点，一旦leader挂了，要重新选举leader，这个过程里为了保证C，就牺牲了A，不可用一段时间，但是一个leader选举好了，那么就可以继续写数据了，保证一致性</p>
<p>(4)容量</p>
<p>zk，不适合大规模的服务实例，因为服务上下线的时候，需要瞬间推送数据通知到所有的其他服务实例，所以一旦服务规模太大，到了几千个服务实例的时候，会导致网络带宽被大量占用</p>
<p>eureka，也很难支撑大规模的服务实例，因为每个eureka实例都要接受所有的请求，实例多了压力太大，扛不住，也很难到几千服务实例</p>
<p>之前dubbo技术体系都是用zk当注册中心，spring cloud技术体系都是用eureka当注册中心这两种是运用最广泛的，但是现在很多中小型公司以spring cloud居多，所以后面基于eureka说一下服务注册中心的生产优化</p>
<p>Eureka是peer模式，可能还没同步数据过去，结果自己就死了，此时还是可以继续从别的机器上拉取注册表，但是看到的就不是最新的数据了，但是保证了可用性，强一致，最终一致性</p>
<p>3）服务注册发现的时效性</p>
<p>zk，时效性更好，注册或者是挂了，一般秒级就能感知到</p>
<p>eureka，默认配置非常糟糕，服务发现感知要到几十秒，甚至分钟级别，上线一个新的服务实例，到其他人可以发现他，极端情况下，可能要1分钟的时间，ribbon去获取每个服务上缓存的eureka的注册表进行负载均衡</p>
<p>服务故障，隔60秒才去检查心跳，发现这个服务上一次心跳是在60秒之前，隔60秒去检查心跳，超过90秒没有心跳，才会认为他死了，2分钟都过去</p>
<p>30秒，才会更新缓存，30秒，其他服务才会来拉取最新的注册表</p>
<p>三分钟都过去了，如果你的服务实例挂掉了，此时别人感知到，可能要两三分钟的时间，一两分钟的时间，很漫长</p>
<p>4)容量</p>
<p>zk，不适合大规模的服务实例，因为服务上下线的时候，需要瞬间推送数据通知到所有的其他服务实例，所以一旦服务规模太大，到了几千个服务实例的时候，会导致网络带宽被大量占用</p>
<p>eureka，也很难支撑大规模的服务实例，因为每个eureka实例都要接受所有的请求，实例多了压力太大，扛不住，也很难到几千服务实例</p>
<p>之前dubbo技术体系都是用zk当注册中心，spring cloud技术体系都是用eureka当注册中心这两种是运用最广泛的，但是现在很多中小型公司以spring cloud居多，所以后面基于eureka说一下服务注册中心的生产优化</p>
<p>（5）多机房、多数据中心、健康检查</p>
<p>eureka：peer-to-peer，每台机器都是高并发请求，有瓶颈</p>
<p>zookeeper：服务上下线，全量通知其他服务，网络带宽被打满，有瓶颈</p>
<p>分布式服务注册中心，分片存储服务注册表，横向扩容，每台机器均摊高并发请求，各个服务主动拉取，避免反向通知网卡被打满</p>
<p>RocketKMQ</p>
<p><img src="/blog4/2019/10/20/javaInterview2/1571660734359.png" alt="1571660734359"></p>
<p>核心交易链路，分布式事务框架</p>
<p>有些服务之间的调用是走异步的，下成功了订单之后，你会通知一个wms服务去发货，这个过程可以是异步的，可以是走一个MQ的，发送一个消息到MQ里去，由wms服务去从MQ里消费消息</p>
<p>MQ，消息中间件，面试突击第一季，刚开头我就讲过消息中间件的面试连环炮</p>
<p>可靠消息最终一致性方案，参考面试突击第一季</p>
<p>落地，RocketMQ来实现可靠消息最终一致性事务方案</p>
<p>Producer向RocketMQ发送一个half message</p>
<p>RocketMQ返回一个half message success的响应给Producer，这个时候就形成了一个half message了，此时这个message是不能被消费的</p>
<p>注意，这个步骤可能会因为网络等原因失败，可能你没收到RocketMQ返回的响应，那么就需要重试发送half message，直到一个half message成功建立为止</p>
<p>接着Producer本地执行数据库操作</p>
<p>Producer根据本地数据库操作的结果发送commit/rollback给RocketMQ，如果本地数据库执行成功，那么就发送一个commit给RocketMQ，让他把消息变为可以被消费的；如果本地数据库执行失败，那么就发送一个rollback给RocketMQ，废弃之前的message</p>
<p>注意，这个步骤可能失败，就是Producer可能因为网络原因没成功发送commit/rollback给RocketMQ，此时RocketMQ自己过一段时间发现一直没收到message的commit/rollback，就回调你服务提供的一个接口</p>
<p>此时在这个接口里，你需要自己去检查之前执行的本地数据库操作是否成功了，然后返回commit/rollback给RocketMQ</p>
<p>只要message被commit了，此时下游的服务就可以消费到这个消息，此时还需要结合ack机制，下游消费必须是消费成功了返回ack给RocketMQ，才可以认为是成功了，否则一旦失败没有ack，则必须让RocketMQ重新投递message给其他consumer</p>
<p>TCC框架，bytetcc，seata</p>
<p>seata-server</p>
<p>bytetcc，大家就是基于mysql里面创建一些表，基于表中的数据进行状态的更新</p>
<p>核心链路中的各个服务都需要跟TC这个角色进行频繁的网络通信，频繁的网络通信其实就会带来性能的开销，本来一次请求不引入分布式事务只需要100ms，此时引入了分布式事务之后可能需要耗费200ms</p>
<p>网络请求可能还挺耗时的，上报一些分支事务的状态给TC，seata-server，选择基于哪种存储来放这些分布式事务日志或者状态的，file，磁盘文件，MySQL，数据库来存放对应的一些状态 </p>
<p>高并发场景下，会不会有问题，seata-server，你也需要支持扩容，也需要部署多台机器，用一个数据库来存放分布式事务的日志和状态的话，假设并发量每秒上万，分库分表，对TC背后的数据库也会有同样的压力</p>
<p>这个时候对TC背后的db也得进行分库分表，抗更高的并发压力</p>
<h1 id="为什么要进行系统拆分？如何进行系统拆分？拆分后不用-dubbo-可以吗？"><a href="#为什么要进行系统拆分？如何进行系统拆分？拆分后不用-dubbo-可以吗？" class="headerlink" title="为什么要进行系统拆分？如何进行系统拆分？拆分后不用 dubbo 可以吗？"></a>为什么要进行系统拆分？如何进行系统拆分？拆分后不用 dubbo 可以吗？</h1><p>从这个问题开始就进行分布式系统环节了，现在出去面试分布式都成标配了，没有哪个公司不问问你分布式的事儿。你要是不会分布式的东西，简直这简历没法看，没人会让你去面试。</p>
<p>其实为啥会这样呢？这就是因为整个大行业技术发展的原因。</p>
<p>早些年，印象中在 2010 年初的时候，整个 IT 行业，很少有人谈分布式，更不用说微服务，虽然很多 BAT 等大型公司，因为系统的复杂性，很早就是分布式架构，大量的服务，只不过微服务大多基于自己搞的一套框架来实现而已。</p>
<p>但是确实，那个年代，大家很重视 ssh2，很多中小型公司几乎大部分都是玩儿 struts2、spring、hibernate，稍晚一些，才进入了 spring mvc、spring、mybatis 的组合。那个时候整个行业的技术水平就是那样，当年 oracle 很火，oracle 管理员很吃香，oracle 性能优化啥的都是 IT 男的大杀招啊。连大数据都没人提，当年 OCP、OCM 等认证培训机构，火的不行。</p>
<p>但是确实随着时代的发展，慢慢的，很多公司开始接受分布式系统架构了，这里面尤为对行业有至关重要影响的，是阿里的 dubbo，<strong>某种程度上而言，阿里在这里推动了行业技术的前进</strong>。</p>
<p>正是因为有阿里的 dubbo，很多中小型公司才可以基于 dubbo，来把系统拆分成很多的服务，每个人负责一个服务，大家的代码都没有冲突，服务可以自治，自己选用什么技术都可以，每次发布如果就改动一个服务那就上线一个服务好了，不用所有人一起联调，每次发布都是几十万行代码，甚至几百万行代码了。</p>
<p>直到今日，很高兴看到分布式系统都成行业面试标配了，任何一个普通的程序员都该掌握这个东西，其实这是行业的进步，也是所有 IT 码农的技术进步。所以既然分布式都成标配了，那么面试官当然会问了，因为很多公司现在都是分布式、微服务的架构，那面试官当然得考察考察你了。</p>
<h1 id="为什么要将系统进行拆分？"><a href="#为什么要将系统进行拆分？" class="headerlink" title="为什么要将系统进行拆分？"></a>为什么要将系统进行拆分？</h1><p>是<strong>不拆分</strong>，一个大系统几十万行代码，20 个人维护一份代码，简直是悲剧啊。代码经常改着改着就冲突了，各种代码冲突和合并要处理，非常耗费时间；经常我改动了我的代码，你调用了我的，导致你的代码也得重新测试，麻烦的要死；然后每次发布都是几十万行代码的系统一起发布，大家得一起提心吊胆准备上线，几十万行代码的上线，可能每次上线都要做很多的检查，很多异常问题的处理，简直是又麻烦又痛苦；而且如果我现在打算把技术升级到最新的 spring 版本，还不行，因为这可能导致你的代码报错，我不敢随意乱改技术。</p>
<p>假设一个系统是 20 万行代码，其中 A 在里面改了 1000 行代码，但是此时发布的时候是这个 20 万行代码的大系统一块儿发布。就意味着 20 万上代码在线上就可能出现各种变化，20 个人，每个人都要紧张地等在电脑面前，上线之后，检查日志，看自己负责的那一块儿有没有什么问题。</p>
<p>A 就检查了自己负责的 1 万行代码对应的功能，确保 ok 就闪人了；结果不巧的是，A 上线的时候不小心修改了线上机器的某个配置，导致另外 B 和 C 负责的 2 万行代码对应的一些功能，出错了。</p>
<p>几十个人负责维护一个几十万行代码的单块应用，每次上线，准备几个礼拜，上线 -&gt; 部署 -&gt; 检查自己负责的功能。</p>
<p><strong>拆分了以后</strong>，整个世界清爽了，几十万行代码的系统，拆分成 20 个服务，平均每个服务就 1~2 万行代码，每个服务部署到单独的机器上。20 个工程，20 个 git 代码仓库，20 个开发人员，每个人维护自己的那个服务就可以了，是自己独立的代码，跟别人没关系。再也没有代码冲突了，爽。每次就测试我自己的代码就可以了，爽。每次就发布我自己的一个小服务就可以了，爽。技术上想怎么升级就怎么升级，保持接口不变就可以了，真爽。</p>
<p>所以简单来说，一句话总结，如果是那种代码量多达几十万行的中大型项目，团队里有几十个人，那么如果不拆分系统，<strong>开发效率极其低下</strong>，问题很多。但是拆分系统之后，每个人就负责自己的一小部分就好了，可以随便玩儿随便弄。分布式系统拆分之后，可以大幅度提升复杂系统大型团队的开发效率。</p>
<p>但是同时，也要<strong>提醒</strong>的一点是，系统拆分成分布式系统之后，大量的分布式系统面临的问题也是接踵而来，所以后面的问题都是在<strong>围绕分布式系统带来的复杂技术挑战</strong>在说。</p>
<h1 id="如何进行系统拆分？"><a href="#如何进行系统拆分？" class="headerlink" title="如何进行系统拆分？"></a>如何进行系统拆分？</h1><p>这个问题说大可以很大，可以扯到领域驱动模型设计上去，说小了也很小，我不太想给大家太过于学术的说法，因为你也不可能背这个答案，过去了直接说吧。还是说的简单一点，大家自己到时候知道怎么回答就行了。</p>
<p>系统拆分为分布式系统，拆成多个服务，拆成微服务的架构，是需要拆很多轮的。并不是说上来一个架构师一次就给拆好了，而以后都不用拆。</p>
<p>第一轮；团队继续扩大，拆好的某个服务，刚开始是 1 个人维护 1 万行</p>
<p>如果是多人维护一个服务，最理想的情况下，几十个人，1 个人负责 1 个或 2~3 个服务；某个服务工作量变大了，代码量越来越多，某个同学，负责一个服务，代码量变成了 10 万行了，他自己不堪重负，他现在一个人拆开，5 个服务，1 个人顶着，负责 5 个人，接着招人，2 个人，给那个同学带着，3 个人负责 5 个服务，其中 2 个人每个人负责 2 个服务，1 个人负责 1 个服务。</p>
<p>个人建议，一个服务的代码不要太多，1 万行左右，两三万撑死了吧</p>
<p>大部分的系统，是要进行<strong>多轮拆分</strong>的，第一次拆分，可能就是将以前的多个模块该拆分开来了，比如说将电商系统拆分成订单系统、商品系统、采购系统、仓储系统、用户系统，等等吧。</p>
<p>但是后面可能每个系统又变得越来越复杂了，比如说采购系统里面又分成了供应商管理系统、采购单管理系统，订单系统又拆分成了购物车系统、价格系统、订单管理系统。</p>
<p>扯深了实在很深，所以这里先给大家举个例子，你自己感受一下，<strong>核心意思就是根据情况，先拆分一轮，后面如果系统更复杂了，可以继续分拆</strong>。你根据自己负责系统的例子，来考虑一下就好了。</p>
<h1 id="拆分后不用-dubbo-可以吗？"><a href="#拆分后不用-dubbo-可以吗？" class="headerlink" title="拆分后不用 dubbo 可以吗？"></a>拆分后不用 dubbo 可以吗？</h1><p>当然可以了，大不了最次，就是各个系统之间，直接基于 spring mvc，就纯 http 接口互相通信呗，还能咋样。但是这个肯定是有问题的，因为 http 接口通信维护起来成本很高，你要考虑<strong>超时重试</strong>、<strong>负载均衡</strong>等等各种乱七八糟的问题，比如说你的订单系统调用商品系统，商品系统部署了 5 台机器，你怎么把请求均匀地甩给那 5 台机器？这不就是负载均衡？你要是都自己搞那是可以的，但是确实很痛苦。</p>
<p>所以 dubbo 说白了，是一种 rpc 框架，就是说本地就是进行接口调用，但是 dubbo 会代理这个调用请求，跟远程机器网络通信，给你处理掉负载均衡、服务实例上下线自动感知、超时重试等等乱七八糟的问题。那你就不用自己做了，用 dubbo 就可以了。</p>
<p>如果有问题，结合你的业务，如何基于唯一索引、redis定制化防重机制</p>
<p>自己哪个业务可以用分布式锁？用什么框架？有什么生产问题？</p>
<p>部署，机器配置，大概能抗多少并发；流量、QPS、性能，metrics；压测，借助一些小工具；扩容方案，横向加机器，还是说纵向提升机器的配置</p>
<h1 id="zookeeper-都有哪些使用场景？"><a href="#zookeeper-都有哪些使用场景？" class="headerlink" title="zookeeper 都有哪些使用场景？"></a>zookeeper 都有哪些使用场景？</h1><p>分布式锁这个东西，很常用的，你做 Java 系统开发，分布式系统，可能会有一些场景会用到。最常用的分布式锁就是基于 zookeeper 来实现的。</p>
<p>其实说实话，问这个问题，一般就是看看你是否了解 zookeeper，因为 zookeeper 是分布式系统中很常见的一个基础系统。而且问的话常问的就是说 zookeeper 的使用场景是什么？看你知道不知道一些基本的使用场景。但是其实 zookeeper 挖深了自然是可以问的很深很深的。</p>
<p>大致来说，zookeeper 的使用场景如下，我就举几个简单的，大家能说几个就好了：</p>
<ul>
<li>分布式协调</li>
<li>分布式锁</li>
<li>元数据/配置信息管理</li>
<li>HA高可用性</li>
</ul>
<p>分布式协调</p>
<p>这个其实是 zookeeper 很经典的一个用法，简单来说，就好比，你 A 系统发送个请求到 mq，然后 B 系统消息消费之后处理了。那 A 系统如何知道 B 系统的处理结果？用 zookeeper 就可以实现分布式系统之间的协调工作。A 系统发送请求之后可以在 zookeeper 上<strong>对某个节点的值注册个监听器</strong>，一旦 B 系统处理完了就修改 zookeeper 那个节点的值，A 系统立马就可以收到通知，完美解决。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/1571661593946.png" alt="1571661593946"></p>
<p>分布式锁</p>
<p>对某一个数据连续发出两个修改操作，两台机器同时收到了请求，但是只能一台机器先执行完另外一个机器再执行。那么此时就可以使用 zookeeper 分布式锁，一个机器接收到了请求之后先获取 zookeeper 上的一把分布式锁，就是可以去创建一个 znode，接着执行操作；然后另外一个机器也<strong>尝试去创建</strong>那个 znode，结果发现自己创建不了，因为被别人创建了，那只能等着，等第一个机器执行完了自己再执行。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/1571661715001.png" alt="1571661715001"></p>
<p>元数据/配置信息管理</p>
<p>zookeeper 可以用作很多系统的配置信息的管理，比如 kafka、storm 等等很多分布式系统都会选用 zookeeper 来做一些元数据、配置信息的管理，包括 dubbo 注册中心不也支持 zookeeper 么？</p>
<p><img src="/blog4/2019/10/20/javaInterview2/1571661776518.png" alt></p>
<p>HA高可用性</p>
<p>这个应该是很常见的，比如 hadoop、hdfs、yarn 等很多大数据系统，都选择基于 zookeeper 来开发 HA 高可用机制，就是一个<strong>重要进程一般会做主备</strong>两个，主进程挂了立马通过 zookeeper 感知到切换到备用进程。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/1571661932961.png" alt="1571661932961"></p>
<p>分布式锁的原理</p>
<p><img src="/blog4/2019/10/20/javaInterview2/1571662111632.png" alt="1571662111632"></p>
<p><img src="/blog4/2019/10/20/javaInterview2/1571662256516.png" alt="1571662256516"></p>
<p>羊群效应</p>
<p>如果几十个客户端同时争抢一个锁，此时会导致任何一个客户端释放锁的时候，zk反向通知几十个客户端，几十个客户端又要发送请求到zk去尝试创建锁，所以大家会发现，几十个人要加锁，大家乱糟糟的，无序的</p>
<p>羊群效应</p>
<p>造成很多没必要的请求和网络开销，会加重网络的负载</p>
<p>Redis和ZooKeeper，哪种分布式锁更好？</p>
<p>从分布式系统协调语义而言，是ZooKeeper做分布式锁更好一些，因为Redis本身其实是缓存，但是Redis能抗高并发，高并发场景下更好一些</p>
<p>zookeeper本身不适合部署大规模集群，他本身适用的场景就是部署三五台机器，不是承载高并发请求的，仅仅是用作分布式系统的协调的</p>
<p>Redis？ZooKeeper？</p>
<p>有redis集群，没有zookeeper集群，那你当然就选择redis了；如果你们公司两个都有，用哪种分布式锁都可以，高并发场景，redis</p>
<p>分布式锁脑裂，重复加锁</p>
<p>分布式系统，主控节点有一个Master，此时因为网络故障，导致其他人以为这个Master不可用了，其他节点出现了别的Master，导致集群里有2个Master同时在运行</p>
<p>curator框架源码，加一些协调机制</p>
<h1 id="高可用"><a href="#高可用" class="headerlink" title="高可用"></a>高可用</h1><h2 id="电商网站的商品详情页系统架构"><a href="#电商网站的商品详情页系统架构" class="headerlink" title="电商网站的商品详情页系统架构"></a>电商网站的商品详情页系统架构</h2><h3 id="小型电商网站的商品详情页系统架构"><a href="#小型电商网站的商品详情页系统架构" class="headerlink" title="小型电商网站的商品详情页系统架构"></a>小型电商网站的商品详情页系统架构</h3><p>小型电商网站的页面展示采用页面全量静态化的思想。数据库中存放了所有的商品信息，页面静态化系统，将数据填充进静态模板中，形成静态化页面，推入 Nginx 服务器。用户浏览网站页面时，取用一个已经静态化好的 html 页面，直接返回回去，不涉及任何的业务逻辑处理。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/1571662468695.png" alt="1571662468695"></p>
<p>下面是页面模板的简单 Demo 。</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">        商品名称：#&#123;productName&#125;<span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        商品价格：#&#123;productPrice&#125;<span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        商品描述：#&#123;productDesc&#125;</span><br><span class="line">    <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>这样做，<strong>好处</strong>在于，用户每次浏览一个页面，不需要进行任何的跟数据库的交互逻辑，也不需要执行任何的代码，直接返回一个 html 页面就可以了，速度和性能非常高。</p>
<p>对于小网站，页面很少，很实用，非常简单，Java 中可以使用 velocity、freemarker、thymeleaf 等等，然后做个 cms 页面内容管理系统，模板变更的时候，点击按钮或者系统自动化重新进行全量渲染。</p>
<p><strong>坏处</strong>在于，仅仅适用于一些小型的网站，比如页面的规模在几十到几万不等。对于一些大型的电商网站，亿级数量的页面，你说你每次页面模板修改了，都需要将这么多页面全量静态化，靠谱吗？每次渲染花个好几天时间，那你整个网站就废掉了。</p>
<h3 id="大型电商网站的商品详情页系统架构"><a href="#大型电商网站的商品详情页系统架构" class="headerlink" title="大型电商网站的商品详情页系统架构"></a>大型电商网站的商品详情页系统架构</h3><p>大型电商网站商品详情页的系统设计中，当商品数据发生变更时，会将变更消息压入 MQ 消息队列中。<strong>缓存服务</strong>从消息队列中消费这条消息时，感知到有数据发生变更，便通过调用数据服务接口，获取变更后的数据，然后将整合好的数据推送至 redis 中。Nginx 本地缓存的数据是有一定的时间期限的，比如说 10 分钟，当数据过期之后，它就会从 redis 获取到最新的缓存数据，并且缓存到自己本地。</p>
<p>用户浏览网页时，动态将 Nginx 本地数据渲染到本地 html 模板并返回给用户。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/1571662565958.png" alt="1571662565958"></p>
<p>虽然没有直接返回 html 页面那么快，但是因为数据在本地缓存，所以也很快，其实耗费的也就是动态渲染一个 html 页面的性能。如果 html 模板发生了变更，不需要将所有的页面重新静态化，也不需要发送请求，没有网络请求的开销，直接将数据渲染进最新的 html 页面模板后响应即可。</p>
<p>在这种架构下，我们需要<strong>保证系统的高可用性</strong>。</p>
<p>如果系统访问量很高，Nginx 本地缓存过期失效了，redis 中的缓存也被 LRU 算法给清理掉了，那么会有较高的访问量，从缓存服务调用商品服务。但如果此时商品服务的接口发生故障，调用出现了延时，缓存服务全部的线程都被这个调用商品服务接口给耗尽了，每个线程去调用商品服务接口的时候，都会卡住很长时间，后面大量的请求过来都会卡在那儿，此时缓存服务没有足够的线程去调用其它一些服务的接口，从而导致整个大量的商品详情页无法正常显示。</p>
<p>这其实就是一个商品接口服务故障导致缓存服务资源耗尽的现象。</p>
<h2 id="深入-Hystrix-断路器执行原理"><a href="#深入-Hystrix-断路器执行原理" class="headerlink" title="深入 Hystrix 断路器执行原理"></a>深入 Hystrix 断路器执行原理</h2><h3 id="RequestVolumeThreshold"><a href="#RequestVolumeThreshold" class="headerlink" title="RequestVolumeThreshold"></a>RequestVolumeThreshold</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">HystrixCommandProperties.Setter()</span><br><span class="line">    .withCircuitBreakerRequestVolumeThreshold(<span class="keyword">int</span>)</span><br></pre></td></tr></table></figure>

<p>表示在滑动窗口中，至少有多少个请求，才可能触发断路。</p>
<p>Hystrix 经过断路器的流量超过了一定的阈值，才有可能触发断路。比如说，要求在 10s 内经过断路器的流量必须达到 20 个，而实际经过断路器的流量才 10 个，那么根本不会去判断要不要断路。</p>
<h3 id="ErrorThresholdPercentage"><a href="#ErrorThresholdPercentage" class="headerlink" title="ErrorThresholdPercentage"></a>ErrorThresholdPercentage</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">HystrixCommandProperties.Setter()</span><br><span class="line">    .withCircuitBreakerErrorThresholdPercentage(<span class="keyword">int</span>)</span><br></pre></td></tr></table></figure>

<p>表示异常比例达到多少，才会触发断路，默认值是 50(%)。</p>
<p>如果断路器统计到的异常调用的占比超过了一定的阈值，比如说在 10s 内，经过断路器的流量达到了 30 个，同时其中异常访问的数量也达到了一定的比例，比如 60% 的请求都是异常（报错 / 超时 / reject），就会开启断路。</p>
<h3 id="SleepWindowInMilliseconds"><a href="#SleepWindowInMilliseconds" class="headerlink" title="SleepWindowInMilliseconds"></a>SleepWindowInMilliseconds</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">HystrixCommandProperties.Setter()</span><br><span class="line">    .withCircuitBreakerSleepWindowInMilliseconds(<span class="keyword">int</span>)</span><br></pre></td></tr></table></figure>

<p>断路开启，也就是由 close 转换到 open 状态（close -&gt; open）。那么之后在 <code>SleepWindowInMilliseconds</code> 时间内，所有经过该断路器的请求全部都会被断路，不调用后端服务，直接走 fallback 降级机制。</p>
<p>而在该参数时间过后，断路器会变为 <code>half-open</code> 半开闭状态，尝试让一条请求经过断路器，看能不能正常调用。如果调用成功了，那么就自动恢复，断路器转为 close 状态。</p>
<h3 id="Enabled"><a href="#Enabled" class="headerlink" title="Enabled"></a>Enabled</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">HystrixCommandProperties.Setter()</span><br><span class="line">    .withCircuitBreakerEnabled(<span class="keyword">boolean</span>)</span><br></pre></td></tr></table></figure>

<p>控制是否允许断路器工作，包括跟踪依赖服务调用的健康状况，以及对异常情况过多时是否允许触发断路。默认值是 <code>true</code>。</p>
<h3 id="ForceOpen"><a href="#ForceOpen" class="headerlink" title="ForceOpen"></a>ForceOpen</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">HystrixCommandProperties.Setter()</span><br><span class="line">    .withCircuitBreakerForceOpen(<span class="keyword">boolean</span>)</span><br></pre></td></tr></table></figure>

<p>如果设置为 true 的话，直接强迫打开断路器，相当于是手动断路了，手动降级，默认值是 <code>false</code>。</p>
<h3 id="ForceClosed"><a href="#ForceClosed" class="headerlink" title="ForceClosed"></a>ForceClosed</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">HystrixCommandProperties.Setter()</span><br><span class="line">    .withCircuitBreakerForceClosed(<span class="keyword">boolean</span>)</span><br></pre></td></tr></table></figure>

<p>如果设置为 true，直接强迫关闭断路器，相当于手动停止断路了，手动升级，默认值是 <code>false</code>。</p>
<h2 id="实例-Demo"><a href="#实例-Demo" class="headerlink" title="实例 Demo"></a>实例 Demo</h2><h3 id="HystrixCommand-配置参数"><a href="#HystrixCommand-配置参数" class="headerlink" title="HystrixCommand 配置参数"></a>HystrixCommand 配置参数</h3><p>在 GetProductInfoCommand 中配置 Setter 断路器相关参数。</p>
<ul>
<li>滑动窗口中，最少 20 个请求，才可能触发断路。</li>
<li>异常比例达到 40% 时，才触发断路。</li>
<li>断路后 3000ms 内，所有请求都被 reject，直接走 fallback 降级，不会调用 run() 方法。3000ms 过后，变为 half-open 状态。</li>
</ul>
<p>run() 方法中，我们判断一下 productId 是否为 -1，是的话，直接抛出异常。这么写，我们之后测试的时候就可以传入 productId=-1，<strong>模拟服务执行异常</strong>了。</p>
<p>在降级逻辑中，我们直接给它返回降级商品就好了。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GetProductInfoCommand</span> <span class="keyword">extends</span> <span class="title">HystrixCommand</span>&lt;<span class="title">ProductInfo</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Long productId;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> HystrixCommandKey KEY = HystrixCommandKey.Factory.asKey(<span class="string">"GetProductInfoCommand"</span>);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">GetProductInfoCommand</span><span class="params">(Long productId)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(<span class="string">"ProductInfoService"</span>))</span><br><span class="line">                .andCommandKey(KEY)</span><br><span class="line">                .andCommandPropertiesDefaults(HystrixCommandProperties.Setter()</span><br><span class="line">                        <span class="comment">// 是否允许断路器工作</span></span><br><span class="line">                        .withCircuitBreakerEnabled(<span class="keyword">true</span>)</span><br><span class="line">                        <span class="comment">// 滑动窗口中，最少有多少个请求，才可能触发断路</span></span><br><span class="line">                        .withCircuitBreakerRequestVolumeThreshold(<span class="number">20</span>)</span><br><span class="line">                        <span class="comment">// 异常比例达到多少，才触发断路，默认50%</span></span><br><span class="line">                        .withCircuitBreakerErrorThresholdPercentage(<span class="number">40</span>)</span><br><span class="line">                        <span class="comment">// 断路后多少时间内直接reject请求，之后进入half-open状态，默认5000ms</span></span><br><span class="line">                        .withCircuitBreakerSleepWindowInMilliseconds(<span class="number">3000</span>)));</span><br><span class="line">        <span class="keyword">this</span>.productId = productId;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> ProductInfo <span class="title">run</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"调用接口查询商品数据，productId="</span> + productId);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (productId == -<span class="number">1L</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> Exception();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        String url = <span class="string">"http://localhost:8081/getProductInfo?productId="</span> + productId;</span><br><span class="line">        String response = HttpClientUtils.sendGetRequest(url);</span><br><span class="line">        <span class="keyword">return</span> JSONObject.parseObject(response, ProductInfo.class);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> ProductInfo <span class="title">getFallback</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        ProductInfo productInfo = <span class="keyword">new</span> ProductInfo();</span><br><span class="line">        productInfo.setName(<span class="string">"降级商品"</span>);</span><br><span class="line">        <span class="keyword">return</span> productInfo;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="断路测试类"><a href="#断路测试类" class="headerlink" title="断路测试类"></a>断路测试类</h3><p>我们在测试类中，前 30 次请求，传入 productId=-1，然后休眠 3s，之后 70 次请求，传入 productId=1。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@SpringBootTest</span></span><br><span class="line"><span class="meta">@RunWith</span>(SpringRunner.class)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CircuitBreakerTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testCircuitBreaker</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        String baseURL = <span class="string">"http://localhost:8080/getProductInfo?productId="</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">30</span>; ++i) &#123;</span><br><span class="line">            <span class="comment">// 传入-1，会抛出异常，然后走降级逻辑</span></span><br><span class="line">            HttpClientUtils.sendGetRequest(baseURL + <span class="string">"-1"</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        TimeUtils.sleep(<span class="number">3</span>);</span><br><span class="line">        System.out.println(<span class="string">"After sleeping..."</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">31</span>; i &lt; <span class="number">100</span>; ++i) &#123;</span><br><span class="line">            <span class="comment">// 传入1，走服务正常调用</span></span><br><span class="line">            HttpClientUtils.sendGetRequest(baseURL + <span class="string">"1"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h3><p>测试结果，我们可以明显看出系统断路与恢复的整个过程。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">调用接口查询商品数据，productId=<span class="number">-1</span></span><br><span class="line">ProductInfo(id=null, name=降级商品, price=null, pictureList=null, specification=null, service=null, color=null, size=null, shopId=null, modifiedTime=null, cityId=null, cityName=null, brandId=null, brandName=null)</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"><span class="comment">// 这里重复打印了 20 次上面的结果</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ProductInfo(id=null, name=降级商品, price=null, pictureList=null, specification=null, service=null, color=null, size=null, shopId=null, modifiedTime=null, cityId=null, cityName=null, brandId=null, brandName=null)</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"><span class="comment">// 这里重复打印了 8 次上面的结果</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 休眠 3s 后</span></span><br><span class="line">调用接口查询商品数据，productId=<span class="number">1</span></span><br><span class="line">ProductInfo(id=<span class="number">1</span>, name=iphone7手机, price=<span class="number">5599.0</span>, pictureList=a.jpg,b.jpg, specification=iphone7的规格, service=iphone7的售后服务, color=红色,白色,黑色, size=<span class="number">5.5</span>, shopId=<span class="number">1</span>, modifiedTime=<span class="number">2017</span><span class="number">-01</span><span class="number">-01</span> <span class="number">12</span>:<span class="number">00</span>:<span class="number">00</span>, cityId=<span class="number">1</span>, cityName=null, brandId=<span class="number">1</span>, brandName=null)</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"><span class="comment">// 这里重复打印了 69 次上面的结果</span></span><br></pre></td></tr></table></figure>

<p>前 30 次请求，我们传入的 productId 为 -1，所以服务执行过程中会抛出异常。我们设置了最少 20 次请求通过断路器并且异常比例超出 40% 就触发断路。因此执行了 21 次接口调用，每次都抛异常并且走降级，21 次过后，断路器就被打开了。</p>
<p>之后的 9 次请求，都不会执行 run() 方法，也就不会打印以下信息。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">调用接口查询商品数据，productId=<span class="number">-1</span></span><br></pre></td></tr></table></figure>

<p>而是直接走降级逻辑，调用 getFallback() 执行。</p>
<p>休眠了 3s 后，我们在之后的 70 次请求中，都传入 productId 为 1。由于我们前面设置了 3000ms 过后断路器变为 <code>half-open</code> 状态。因此 Hystrix 会尝试执行请求，发现成功了，那么断路器关闭，之后的所有请求也都能正常调用了。</p>
<h2 id="Hystrix-隔离策略细粒度控制"><a href="#Hystrix-隔离策略细粒度控制" class="headerlink" title="Hystrix 隔离策略细粒度控制"></a>Hystrix 隔离策略细粒度控制</h2><p>Hystrix 实现资源隔离，有两种策略：</p>
<ul>
<li>线程池隔离</li>
<li>信号量隔离</li>
</ul>
<p>对资源隔离这一块东西，其实可以做一定细粒度的一些控制。</p>
<h3 id="execution-isolation-strategy"><a href="#execution-isolation-strategy" class="headerlink" title="execution.isolation.strategy"></a>execution.isolation.strategy</h3><p>指定了 HystrixCommand.run() 的资源隔离策略：<code>THREAD</code> or <code>SEMAPHORE</code>，一种基于线程池，一种基于信号量。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// to use thread isolation</span></span><br><span class="line">HystrixCommandProperties.Setter().withExecutionIsolationStrategy(ExecutionIsolationStrategy.THREAD)</span><br><span class="line"></span><br><span class="line"><span class="comment">// to use semaphore isolation</span></span><br><span class="line">HystrixCommandProperties.Setter().withExecutionIsolationStrategy(ExecutionIsolationStrategy.SEMAPHORE)</span><br></pre></td></tr></table></figure>

<p>线程池机制，每个 command 运行在一个线程中，限流是通过线程池的大小来控制的；信号量机制，command 是运行在调用线程中，通过信号量的容量来进行限流。</p>
<p>如何在线程池和信号量之间做选择？</p>
<p><strong>默认的策略</strong>就是线程池。</p>
<p><strong>线程池</strong>其实最大的好处就是对于网络访问请求，如果有超时的话，可以避免调用线程阻塞住。</p>
<p>而使用信号量的场景，通常是针对超大并发量的场景下，每个服务实例每秒都几百的 <code>QPS</code>，那么此时你用线程池的话，线程一般不会太多，可能撑不住那么高的并发，如果要撑住，可能要耗费大量的线程资源，那么就是用信号量，来进行限流保护。一般用信号量常见于那种基于纯内存的一些业务逻辑服务，而不涉及到任何网络访问请求。</p>
<h3 id="command-key-amp-command-group"><a href="#command-key-amp-command-group" class="headerlink" title="command key &amp; command group"></a>command key &amp; command group</h3><p>我们使用线程池隔离，要怎么对<strong>依赖服务</strong>、<strong>依赖服务接口</strong>、<strong>线程池</strong>三者做划分呢？</p>
<p>每一个 command，都可以设置一个自己的名称 command key，同时可以设置一个自己的组 command group。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Setter cachedSetter = Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(<span class="string">"ExampleGroup"</span>))</span><br><span class="line">                                                .andCommandKey(HystrixCommandKey.Factory.asKey(<span class="string">"HelloWorld"</span>)); </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">CommandHelloWorld</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>(cachedSetter);</span><br><span class="line">    <span class="keyword">this</span>.name = name;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>command group 是一个非常重要的概念，默认情况下，就是通过 command group 来定义一个线程池的，而且还会通过 command group 来聚合一些监控和报警信息。同一个 command group 中的请求，都会进入同一个线程池中。</p>
<h3 id="command-thread-pool"><a href="#command-thread-pool" class="headerlink" title="command thread pool"></a>command thread pool</h3><p>ThreadPoolKey 代表了一个 HystrixThreadPool，用来进行统一监控、统计、缓存。默认的 ThreadPoolKey 就是 command group 的名称。每个 command 都会跟它的 ThreadPoolKey 对应的 ThreadPool 绑定在一起。</p>
<p>如果不想直接用 command group，也可以手动设置 ThreadPool 的名称。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Setter cachedSetter = Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(<span class="string">"ExampleGroup"</span>))</span><br><span class="line">                                                .andCommandKey(HystrixCommandKey.Factory.asKey(<span class="string">"HelloWorld"</span>))</span><br><span class="line">                                                .andThreadPoolKey(HystrixThreadPoolKey.Factory.asKey(<span class="string">"HelloWorldPool"</span>));</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">CommandHelloWorld</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>(cachedSetter);</span><br><span class="line">    <span class="keyword">this</span>.name = name;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="command-key-amp-command-group-amp-command-thread-pool"><a href="#command-key-amp-command-group-amp-command-thread-pool" class="headerlink" title="command key &amp; command group &amp; command thread pool"></a>command key &amp; command group &amp; command thread pool</h3><p><strong>command key</strong> ，代表了一类 command，一般来说，代表了底层的依赖服务的一个接口。</p>
<p><strong>command group</strong> ，代表了某一个底层的依赖服务，这是很合理的，一个依赖服务可能会暴露出来多个接口，每个接口就是一个 command key。command group 在逻辑上去组织起来一堆 command key 的调用、统计信息、成功次数、timeout 超时次数、失败次数等，可以看到某一个服务整体的一些访问情况。一般来说，<strong>推荐</strong>根据一个服务区划分出一个线程池，command key 默认都是属于同一个线程池的。</p>
<p>比如说你以一个服务为粒度，估算出来这个服务每秒的所有接口加起来的整体 <code>QPS</code> 在 100 左右，你调用这个服务，当前这个服务部署了 10 个服务实例，每个服务实例上，其实用这个 command group 对应这个服务，给一个线程池，量大概在 10 个左右就可以了，你对整个服务的整体的访问 QPS 就大概在每秒 100 左右。</p>
<p>但是，如果说 command group 对应了一个服务，而这个服务暴露出来的几个接口，访问量很不一样，差异非常之大。你可能就希望在这个服务 command group 内部，包含的对应多个接口的 command key，做一些细粒度的资源隔离。就是说，对同一个服务的不同接口，使用不同的线程池。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">command key -&gt; command group</span><br><span class="line"></span><br><span class="line">command key -&gt; 自己的 thread pool key</span><br></pre></td></tr></table></figure>

<p>逻辑上来说，多个 command key 属于一个command group，在做统计的时候，会放在一起统计。每个 command key 有自己的线程池，每个接口有自己的线程池，去做资源隔离和限流。</p>
<p>说白点，就是说如果你的 command key 要用自己的线程池，可以定义自己的 thread pool key，就 ok 了。</p>
<h3 id="coreSize"><a href="#coreSize" class="headerlink" title="coreSize"></a>coreSize</h3><p>设置线程池的大小，默认是 10。一般来说，用这个默认的 10 个线程大小就够了。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HystrixThreadPoolProperties.Setter().withCoreSize(<span class="keyword">int</span> value);</span><br></pre></td></tr></table></figure>

<h3 id="queueSizeRejectionThreshold"><a href="#queueSizeRejectionThreshold" class="headerlink" title="queueSizeRejectionThreshold"></a>queueSizeRejectionThreshold</h3><p>如果说线程池中的 10 个线程都在工作中，没有空闲的线程来做其它的事情，此时再有请求过来，会先进入队列积压。如果说队列积压满了，再有请求过来，就直接 reject，拒绝请求，执行 fallback 降级的逻辑，快速返回。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/../../../../images/hystrix-thread-pool-queue.png" alt="hystrix-thread-pool-queue"></p>
<p>控制 queue 满了之后 reject 的 threshold，因为 maxQueueSize 不允许热修改，因此提供这个参数可以热修改，控制队列的最大大小。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HystrixThreadPoolProperties.Setter().withQueueSizeRejectionThreshold(<span class="keyword">int</span> value);</span><br></pre></td></tr></table></figure>

<h3 id="execution-isolation-semaphore-maxConcurrentRequests"><a href="#execution-isolation-semaphore-maxConcurrentRequests" class="headerlink" title="execution.isolation.semaphore.maxConcurrentRequests"></a>execution.isolation.semaphore.maxConcurrentRequests</h3><p>设置使用 SEMAPHORE 隔离策略的时候允许访问的最大并发量，超过这个最大并发量，请求直接被 reject。</p>
<p>这个并发量的设置，跟线程池大小的设置，应该是类似的，但是基于信号量的话，性能会好很多，而且 Hystrix 框架本身的开销会小很多。</p>
<p>默认值是 10，尽量设置的小一些，因为一旦设置的太大，而且有延时发生，可能瞬间导致 tomcat 本身的线程资源被占满。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HystrixCommandProperties.Setter().withExecutionIsolationSemaphoreMaxConcurrentRequests(<span class="keyword">int</span> value);</span><br></pre></td></tr></table></figure>

<h2 id="基于本地缓存的-fallback-降级机制"><a href="#基于本地缓存的-fallback-降级机制" class="headerlink" title="基于本地缓存的 fallback 降级机制"></a>基于本地缓存的 fallback 降级机制</h2><p>Hystrix 出现以下四种情况，都会去调用 fallback 降级机制：</p>
<ul>
<li>断路器处于打开的状态。</li>
<li>资源池已满（线程池+队列 / 信号量）。</li>
<li>Hystrix 调用各种接口，或者访问外部依赖，比如 MySQL、Redis、Zookeeper、Kafka 等等，出现了任何异常的情况。</li>
<li>访问外部依赖的时候，访问时间过长，报了 TimeoutException 异常。</li>
</ul>
<h3 id="两种最经典的降级机制"><a href="#两种最经典的降级机制" class="headerlink" title="两种最经典的降级机制"></a>两种最经典的降级机制</h3><ul>
<li><p>纯内存数据<br><br>在降级逻辑中，你可以在内存中维护一个 ehcache，作为一个纯内存的基于 LRU 自动清理的缓存，让数据放在缓存内。如果说外部依赖有异常，fallback 这里直接尝试从 ehcache 中获取数据。</p>
</li>
<li><p>默认值<br><br>fallback 降级逻辑中，也可以直接返回一个默认值。</p>
</li>
</ul>
<p>在 <code>HystrixCommand</code>，降级逻辑的书写，是通过实现 getFallback() 接口；而在 <code>HystrixObservableCommand</code> 中，则是实现 resumeWithFallback() 方法。</p>
<p>现在，我们用一个简单的栗子，来演示 fallback 降级是怎么做的。</p>
<p>比如，有这么个<strong>场景</strong>。我们现在有个包含 brandId 的商品数据，假设正常的逻辑是这样：拿到一个商品数据，根据 brandId 去调用品牌服务的接口，获取品牌的最新名称 brandName。</p>
<p>假如说，品牌服务接口挂掉了，那么我们可以尝试从本地内存中，获取一份稍过期的数据，先凑合着用。</p>
<h3 id="步骤一：本地缓存获取数据"><a href="#步骤一：本地缓存获取数据" class="headerlink" title="步骤一：本地缓存获取数据"></a>步骤一：本地缓存获取数据</h3><p>本地获取品牌名称的代码大致如下。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 品牌名称本地缓存</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BrandCache</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Map&lt;Long, String&gt; brandMap = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        brandMap.put(<span class="number">1L</span>, <span class="string">"Nike"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * brandId 获取 brandName</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> brandId 品牌id</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 品牌名</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">getBrandName</span><span class="params">(Long brandId)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> brandMap.get(brandId);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<h3 id="步骤二：实现-GetBrandNameCommand"><a href="#步骤二：实现-GetBrandNameCommand" class="headerlink" title="步骤二：实现 GetBrandNameCommand"></a>步骤二：实现 GetBrandNameCommand</h3><p>在 GetBrandNameCommand 中，run() 方法的正常逻辑是去调用品牌服务的接口获取到品牌名称，如果调用失败，报错了，那么就会去调用 fallback 降级机制。</p>
<p>这里，我们直接<strong>模拟接口调用报错</strong>，给它抛出个异常。</p>
<p>而在 getFallback() 方法中，就是我们的<strong>降级逻辑</strong>，我们直接从本地的缓存中，<strong>获取到品牌名称</strong>的数据。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 获取品牌名称的command</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GetBrandNameCommand</span> <span class="keyword">extends</span> <span class="title">HystrixCommand</span>&lt;<span class="title">String</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Long brandId;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">GetBrandNameCommand</span><span class="params">(Long brandId)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(<span class="string">"BrandService"</span>))</span><br><span class="line">                .andCommandKey(HystrixCommandKey.Factory.asKey(<span class="string">"GetBrandNameCommand"</span>))</span><br><span class="line">                .andCommandPropertiesDefaults(HystrixCommandProperties.Setter()</span><br><span class="line">                        <span class="comment">// 设置降级机制最大并发请求数</span></span><br><span class="line">                        .withFallbackIsolationSemaphoreMaxConcurrentRequests(<span class="number">15</span>)));</span><br><span class="line">        <span class="keyword">this</span>.brandId = brandId;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> String <span class="title">run</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">// 这里正常的逻辑应该是去调用一个品牌服务的接口获取名称</span></span><br><span class="line">        <span class="comment">// 如果调用失败，报错了，那么就会去调用fallback降级机制</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 这里我们直接模拟调用报错，抛出异常</span></span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> Exception();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> String <span class="title">getFallback</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> BrandCache.getBrandName(brandId);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>FallbackIsolationSemaphoreMaxConcurrentRequests</code> 用于设置 fallback 最大允许的并发请求量，默认值是 10，是通过 semaphore 信号量的机制去限流的。如果超出了这个最大值，那么直接 reject。</p>
<h3 id="步骤三：CacheController-调用接口"><a href="#步骤三：CacheController-调用接口" class="headerlink" title="步骤三：CacheController 调用接口"></a>步骤三：CacheController 调用接口</h3><p>在 CacheController 中，我们通过 productInfo 获取 brandId，然后创建 GetBrandNameCommand 并执行，去尝试获取 brandName。这里执行会报错，因为我们在 run() 方法中直接抛出异常，Hystrix 就会去调用 getFallback() 方法走降级逻辑。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Controller</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CacheController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@RequestMapping</span>(<span class="string">"/getProductInfo"</span>)</span><br><span class="line">    <span class="meta">@ResponseBody</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getProductInfo</span><span class="params">(Long productId)</span> </span>&#123;</span><br><span class="line">        HystrixCommand&lt;ProductInfo&gt; getProductInfoCommand = <span class="keyword">new</span> GetProductInfoCommand(productId);</span><br><span class="line"></span><br><span class="line">        ProductInfo productInfo = getProductInfoCommand.execute();</span><br><span class="line">        Long brandId = productInfo.getBrandId();</span><br><span class="line"></span><br><span class="line">        HystrixCommand&lt;String&gt; getBrandNameCommand = <span class="keyword">new</span> GetBrandNameCommand(brandId);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 执行会抛异常报错，然后走降级</span></span><br><span class="line">        String brandName = getBrandNameCommand.execute();</span><br><span class="line">        productInfo.setBrandName(brandName);</span><br><span class="line"></span><br><span class="line">        System.out.println(productInfo);</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"success"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>关于降级逻辑的演示，基本上就结束了。</p>
<h2 id="用-Hystrix-构建高可用服务架构"><a href="#用-Hystrix-构建高可用服务架构" class="headerlink" title="用 Hystrix 构建高可用服务架构"></a>用 Hystrix 构建高可用服务架构</h2><p>参考 <a href="https://github.com/Netflix/Hystrix/wiki#what" target="_blank" rel="noopener">Hystrix Home</a>。</p>
<h3 id="Hystrix-是什么？"><a href="#Hystrix-是什么？" class="headerlink" title="Hystrix 是什么？"></a>Hystrix 是什么？</h3><p>在分布式系统中，每个服务都可能会调用很多其他服务，被调用的那些服务就是<strong>依赖服务</strong>，有的时候某些依赖服务出现故障也是很正常的。</p>
<p>Hystrix 可以让我们在分布式系统中对服务间的调用进行控制，加入一些<strong>调用延迟</strong>或者<strong>依赖故障</strong>的<strong>容错机制</strong>。</p>
<p>Hystrix 通过将依赖服务进行<strong>资源隔离</strong>，进而阻止某个依赖服务出现故障时在整个系统所有的依赖服务调用中进行蔓延；同时Hystrix 还提供故障时的 fallback 降级机制。</p>
<p>总而言之，Hystrix 通过这些方法帮助我们提升分布式系统的可用性和稳定性。</p>
<h3 id="Hystrix-的历史"><a href="#Hystrix-的历史" class="headerlink" title="Hystrix 的历史"></a>Hystrix 的历史</h3><p>Hystrix 是高可用性保障的一个框架。Netflix（可以认为是国外的优酷或者爱奇艺之类的视频网站）的 API 团队从 2011 年开始做一些提升系统可用性和稳定性的工作，Hystrix 就是从那时候开始发展出来的。</p>
<p>在 2012 年的时候，Hystrix 就变得比较成熟和稳定了，Netflix 中，除了 API 团队以外，很多其他的团队都开始使用 Hystrix。</p>
<p>时至今日，Netflix 中每天都有数十亿次的服务间调用，通过 Hystrix 框架在进行，而 Hystrix 也帮助 Netflix 网站提升了整体的可用性和稳定性。</p>
<p><a href="https://github.com/Netflix/Hystrix/blob/master/README.md#hystrix-status" target="_blank" rel="noopener">2018 年 11 月，Hystrix 在其 Github 主页宣布，不再开放新功能，推荐开发者使用其他仍然活跃的开源项目</a>。维护模式的转变绝不意味着 Hystrix 不再有价值。相反，Hystrix 激发了很多伟大的想法和项目，我们高可用的这一块知识还是会针对 Hystrix 进行讲解。</p>
<h3 id="Hystrix-的设计原则"><a href="#Hystrix-的设计原则" class="headerlink" title="Hystrix 的设计原则"></a>Hystrix 的设计原则</h3><ul>
<li>对依赖服务调用时出现的调用延迟和调用失败进行<strong>控制和容错保护</strong>。</li>
<li>在复杂的分布式系统中，阻止某一个依赖服务的故障在整个系统中蔓延。比如某一个服务故障了，导致其它服务也跟着故障。</li>
<li>提供 <code>fail-fast</code>（快速失败）和快速恢复的支持。</li>
<li>提供 fallback 优雅降级的支持。</li>
<li>支持近实时的监控、报警以及运维操作。</li>
</ul>
<p>有这样一个分布式系统，服务 A 依赖于服务 B，服务 B 依赖于服务 C/D/E。在这样一个成熟的系统内，比如说最多可能只有 100 个线程资源。正常情况下，40 个线程并发调用服务 C，各 30 个线程并发调用 D/E。</p>
<p>调用服务 C，只需要 20ms，现在因为服务 C 故障了，比如延迟，或者挂了，此时线程会 hang 住 2s 左右。40 个线程全部被卡住，由于请求不断涌入，其它的线程也用来调用服务 C，同样也会被卡住。这样导致服务 B 的线程资源被耗尽，无法接收新的请求，甚至可能因为大量线程不断的运转，导致自己宕机。服务 A 也挂。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/1571662862056.png" alt="1571662862056"></p>
<p>Hystrix 可以对其进行资源隔离，比如限制服务 B 只有 40 个线程调用服务 C。当此 40 个线程被 hang 住时，其它 60 个线程依然能正常调用工作。从而确保整个系统不会被拖垮。</p>
<h3 id="Hystrix-更加细节的设计原则"><a href="#Hystrix-更加细节的设计原则" class="headerlink" title="Hystrix 更加细节的设计原则"></a>Hystrix 更加细节的设计原则</h3><ul>
<li>阻止任何一个依赖服务耗尽所有的资源，比如 tomcat 中的所有线程资源。</li>
<li>避免请求排队和积压，采用限流和 <code>fail fast</code> 来控制故障。</li>
<li>提供 fallback 降级机制来应对故障。</li>
<li>使用资源隔离技术，比如 <code>bulkhead</code>（舱壁隔离技术）、<code>swimlane</code>（泳道技术）、<code>circuit breaker</code>（断路技术）来限制任何一个依赖服务的故障的影响。</li>
<li>通过近实时的统计/监控/报警功能，来提高故障发现的速度。</li>
<li>通过近实时的属性和配置<strong>热修改</strong>功能，来提高故障处理和恢复的速度。</li>
<li>保护依赖服务调用的所有故障情况，而不仅仅只是网络故障情况。</li>
</ul>
<h2 id="深入-Hystrix-执行时内部原理"><a href="#深入-Hystrix-执行时内部原理" class="headerlink" title="深入 Hystrix 执行时内部原理"></a>深入 Hystrix 执行时内部原理</h2><p>前面我们了解了 Hystrix 最基本的支持高可用的技术：<strong>资源隔离</strong> + <strong>限流</strong>。</p>
<ul>
<li>创建 command；</li>
<li>执行这个 command；</li>
<li>配置这个 command 对应的 group 和线程池。</li>
</ul>
<p>开始执行这个 command，调用了这个 command 的 execute() 方法之后，Hystrix 底层的执行流程和步骤以及原理是什么。</p>
<p>在讲解这个流程的过程中，我会带出来 Hystrix 其他的一些核心以及重要的功能。</p>
<p>这里是整个 8 大步骤的流程图</p>
<p><img src="/blog4/2019/10/20/javaInterview2/1571663234245.png" alt="1571663234245"></p>
<h3 id="步骤一：创建-command"><a href="#步骤一：创建-command" class="headerlink" title="步骤一：创建 command"></a>步骤一：创建 command</h3><p>一个 HystrixCommand 或 HystrixObservableCommand 对象，代表了对某个依赖服务发起的一次请求或者调用。创建的时候，可以在构造函数中传入任何需要的参数。</p>
<ul>
<li>HystrixCommand 主要用于仅仅会返回一个结果的调用。</li>
<li>HystrixObservableCommand 主要用于可能会返回多条结果的调用。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建 HystrixCommand</span></span><br><span class="line">HystrixCommand hystrixCommand = <span class="keyword">new</span> HystrixCommand(arg1, arg2);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建 HystrixObservableCommand</span></span><br><span class="line">HystrixObservableCommand hystrixObservableCommand = <span class="keyword">new</span> HystrixObservableCommand(arg1, arg2);</span><br></pre></td></tr></table></figure>

<h3 id="步骤二：调用-command-执行方法"><a href="#步骤二：调用-command-执行方法" class="headerlink" title="步骤二：调用 command 执行方法"></a>步骤二：调用 command 执行方法</h3><p>执行 command，就可以发起一次对依赖服务的调用。</p>
<p>要执行 command，可以在 4 个方法中选择其中的一个：execute()、queue()、observe()、toObservable()。</p>
<p>其中 execute() 和 queue() 方法仅仅对 HystrixCommand 适用。</p>
<ul>
<li>execute()：调用后直接 block 住，属于同步调用，直到依赖服务返回单条结果，或者抛出异常。</li>
<li>queue()：返回一个 Future，属于异步调用，后面可以通过 Future 获取单条结果。</li>
<li>observe()：订阅一个 Observable 对象，Observable 代表的是依赖服务返回的结果，获取到一个那个代表结果的 Observable 对象的拷贝对象。</li>
<li>toObservable()：返回一个 Observable 对象，如果我们订阅这个对象，就会执行 command 并且获取返回结果。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">K             value    = hystrixCommand.execute();</span><br><span class="line">Future&lt;K&gt;     fValue   = hystrixCommand.queue();</span><br><span class="line">Observable&lt;K&gt; oValue   = hystrixObservableCommand.observe();</span><br><span class="line">Observable&lt;K&gt; toOValue = hystrixObservableCommand.toObservable();</span><br></pre></td></tr></table></figure>

<p>execute() 实际上会调用 queue().get() 方法，可以看一下 Hystrix 源码。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> R <span class="title">execute</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> queue().get();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        <span class="keyword">throw</span> Exceptions.sneakyThrow(decomposeException(e));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>而在 queue() 方法中，会调用 toObservable().toBlocking().toFuture()。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> Future&lt;R&gt; delegate = toObservable().toBlocking().toFuture();</span><br></pre></td></tr></table></figure>

<p>也就是说，先通过 toObservable() 获得 Future 对象，然后调用 Future 的 get() 方法。那么，其实无论是哪种方式执行 command，最终都是依赖于 toObservable() 去执行的。</p>
<h3 id="步骤三：检查是否开启缓存"><a href="#步骤三：检查是否开启缓存" class="headerlink" title="步骤三：检查是否开启缓存"></a>步骤三：检查是否开启缓存</h3><p>从这一步开始，就进入到 Hystrix 底层运行原理啦，看一下 Hystrix 一些更高级的功能和特性。</p>
<p>如果这个 command 开启了请求缓存 Request Cache，而且这个调用的结果在缓存中存在，那么直接从缓存中返回结果。否则，继续往后的步骤。</p>
<h3 id="步骤四：检查是否开启了断路器"><a href="#步骤四：检查是否开启了断路器" class="headerlink" title="步骤四：检查是否开启了断路器"></a>步骤四：检查是否开启了断路器</h3><p>检查这个 command 对应的依赖服务是否开启了断路器。如果断路器被打开了，那么 Hystrix 就不会执行这个 command，而是直接去执行 fallback 降级机制，返回降级结果。</p>
<h3 id="步骤五：检查线程池-队列-信号量是否已满"><a href="#步骤五：检查线程池-队列-信号量是否已满" class="headerlink" title="步骤五：检查线程池/队列/信号量是否已满"></a>步骤五：检查线程池/队列/信号量是否已满</h3><p>如果这个 command 线程池和队列已满，或者 semaphore 信号量已满，那么也不会执行 command，而是直接去调用 fallback 降级机制，同时发送 reject 信息给断路器统计。</p>
<h3 id="步骤六：执行-command"><a href="#步骤六：执行-command" class="headerlink" title="步骤六：执行 command"></a>步骤六：执行 command</h3><p>调用 HystrixObservableCommand 对象的 construct() 方法，或者 HystrixCommand 的 run() 方法来实际执行这个 command。</p>
<ul>
<li>HystrixCommand.run() 返回单条结果，或者抛出异常。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 通过command执行，获取最新一条商品数据</span></span><br><span class="line">ProductInfo productInfo = getProductInfoCommand.execute();</span><br></pre></td></tr></table></figure>

<ul>
<li>HystrixObservableCommand.construct() 返回一个 Observable 对象，可以获取多条结果。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">Observable&lt;ProductInfo&gt; observable = getProductInfosCommand.observe();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 订阅获取多条结果</span></span><br><span class="line">observable.subscribe(<span class="keyword">new</span> Observer&lt;ProductInfo&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompleted</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"获取完了所有的商品数据"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onError</span><span class="params">(Throwable e)</span> </span>&#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取完一条数据，就回调一次这个方法</span></span><br><span class="line"><span class="comment">     * </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> productInfo 商品信息</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onNext</span><span class="params">(ProductInfo productInfo)</span> </span>&#123;</span><br><span class="line">        System.out.println(productInfo);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<p>如果是采用线程池方式，并且 HystrixCommand.run() 或者 HystrixObservableCommand.construct() 的执行时间超过了 timeout 时长的话，那么 command 所在的线程会抛出一个 TimeoutException，这时会执行 fallback 降级机制，不会去管 run() 或 construct() 返回的值了。另一种情况，如果 command 执行出错抛出了其它异常，那么也会走 fallback 降级。这两种情况下，Hystrix 都会发送异常事件给断路器统计。</p>
<p><strong>注意</strong>，我们是不可能终止掉一个调用严重延迟的依赖服务的线程的，只能说给你抛出来一个 TimeoutException。</p>
<p>如果没有 timeout，也正常执行的话，那么调用线程就会拿到一些调用依赖服务获取到的结果，然后 Hystrix 也会做一些 logging 记录和 metric 度量统计。</p>
<h3 id="步骤七：断路健康检查"><a href="#步骤七：断路健康检查" class="headerlink" title="步骤七：断路健康检查"></a>步骤七：断路健康检查</h3><p>Hystrix 会把每一个依赖服务的调用成功、失败、Reject、Timeout 等事件发送给 circuit breaker 断路器。断路器就会对这些事件的次数进行统计，根据异常事件发生的比例来决定是否要进行断路（熔断）。如果打开了断路器，那么在接下来一段时间内，会直接断路，返回降级结果。</p>
<p>如果在之后，断路器尝试执行 command，调用没有出错，返回了正常结果，那么 Hystrix 就会把断路器关闭。</p>
<h3 id="步骤八：调用-fallback-降级机制"><a href="#步骤八：调用-fallback-降级机制" class="headerlink" title="步骤八：调用 fallback 降级机制"></a>步骤八：调用 fallback 降级机制</h3><p>在以下几种情况中，Hystrix 会调用 fallback 降级机制。</p>
<ul>
<li>断路器处于打开状态；</li>
<li>线程池/队列/semaphore满了；</li>
<li>command 执行超时；</li>
<li>run() 或者 construct() 抛出异常。</li>
</ul>
<p>一般在降级机制中，都建议给出一些默认的返回值，比如静态的一些代码逻辑，或者从内存中的缓存中提取一些数据，在这里尽量不要再进行网络请求了。</p>
<p>在降级中，如果一定要进行网络调用的话，也应该将那个调用放在一个 HystrixCommand 中进行隔离。</p>
<ul>
<li>HystrixCommand 中，实现 getFallback() 方法，可以提供降级机制。</li>
<li>HystrixObservableCommand 中，实现 resumeWithFallback() 方法，返回一个 Observable 对象，可以提供降级结果。</li>
</ul>
<p>如果没有实现 fallback，或者 fallback 抛出了异常，Hystrix 会返回一个 Observable，但是不会返回任何数据。</p>
<p>不同的 command 执行方式，其 fallback 为空或者异常时的返回结果不同。</p>
<ul>
<li>对于 execute()，直接抛出异常。</li>
<li>对于 queue()，返回一个 Future，调用 get() 时抛出异常。</li>
<li>对于 observe()，返回一个 Observable 对象，但是调用 subscribe() 方法订阅它时，立即抛出调用者的 onError() 方法。</li>
<li>对于 toObservable()，返回一个 Observable 对象，但是调用 subscribe() 方法订阅它时，立即抛出调用者的 onError() 方法。</li>
</ul>
<h3 id="不同的执行方式"><a href="#不同的执行方式" class="headerlink" title="不同的执行方式"></a>不同的执行方式</h3><ul>
<li>execute()，获取一个 Future.get()，然后拿到单个结果。</li>
<li>queue()，返回一个 Future。</li>
<li>observe()，立即订阅 Observable，然后启动 8 大执行步骤，返回一个拷贝的 Observable，订阅时立即回调给你结果。</li>
<li>toObservable()，返回一个原始的 Observable，必须手动订阅才会去执行 8 大步骤。</li>
</ul>
<h2 id="基于-request-cache-请求缓存技术优化批量商品数据查询接口"><a href="#基于-request-cache-请求缓存技术优化批量商品数据查询接口" class="headerlink" title="基于 request cache 请求缓存技术优化批量商品数据查询接口"></a>基于 request cache 请求缓存技术优化批量商品数据查询接口</h2><p>Hystrix command 执行时 8 大步骤第三步，就是检查 Request cache 是否有缓存。</p>
<p>首先，有一个概念，叫做 Request Context 请求上下文，一般来说，在一个 web 应用中，如果我们用到了 Hystrix，我们会在一个 filter 里面，对每一个请求都施加一个请求上下文。就是说，每一次请求，就是一次请求上下文。然后在这次请求上下文中，我们会去执行 N 多代码，调用 N 多依赖服务，有的依赖服务可能还会调用好几次。</p>
<p>在一次请求上下文中，如果有多个 command，参数都是一样的，调用的接口也是一样的，而结果可以认为也是一样的。那么这个时候，我们可以让第一个 command 执行返回的结果缓存在内存中，然后这个请求上下文后续的其它对这个依赖的调用全部从内存中取出缓存结果就可以了。</p>
<p>这样的话，好处在于不用在一次请求上下文中反复多次执行一样的 command，<strong>避免重复执行网络请求，提升整个请求的性能</strong>。</p>
<p>举个栗子。比如说我们在一次请求上下文中，请求获取 productId 为 1 的数据，第一次缓存中没有，那么会从商品服务中获取数据，返回最新数据结果，同时将数据缓存在内存中。后续同一次请求上下文中，如果还有获取 productId 为 1 的数据的请求，直接从缓存中取就好了。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/../../../../images/hystrix-request-cache.png" alt="hystrix-request-cache"></p>
<p>HystrixCommand 和 HystrixObservableCommand 都可以指定一个缓存 key，然后 Hystrix 会自动进行缓存，接着在同一个 request context 内，再次访问的话，就会直接取用缓存。</p>
<p>下面，我们结合一个具体的<strong>业务场景</strong>，来看一下如何使用 request cache 请求缓存技术。当然，以下代码只作为一个基本的 Demo 而已。</p>
<p>现在，假设我们要做一个<strong>批量查询商品数据</strong>的接口，在这个里面，我们是用 HystrixCommand 一次性批量查询多个商品 id 的数据。但是这里有个问题，如果说 Nginx 在本地缓存失效了，重新获取一批缓存，传递过来的 productIds 都没有进行去重，比如 <code>productIds=1,1,1,2,2</code>，那么可能说，商品 id 出现了重复，如果按照我们之前的业务逻辑，可能就会重复对 productId=1 的商品查询三次，productId=2 的商品查询两次。</p>
<p>我们对批量查询商品数据的接口，可以用 request cache 做一个优化，就是说一次请求，就是一次 request context，对相同的商品查询只执行一次，其余重复的都走 request cache。</p>
<h3 id="实现-Hystrix-请求上下文过滤器并注册"><a href="#实现-Hystrix-请求上下文过滤器并注册" class="headerlink" title="实现 Hystrix 请求上下文过滤器并注册"></a>实现 Hystrix 请求上下文过滤器并注册</h3><p>定义 HystrixRequestContextFilter 类，实现 Filter 接口。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Hystrix 请求上下文过滤器</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HystrixRequestContextFilter</span> <span class="keyword">implements</span> <span class="title">Filter</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">(FilterConfig filterConfig)</span> <span class="keyword">throws</span> ServletException </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doFilter</span><span class="params">(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain)</span> </span>&#123;</span><br><span class="line">        HystrixRequestContext context = HystrixRequestContext.initializeContext();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            filterChain.doFilter(servletRequest, servletResponse);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException | ServletException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            context.shutdown();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">destroy</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然后将该 filter 对象注册到 SpringBoot Application 中。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">EshopApplication</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SpringApplication.run(EshopApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> FilterRegistrationBean <span class="title">filterRegistrationBean</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        FilterRegistrationBean filterRegistrationBean = <span class="keyword">new</span> FilterRegistrationBean(<span class="keyword">new</span> HystrixRequestContextFilter());</span><br><span class="line">        filterRegistrationBean.addUrlPatterns(<span class="string">"/*"</span>);</span><br><span class="line">        <span class="keyword">return</span> filterRegistrationBean;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="command-重写-getCacheKey-方法"><a href="#command-重写-getCacheKey-方法" class="headerlink" title="command 重写 getCacheKey() 方法"></a>command 重写 getCacheKey() 方法</h3><p>在 GetProductInfoCommand 中，重写 getCacheKey() 方法，这样的话，每一次请求的结果，都会放在 Hystrix 请求上下文中。下一次同一个 productId 的数据请求，直接取缓存，无须再调用 run() 方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GetProductInfoCommand</span> <span class="keyword">extends</span> <span class="title">HystrixCommand</span>&lt;<span class="title">ProductInfo</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Long productId;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> HystrixCommandKey KEY = HystrixCommandKey.Factory.asKey(<span class="string">"GetProductInfoCommand"</span>);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">GetProductInfoCommand</span><span class="params">(Long productId)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(<span class="string">"ProductInfoService"</span>))</span><br><span class="line">                .andCommandKey(KEY));</span><br><span class="line">        <span class="keyword">this</span>.productId = productId;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> ProductInfo <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        String url = <span class="string">"http://localhost:8081/getProductInfo?productId="</span> + productId;</span><br><span class="line">        String response = HttpClientUtils.sendGetRequest(url);</span><br><span class="line">        System.out.println(<span class="string">"调用接口查询商品数据，productId="</span> + productId);</span><br><span class="line">        <span class="keyword">return</span> JSONObject.parseObject(response, ProductInfo.class);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 每次请求的结果，都会放在Hystrix绑定的请求上下文上</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> cacheKey 缓存key</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getCacheKey</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"product_info_"</span> + productId;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 将某个商品id的缓存清空</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> productId 商品id</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">flushCache</span><span class="params">(Long productId)</span> </span>&#123;</span><br><span class="line">        HystrixRequestCache.getInstance(KEY,</span><br><span class="line">                HystrixConcurrencyStrategyDefault.getInstance()).clear(<span class="string">"product_info_"</span> + productId);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里写了一个 flushCache() 方法，用于我们开发手动删除缓存。</p>
<h3 id="controller-调用-command-查询商品信息"><a href="#controller-调用-command-查询商品信息" class="headerlink" title="controller 调用 command 查询商品信息"></a>controller 调用 command 查询商品信息</h3><p>在一次 web 请求上下文中，传入商品 id 列表，查询多条商品数据信息。对于每个 productId，都创建一个 command。</p>
<p>如果 id 列表没有去重，那么重复的 id，第二次查询的时候就会直接走缓存。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Controller</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CacheController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 一次性批量查询多条商品数据的请求</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> productIds 以,分隔的商品id列表</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 响应状态</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@RequestMapping</span>(<span class="string">"/getProductInfos"</span>)</span><br><span class="line">    <span class="meta">@ResponseBody</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getProductInfos</span><span class="params">(String productIds)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (String productId : productIds.split(<span class="string">","</span>)) &#123;</span><br><span class="line">            <span class="comment">// 对每个productId，都创建一个command</span></span><br><span class="line">            GetProductInfoCommand getProductInfoCommand = <span class="keyword">new</span> GetProductInfoCommand(Long.valueOf(productId));</span><br><span class="line">            ProductInfo productInfo = getProductInfoCommand.execute();</span><br><span class="line">            System.out.println(<span class="string">"是否是从缓存中取的结果："</span> + getProductInfoCommand.isResponseFromCache());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="string">"success"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="发起请求"><a href="#发起请求" class="headerlink" title="发起请求"></a>发起请求</h3><p>调用接口，查询多个商品的信息。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8080/getProductInfos?productIds=1,1,1,2,2,5</span><br></pre></td></tr></table></figure>

<p>在控制台，我们可以看到以下结果。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">调用接口查询商品数据，productId=1</span><br><span class="line">是否是从缓存中取的结果：false</span><br><span class="line">是否是从缓存中取的结果：true</span><br><span class="line">是否是从缓存中取的结果：true</span><br><span class="line">调用接口查询商品数据，productId=2</span><br><span class="line">是否是从缓存中取的结果：false</span><br><span class="line">是否是从缓存中取的结果：true</span><br><span class="line">调用接口查询商品数据，productId=5</span><br><span class="line">是否是从缓存中取的结果：false</span><br></pre></td></tr></table></figure>

<p>第一次查询 productId=1 的数据，会调用接口进行查询，不是从缓存中取结果。而随后再出现查询 productId=1 的请求，就直接取缓存了，这样的话，效率明显高很多。</p>
<h3 id="删除缓存"><a href="#删除缓存" class="headerlink" title="删除缓存"></a>删除缓存</h3><p>我们写一个 UpdateProductInfoCommand，在更新商品信息之后，手动调用之前写的 flushCache()，手动将缓存删除。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UpdateProductInfoCommand</span> <span class="keyword">extends</span> <span class="title">HystrixCommand</span>&lt;<span class="title">Boolean</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Long productId;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">UpdateProductInfoCommand</span><span class="params">(Long productId)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(HystrixCommandGroupKey.Factory.asKey(<span class="string">"UpdateProductInfoGroup"</span>));</span><br><span class="line">        <span class="keyword">this</span>.productId = productId;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> Boolean <span class="title">run</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">// 这里执行一次商品信息的更新</span></span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 然后清空缓存</span></span><br><span class="line">        GetProductInfoCommand.flushCache(productId);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这样，以后查询该商品的请求，第一次就会走接口调用去查询最新的商品信息。</p>
<h2 id="基于-Hystrix-线程池技术实现资源隔离"><a href="#基于-Hystrix-线程池技术实现资源隔离" class="headerlink" title="基于 Hystrix 线程池技术实现资源隔离"></a>基于 Hystrix 线程池技术实现资源隔离</h2><p>上一讲提到，如果从 Nginx 开始，缓存都失效了，Nginx 会直接通过缓存服务调用商品服务获取最新商品数据（我们基于电商项目做个讨论），有可能出现调用延时而把缓存服务资源耗尽的情况。这里，我们就来说说，怎么通过 Hystrix 线程池技术实现资源隔离。</p>
<p>资源隔离，就是说，你如果要把对某一个依赖服务的所有调用请求，全部隔离在同一份资源池内，不会去用其它资源了，这就叫资源隔离。哪怕对这个依赖服务，比如说商品服务，现在同时发起的调用量已经到了 1000，但是线程池内就 10 个线程，最多就只会用这 10 个线程去执行，不会说，对商品服务的请求，因为接口调用延时，将 tomcat 内部所有的线程资源全部耗尽。</p>
<p>Hystrix 进行资源隔离，其实是提供了一个抽象，叫做 command。这也是 Hystrix 最最基本的资源隔离技术。</p>
<h3 id="利用-HystrixCommand-获取单条数据"><a href="#利用-HystrixCommand-获取单条数据" class="headerlink" title="利用 HystrixCommand 获取单条数据"></a>利用 HystrixCommand 获取单条数据</h3><p>我们通过将调用商品服务的操作封装在 HystrixCommand 中，限定一个 key，比如下面的 <code>GetProductInfoCommandGroup</code>，在这里我们可以简单认为这是一个线程池，每次调用商品服务，就只会用该线程池中的资源，不会再去用其它线程资源了。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GetProductInfoCommand</span> <span class="keyword">extends</span> <span class="title">HystrixCommand</span>&lt;<span class="title">ProductInfo</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Long productId;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">GetProductInfoCommand</span><span class="params">(Long productId)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(HystrixCommandGroupKey.Factory.asKey(<span class="string">"GetProductInfoCommandGroup"</span>));</span><br><span class="line">        <span class="keyword">this</span>.productId = productId;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> ProductInfo <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        String url = <span class="string">"http://localhost:8081/getProductInfo?productId="</span> + productId;</span><br><span class="line">        <span class="comment">// 调用商品服务接口</span></span><br><span class="line">        String response = HttpClientUtils.sendGetRequest(url);</span><br><span class="line">        <span class="keyword">return</span> JSONObject.parseObject(response, ProductInfo.class);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们在缓存服务接口中，根据 productId 创建 command 并执行，获取到商品数据。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@RequestMapping</span>(<span class="string">"/getProductInfo"</span>)</span><br><span class="line"><span class="meta">@ResponseBody</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">getProductInfo</span><span class="params">(Long productId)</span> </span>&#123;</span><br><span class="line">    HystrixCommand&lt;ProductInfo&gt; getProductInfoCommand = <span class="keyword">new</span> GetProductInfoCommand(productId);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 通过command执行，获取最新商品数据</span></span><br><span class="line">    ProductInfo productInfo = getProductInfoCommand.execute();</span><br><span class="line">    System.out.println(productInfo);</span><br><span class="line">    <span class="keyword">return</span> <span class="string">"success"</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上面执行的是 execute() 方法，其实是同步的。也可以对 command 调用 queue() 方法，它仅仅是将 command 放入线程池的一个等待队列，就立即返回，拿到一个 Future 对象，后面可以继续做其它一些事情，然后过一段时间对 Future 调用 get() 方法获取数据。这是异步的。</p>
<h3 id="利用-HystrixObservableCommand-批量获取数据"><a href="#利用-HystrixObservableCommand-批量获取数据" class="headerlink" title="利用 HystrixObservableCommand 批量获取数据"></a>利用 HystrixObservableCommand 批量获取数据</h3><p>只要是获取商品数据，全部都绑定到同一个线程池里面去，我们通过 HystrixObservableCommand 的一个线程去执行，而在这个线程里面，批量把多个 productId 的 productInfo 拉回来。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GetProductInfosCommand</span> <span class="keyword">extends</span> <span class="title">HystrixObservableCommand</span>&lt;<span class="title">ProductInfo</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String[] productIds;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">GetProductInfosCommand</span><span class="params">(String[] productIds)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 还是绑定在同一个线程池</span></span><br><span class="line">        <span class="keyword">super</span>(HystrixCommandGroupKey.Factory.asKey(<span class="string">"GetProductInfoGroup"</span>));</span><br><span class="line">        <span class="keyword">this</span>.productIds = productIds;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> Observable&lt;ProductInfo&gt; <span class="title">construct</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> Observable.unsafeCreate((Observable.OnSubscribe&lt;ProductInfo&gt;) subscriber -&gt; &#123;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> (String productId : productIds) &#123;</span><br><span class="line">                <span class="comment">// 批量获取商品数据</span></span><br><span class="line">                String url = <span class="string">"http://localhost:8081/getProductInfo?productId="</span> + productId;</span><br><span class="line">                String response = HttpClientUtils.sendGetRequest(url);</span><br><span class="line">                ProductInfo productInfo = JSONObject.parseObject(response, ProductInfo.class);</span><br><span class="line">                subscriber.onNext(productInfo);</span><br><span class="line">            &#125;</span><br><span class="line">            subscriber.onCompleted();</span><br><span class="line"></span><br><span class="line">        &#125;).subscribeOn(Schedulers.io());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在缓存服务接口中，根据传来的 id 列表，比如是以 <code>,</code> 分隔的 id 串，通过上面的 HystrixObservableCommand，执行 Hystrix 的一些 API 方法，获取到所有商品数据。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">getProductInfos</span><span class="params">(String productIds)</span> </span>&#123;</span><br><span class="line">    String[] productIdArray = productIds.split(<span class="string">","</span>);</span><br><span class="line">    HystrixObservableCommand&lt;ProductInfo&gt; getProductInfosCommand = <span class="keyword">new</span> GetProductInfosCommand(productIdArray);</span><br><span class="line">    Observable&lt;ProductInfo&gt; observable = getProductInfosCommand.observe();</span><br><span class="line"></span><br><span class="line">    observable.subscribe(<span class="keyword">new</span> Observer&lt;ProductInfo&gt;() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompleted</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            System.out.println(<span class="string">"获取完了所有的商品数据"</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onError</span><span class="params">(Throwable e)</span> </span>&#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 获取完一条数据，就回调一次这个方法</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> productInfo</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onNext</span><span class="params">(ProductInfo productInfo)</span> </span>&#123;</span><br><span class="line">            System.out.println(productInfo);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">    <span class="keyword">return</span> <span class="string">"success"</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们回过头来，看看 Hystrix 线程池技术是如何实现资源隔离的。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/1571663532026.png" alt="1571663532026"></p>
<p>从 Nginx 开始，缓存都失效了，那么 Nginx 通过缓存服务去调用商品服务。缓存服务默认的线程大小是 10 个，最多就只有 10 个线程去调用商品服务的接口。即使商品服务接口故障了，最多就只有 10 个线程会 hang 死在调用商品服务接口的路上，缓存服务的 tomcat 内其它的线程还是可以用来调用其它的服务，干其它的事情。</p>
<h2 id="基于-timeout-机制为服务接口调用超时提供安全保护"><a href="#基于-timeout-机制为服务接口调用超时提供安全保护" class="headerlink" title="基于 timeout 机制为服务接口调用超时提供安全保护"></a>基于 timeout 机制为服务接口调用超时提供安全保护</h2><p>一般来说，在调用依赖服务的接口的时候，比较常见的一个问题就是<strong>超时</strong>。超时是在一个复杂的分布式系统中，导致系统不稳定，或者系统抖动。出现大量超时，线程资源会被 hang 死，从而导致吞吐量大幅度下降，甚至服务崩溃。</p>
<p>你去调用各种各样的依赖服务，特别是在大公司，你甚至都不认识开发一个服务的人，你都不知道那个人的技术水平怎么样，对那个人根本不了解。</p>
<p>Peter Steiner 说过，”<a href="https://en.wikipedia.org/wiki/On_the_Internet,_nobody_knows_you%27re_a_dog" target="_blank" rel="noopener">On the Internet, nobody knows you’re a dog</a>“，也就是说在互联网的另外一头，你都不知道甚至坐着一条狗。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/../../../../images/220px-Internet_dog.jpg" alt="220px-Internet_dog.jpg"></p>
<p>像特别复杂的分布式系统，特别是在大公司里，多个团队、大型协作，你可能都不知道服务是谁的，很可能说开发服务的那个哥儿们甚至是一个实习生。依赖服务的接口性能可能很不稳定，有时候 2ms，有时候 200ms，甚至 2s，都有可能。</p>
<p>如果你不对各种依赖服务接口的调用做超时控制，来给你的服务提供安全保护措施，那么很可能你的服务就被各种垃圾的依赖服务的性能给拖死了。大量的接口调用很慢，大量的线程被卡死。如果你做了资源的隔离，那么也就是线程池的线程被卡死，但其实我们可以做超时控制，没必要让它们全卡死。</p>
<h3 id="TimeoutMilliseconds"><a href="#TimeoutMilliseconds" class="headerlink" title="TimeoutMilliseconds"></a>TimeoutMilliseconds</h3><p>在 Hystrix 中，我们可以手动设置 timeout 时长，如果一个 command 运行时间超过了设定的时长，那么就被认为是 timeout，然后 Hystrix command 标识为 timeout，同时执行 fallback 降级逻辑。</p>
<p><code>TimeoutMilliseconds</code> 默认值是 1000，也就是 1000ms。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">HystrixCommandProperties.Setter()</span><br><span class="line">    ..withExecutionTimeoutInMilliseconds(<span class="keyword">int</span>)</span><br></pre></td></tr></table></figure>

<h3 id="TimeoutEnabled"><a href="#TimeoutEnabled" class="headerlink" title="TimeoutEnabled"></a>TimeoutEnabled</h3><p>这个参数用于控制是否要打开 timeout 机制，默认值是 true。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">HystrixCommandProperties.Setter()</span><br><span class="line">    .withExecutionTimeoutEnabled(<span class="keyword">boolean</span>)</span><br></pre></td></tr></table></figure>

<h2 id="实例-Demo-1"><a href="#实例-Demo-1" class="headerlink" title="实例 Demo"></a>实例 Demo</h2><p>我们在 command 中，将超时时间设置为 500ms，然后在 run() 方法中，设置休眠时间 1s，这样一个请求过来，直接休眠 1s，结果就会因为超时而执行降级逻辑。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GetProductInfoCommand</span> <span class="keyword">extends</span> <span class="title">HystrixCommand</span>&lt;<span class="title">ProductInfo</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Long productId;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> HystrixCommandKey KEY = HystrixCommandKey.Factory.asKey(<span class="string">"GetProductInfoCommand"</span>);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">GetProductInfoCommand</span><span class="params">(Long productId)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(<span class="string">"ProductInfoService"</span>))</span><br><span class="line">                .andCommandKey(KEY)</span><br><span class="line">                .andThreadPoolPropertiesDefaults(HystrixThreadPoolProperties.Setter()</span><br><span class="line">                        .withCoreSize(<span class="number">8</span>)</span><br><span class="line">                        .withMaxQueueSize(<span class="number">10</span>)</span><br><span class="line">                        .withQueueSizeRejectionThreshold(<span class="number">8</span>))</span><br><span class="line">                .andCommandPropertiesDefaults(HystrixCommandProperties.Setter()</span><br><span class="line">                        .withCircuitBreakerEnabled(<span class="keyword">true</span>)</span><br><span class="line">                        .withCircuitBreakerRequestVolumeThreshold(<span class="number">20</span>)</span><br><span class="line">                        .withCircuitBreakerErrorThresholdPercentage(<span class="number">40</span>)</span><br><span class="line">                        .withCircuitBreakerSleepWindowInMilliseconds(<span class="number">3000</span>)</span><br><span class="line">                        <span class="comment">// 设置是否打开超时，默认是true</span></span><br><span class="line">                        .withExecutionTimeoutEnabled(<span class="keyword">true</span>)</span><br><span class="line">                        <span class="comment">// 设置超时时间，默认1000(ms)</span></span><br><span class="line">                        .withExecutionTimeoutInMilliseconds(<span class="number">500</span>)</span><br><span class="line">                        .withFallbackIsolationSemaphoreMaxConcurrentRequests(<span class="number">30</span>)));</span><br><span class="line">        <span class="keyword">this</span>.productId = productId;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> ProductInfo <span class="title">run</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"调用接口查询商品数据，productId="</span> + productId);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 休眠1s</span></span><br><span class="line">        TimeUtils.sleep(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        String url = <span class="string">"http://localhost:8081/getProductInfo?productId="</span> + productId;</span><br><span class="line">        String response = HttpClientUtils.sendGetRequest(url);</span><br><span class="line">        System.out.println(response);</span><br><span class="line">        <span class="keyword">return</span> JSONObject.parseObject(response, ProductInfo.class);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> ProductInfo <span class="title">getFallback</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        ProductInfo productInfo = <span class="keyword">new</span> ProductInfo();</span><br><span class="line">        productInfo.setName(<span class="string">"降级商品"</span>);</span><br><span class="line">        <span class="keyword">return</span> productInfo;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在测试类中，我们直接发起请求。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@SpringBootTest</span></span><br><span class="line"><span class="meta">@RunWith</span>(SpringRunner.class)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TimeoutTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testTimeout</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        HttpClientUtils.sendGetRequest(<span class="string">"http://localhost:8080/getProductInfo?productId=1"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>结果中可以看到，打印出了降级商品相关信息。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ProductInfo(id=null, name=降级商品, price=null, pictureList=null, specification=null, service=null, color=null, size=null, shopId=null, modifiedTime=null, cityId=null, cityName=null, brandId=null, brandName=null)</span><br><span class="line">&#123;<span class="string">"id"</span>: <span class="number">1</span>, <span class="string">"name"</span>: <span class="string">"iphone7手机"</span>, <span class="string">"price"</span>: <span class="number">5599</span>, <span class="string">"pictureList"</span>:<span class="string">"a.jpg,b.jpg"</span>, <span class="string">"specification"</span>: <span class="string">"iphone7的规格"</span>, <span class="string">"service"</span>: <span class="string">"iphone7的售后服务"</span>, <span class="string">"color"</span>: <span class="string">"红色,白色,黑色"</span>, <span class="string">"size"</span>: <span class="string">"5.5"</span>, <span class="string">"shopId"</span>: <span class="number">1</span>, <span class="string">"modifiedTime"</span>: <span class="string">"2017-01-01 12:00:00"</span>, <span class="string">"cityId"</span>: <span class="number">1</span>, <span class="string">"brandId"</span>: <span class="number">1</span>&#125;</span><br></pre></td></tr></table></figure>

<h1 id="高并发架构"><a href="#高并发架构" class="headerlink" title="高并发架构"></a>高并发架构</h1><h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>为什么要分库分表（设计高并发系统的时候，数据库层面该如何设计）？用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？你们具体是如何对数据库如何进行垂直拆分或水平拆分的？</p>
<h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>其实这块肯定是扯到<strong>高并发</strong>了，因为分库分表一定是为了<strong>支撑高并发、数据量大</strong>两个问题的。而且现在说实话，尤其是互联网类的公司面试，基本上都会来这么一下，分库分表如此普遍的技术问题，不问实在是不行，而如果你不知道那也实在是说不过去！</p>
<h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="为什么要分库分表？（设计高并发系统的时候，数据库层面该如何设计？）"><a href="#为什么要分库分表？（设计高并发系统的时候，数据库层面该如何设计？）" class="headerlink" title="为什么要分库分表？（设计高并发系统的时候，数据库层面该如何设计？）"></a>为什么要分库分表？（设计高并发系统的时候，数据库层面该如何设计？）</h3><p>说白了，分库分表是两回事儿，大家可别搞混了，可能是光分库不分表，也可能是光分表不分库，都有可能。</p>
<p>我先给大家抛出来一个场景。</p>
<p>假如我们现在是一个小创业公司（或者是一个 BAT 公司刚兴起的一个新部门），现在注册用户就 20 万，每天活跃用户就 1 万，每天单表数据量就 1000，然后高峰期每秒钟并发请求最多就 10。天，就这种系统，随便找一个有几年工作经验的，然后带几个刚培训出来的，随便干干都可以。</p>
<p>结果没想到我们运气居然这么好，碰上个 CEO 带着我们走上了康庄大道，业务发展迅猛，过了几个月，注册用户数达到了 2000 万！每天活跃用户数 100 万！每天单表数据量 10 万条！高峰期每秒最大请求达到 1000！同时公司还顺带着融资了两轮，进账了几个亿人民币啊！公司估值达到了惊人的几亿美金！这是小独角兽的节奏！</p>
<p>好吧，没事，现在大家感觉压力已经有点大了，为啥呢？因为每天多 10 万条数据，一个月就多 300 万条数据，现在咱们单表已经几百万数据了，马上就破千万了。但是勉强还能撑着。高峰期请求现在是 1000，咱们线上部署了几台机器，负载均衡搞了一下，数据库撑 1000QPS 也还凑合。但是大家现在开始感觉有点担心了，接下来咋整呢……</p>
<p>再接下来几个月，我的天，CEO 太牛逼了，公司用户数已经达到 1 亿，公司继续融资几十亿人民币啊！公司估值达到了惊人的几十亿美金，成为了国内今年最牛逼的明星创业公司！天，我们太幸运了。</p>
<p>但是我们同时也是不幸的，因为此时每天活跃用户数上千万，每天单表新增数据多达 50 万，目前一个表总数据量都已经达到了两三千万了！扛不住啊！数据库磁盘容量不断消耗掉！高峰期并发达到惊人的 <code>5000~8000</code>！别开玩笑了，哥。我跟你保证，你的系统支撑不到现在，已经挂掉了！</p>
<p>好吧，所以你看到这里差不多就理解分库分表是怎么回事儿了，实际上这是跟着你的公司业务发展走的，你公司业务发展越好，用户就越多，数据量越大，请求量越大，那你单个数据库一定扛不住。</p>
<h4 id="分表"><a href="#分表" class="headerlink" title="分表"></a>分表</h4><p>比如你单表都几千万数据了，你确定你能扛住么？绝对不行，<strong>单表数据量太大</strong>，会极大影响你的 sql <strong>执行的性能</strong>，到了后面你的 sql 可能就跑的很慢了。一般来说，就以我的经验来看，单表到几百万的时候，性能就会相对差一些了，你就得分表了。</p>
<p>分表是啥意思？就是把一个表的数据放到多个表中，然后查询的时候你就查一个表。比如按照用户 id 来分表，将一个用户的数据就放在一个表中。然后操作的时候你对一个用户就操作那个表就好了。这样可以控制每个表的数据量在可控的范围内，比如每个表就固定在 200 万以内。</p>
<h4 id="分库"><a href="#分库" class="headerlink" title="分库"></a>分库</h4><p>分库是啥意思？就是你一个库一般我们经验而言，最多支撑到并发 2000，一定要扩容了，而且一个健康的单库并发值你最好保持在每秒 1000 左右，不要太大。那么你可以将一个库的数据拆分到多个库中，访问的时候就访问一个库好了。</p>
<p>这就是所谓的<strong>分库分表</strong>，为啥要分库分表？你明白了吧。</p>
<table>
<thead>
<tr>
<th>#</th>
<th>分库分表前</th>
<th>分库分表后</th>
</tr>
</thead>
<tbody><tr>
<td>并发支撑情况</td>
<td>MySQL 单机部署，扛不住高并发</td>
<td>MySQL从单机到多机，能承受的并发增加了多倍</td>
</tr>
<tr>
<td>磁盘使用情况</td>
<td>MySQL 单机磁盘容量几乎撑满</td>
<td>拆分为多个库，数据库服务器磁盘使用率大大降低</td>
</tr>
<tr>
<td>SQL 执行性能</td>
<td>单表数据量太大，SQL 越跑越慢</td>
<td>单表数据量减少，SQL 执行效率明显提升</td>
</tr>
</tbody></table>
<h3 id="用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？"><a href="#用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？" class="headerlink" title="用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？"></a>用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？</h3><p>这个其实就是看看你了解哪些分库分表的中间件，各个中间件的优缺点是啥？然后你用过哪些分库分表的中间件。</p>
<p>比较常见的包括：</p>
<ul>
<li>Cobar</li>
<li>TDDL</li>
<li>Atlas</li>
<li>Sharding-jdbc</li>
<li>Mycat</li>
</ul>
<h4 id="Cobar"><a href="#Cobar" class="headerlink" title="Cobar"></a>Cobar</h4><p>阿里 b2b 团队开发和开源的，属于 proxy 层方案，就是介于应用服务器和数据库服务器之间。应用程序通过 JDBC 驱动访问 Cobar 集群，Cobar 根据 SQL 和分库规则对 SQL 做分解，然后分发到 MySQL 集群不同的数据库实例上执行。早些年还可以用，但是最近几年都没更新了，基本没啥人用，差不多算是被抛弃的状态吧。而且不支持读写分离、存储过程、跨库 join 和分页等操作。</p>
<h4 id="TDDL"><a href="#TDDL" class="headerlink" title="TDDL"></a>TDDL</h4><p>淘宝团队开发的，属于 client 层方案。支持基本的 crud 语法和读写分离，但不支持 join、多表查询等语法。目前使用的也不多，因为还依赖淘宝的 diamond 配置管理系统。</p>
<h4 id="Atlas"><a href="#Atlas" class="headerlink" title="Atlas"></a>Atlas</h4><p>360 开源的，属于 proxy 层方案，以前是有一些公司在用的，但是确实有一个很大的问题就是社区最新的维护都在 5 年前了。所以，现在用的公司基本也很少了。</p>
<h4 id="Sharding-jdbc"><a href="#Sharding-jdbc" class="headerlink" title="Sharding-jdbc"></a>Sharding-jdbc</h4><p>当当开源的，属于 client 层方案，目前已经更名为 <a href="https://github.com/apache/incubator-shardingsphere" target="_blank" rel="noopener"><code>ShardingSphere</code></a>（后文所提到的 <code>Sharding-jdbc</code>，等同于 <code>ShardingSphere</code>）。确实之前用的还比较多一些，因为 SQL 语法支持也比较多，没有太多限制，而且截至 2019.4，已经推出到了 <code>4.0.0-RC1</code> 版本，支持分库分表、读写分离、分布式 id 生成、柔性事务（最大努力送达型事务、TCC 事务）。而且确实之前使用的公司会比较多一些（这个在官网有登记使用的公司，可以看到从 2017 年一直到现在，是有不少公司在用的），目前社区也还一直在开发和维护，还算是比较活跃，个人认为算是一个现在也<strong>可以选择的方案</strong>。</p>
<h4 id="Mycat"><a href="#Mycat" class="headerlink" title="Mycat"></a>Mycat</h4><p>基于 Cobar 改造的，属于 proxy 层方案，支持的功能非常完善，而且目前应该是非常火的而且不断流行的数据库中间件，社区很活跃，也有一些公司开始在用了。但是确实相比于 Sharding jdbc 来说，年轻一些，经历的锤炼少一些。</p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>综上，现在其实建议考量的，就是 Sharding-jdbc 和 Mycat，这两个都可以去考虑使用。</p>
<p>Sharding-jdbc 这种 client 层方案的<strong>优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能很高</strong>，但是如果遇到升级啥的需要各个系统都重新升级版本再发布，各个系统都需要<strong>耦合</strong> Sharding-jdbc 的依赖；</p>
<p>Mycat 这种 proxy 层方案的<strong>缺点在于需要部署</strong>，自己运维一套中间件，运维成本高，但是<strong>好处在于对于各个项目是透明的</strong>，如果遇到升级之类的都是自己中间件那里搞就行了。</p>
<p>通常来说，这两个方案其实都可以选用，但是我个人建议中小型公司选用 Sharding-jdbc，client 层方案轻便，而且维护成本低，不需要额外增派人手，而且中小型公司系统复杂度会低一些，项目也没那么多；但是中大型公司最好还是选用 Mycat 这类 proxy 层方案，因为可能大公司系统和项目非常多，团队很大，人员充足，那么最好是专门弄个人来研究和维护 Mycat，然后大量项目直接透明使用即可。</p>
<h3 id="你们具体是如何对数据库如何进行垂直拆分或水平拆分的？"><a href="#你们具体是如何对数据库如何进行垂直拆分或水平拆分的？" class="headerlink" title="你们具体是如何对数据库如何进行垂直拆分或水平拆分的？"></a>你们具体是如何对数据库如何进行垂直拆分或水平拆分的？</h3><p><strong>水平拆分</strong>的意思，就是把一个表的数据给弄到多个库的多个表里去，但是每个库的表结构都一样，只不过每个库表放的数据是不同的，所有库表的数据加起来就是全部数据。水平拆分的意义，就是将数据均匀放更多的库里，然后用多个库来扛更高的并发，还有就是用多个库的存储容量来进行扩容。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/1571663708231.png" alt="1571663708231"></p>
<p><strong>垂直拆分</strong>的意思，就是<strong>把一个有很多字段的表给拆分成多个表</strong>，<strong>或者是多个库上去</strong>。每个库表的结构都不一样，每个库表都包含部分字段。一般来说，会<strong>将较少的访问频率很高的字段放到一个表里去</strong>，然后<strong>将较多的访问频率很低的字段放到另外一个表里去</strong>。因为数据库是有缓存的，你访问频率高的行字段越少，就可以在缓存里缓存更多的行，性能就越好。这个一般在表层面做的较多一些。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/1571663735460.png" alt="1571663735460"></p>
<p>这个其实挺常见的，不一定我说，大家很多同学可能自己都做过，把一个大表拆开，订单表、订单支付表、订单商品表。</p>
<p>还有<strong>表层面的拆分</strong>，就是分表，将一个表变成 N 个表，就是<strong>让每个表的数据量控制在一定范围内</strong>，保证 SQL 的性能。否则单表数据量越大，SQL 性能就越差。一般是 200 万行左右，不要太多，但是也得看具体你怎么操作，也可能是 500 万，或者是 100 万。你的SQL越复杂，就最好让单表行数越少。</p>
<p>好了，无论分库还是分表，上面说的那些数据库中间件都是可以支持的。就是基本上那些中间件可以做到你分库分表之后，<strong>中间件可以根据你指定的某个字段值</strong>，比如说 userid，<strong>自动路由到对应的库上去，然后再自动路由到对应的表里去</strong>。</p>
<p>你就得考虑一下，你的项目里该如何分库分表？一般来说，垂直拆分，你可以在表层面来做，对一些字段特别多的表做一下拆分；水平拆分，你可以说是并发承载不了，或者是数据量太大，容量承载不了，你给拆了，按什么字段来拆，你自己想好；分表，你考虑一下，你如果哪怕是拆到每个库里去，并发和容量都 ok 了，但是每个库的表还是太大了，那么你就分表，将这个表分开，保证每个表的数据量并不是很大。</p>
<p>而且这儿还有两种<strong>分库分表的方式</strong>：</p>
<ul>
<li>一种是按照 range 来分，就是每个库一段连续的数据，这个一般是按比如<strong>时间范围</strong>来的，但是这种一般较少用，因为很容易产生热点问题，大量的流量都打在最新的数据上了。</li>
<li>或者是按照某个字段 hash 一下均匀分散，这个较为常用。</li>
</ul>
<p>range 来分，好处在于说，扩容的时候很简单，因为你只要预备好，给每个月都准备一个库就可以了，到了一个新的月份的时候，自然而然，就会写新的库了；缺点，但是大部分的请求，都是访问最新的数据。实际生产用 range，要看场景。</p>
<p>hash 分发，好处在于说，可以平均分配每个库的数据量和请求压力；坏处在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表。</p>
<h2 id="面试题-1"><a href="#面试题-1" class="headerlink" title="面试题"></a>面试题</h2><p>如何设计可以动态扩容缩容的分库分表方案？</p>
<h2 id="面试官心理分析-1"><a href="#面试官心理分析-1" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>对于分库分表来说，主要是面对以下问题：</p>
<ul>
<li>选择一个数据库中间件，调研、学习、测试；</li>
<li>设计你的分库分表的一个方案，你要分成多少个库，每个库分成多少个表，比如 3 个库，每个库 4 个表；</li>
<li>基于选择好的数据库中间件，以及在测试环境建立好的分库分表的环境，然后测试一下能否正常进行分库分表的读写；</li>
<li>完成单库单表到分库分表的<strong>迁移</strong>，双写方案；</li>
<li>线上系统开始基于分库分表对外提供服务；</li>
<li>扩容了，扩容成 6 个库，每个库需要 12 个表，你怎么来增加更多库和表呢？</li>
</ul>
<p>这个是你必须面对的一个事儿，就是你已经弄好分库分表方案了，然后一堆库和表都建好了，基于分库分表中间件的代码开发啥的都好了，测试都 ok 了，数据能均匀分布到各个库和各个表里去，而且接着你还通过双写的方案咔嚓一下上了系统，已经直接基于分库分表方案在搞了。</p>
<p>那么现在问题来了，你现在这些库和表又支撑不住了，要继续扩容咋办？这个可能就是说你的每个库的容量又快满了，或者是你的表数据量又太大了，也可能是你每个库的写并发太高了，你得继续扩容。</p>
<p>这都是玩儿分库分表线上必须经历的事儿。</p>
<h2 id="面试题剖析-1"><a href="#面试题剖析-1" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="停机扩容（不推荐）"><a href="#停机扩容（不推荐）" class="headerlink" title="停机扩容（不推荐）"></a>停机扩容（不推荐）</h3><p>这个方案就跟停机迁移一样，步骤几乎一致，唯一的一点就是那个导数的工具，是把现有库表的数据抽出来慢慢倒入到新的库和表里去。但是最好别这么玩儿，有点不太靠谱，因为既然<strong>分库分表</strong>就说明数据量实在是太大了，可能多达几亿条，甚至几十亿，你这么玩儿，可能会出问题。</p>
<p>从单库单表迁移到分库分表的时候，数据量并不是很大，单表最大也就两三千万。那么你写个工具，多弄几台机器并行跑，1小时数据就导完了。这没有问题。</p>
<p>如果 3 个库 + 12 个表，跑了一段时间了，数据量都 1~2 亿了。光是导 2 亿数据，都要导个几个小时，6 点，刚刚导完数据，还要搞后续的修改配置，重启系统，测试验证，10 点才可以搞完。所以不能这么搞。</p>
<h3 id="优化后的方案"><a href="#优化后的方案" class="headerlink" title="优化后的方案"></a>优化后的方案</h3><p>一开始上来就是 32 个库，每个库 32 个表，那么总共是 1024 张表。</p>
<p>我可以告诉各位同学，这个分法，第一，基本上国内的互联网肯定都是够用了，第二，无论是并发支撑还是数据量支撑都没问题。</p>
<p>每个库正常承载的写入并发量是 1000，那么 32 个库就可以承载 32 * 1000 = 32000 的写并发，如果每个库承载 1500 的写并发，32 * 1500 = 48000 的写并发，接近 5 万每秒的写入并发，前面再加一个MQ，削峰，每秒写入 MQ 8 万条数据，每秒消费 5 万条数据。</p>
<p>有些除非是国内排名非常靠前的这些公司，他们的最核心的系统的数据库，可能会出现几百台数据库的这么一个规模，128 个库，256 个库，512 个库。</p>
<p>1024 张表，假设每个表放 500 万数据，在 MySQL 里可以放 50 亿条数据。</p>
<p>每秒 5 万的写并发，总共 50 亿条数据，对于国内大部分的互联网公司来说，其实一般来说都够了。</p>
<p>谈分库分表的扩容，<strong>第一次分库分表，就一次性给他分个够</strong>，32 个库，1024 张表，可能对大部分的中小型互联网公司来说，已经可以支撑好几年了。</p>
<p>一个实践是利用 <code>32 * 32</code> 来分库分表，即分为 32 个库，每个库里一个表分为 32 张表。一共就是 1024 张表。根据某个 id 先根据 32 取模路由到库，再根据 32 取模路由到库里的表。</p>
<table>
<thead>
<tr>
<th>orderId</th>
<th>id % 32 (库)</th>
<th>id / 32 % 32 (表)</th>
</tr>
</thead>
<tbody><tr>
<td>259</td>
<td>3</td>
<td>8</td>
</tr>
<tr>
<td>1189</td>
<td>5</td>
<td>5</td>
</tr>
<tr>
<td>352</td>
<td>0</td>
<td>11</td>
</tr>
<tr>
<td>4593</td>
<td>17</td>
<td>15</td>
</tr>
</tbody></table>
<p>刚开始的时候，这个库可能就是逻辑库，建在一个数据库上的，就是一个 mysql 服务器可能建了 n 个库，比如 32 个库。后面如果要拆分，就是不断在库和 mysql 服务器之间做迁移就可以了。然后系统配合改一下配置即可。</p>
<p>比如说最多可以扩展到 32 个数据库服务器，每个数据库服务器是一个库。如果还是不够？最多可以扩展到 1024 个数据库服务器，每个数据库服务器上面一个库一个表。因为最多是 1024 个表。</p>
<p>这么搞，是不用自己写代码做数据迁移的，都交给 dba 来搞好了，但是 dba 确实是需要做一些库表迁移的工作，但是总比你自己写代码，然后抽数据导数据来的效率高得多吧。</p>
<p>哪怕是要减少库的数量，也很简单，其实说白了就是按倍数缩容就可以了，然后修改一下路由规则。</p>
<p>这里对步骤做一个总结：</p>
<ol>
<li>设定好几台数据库服务器，每台服务器上几个库，每个库多少个表，推荐是 32 库 * 32 表，对于大部分公司来说，可能几年都够了。</li>
<li>路由的规则，orderId 模 32 = 库，orderId / 32 模 32 = 表</li>
<li>扩容的时候，申请增加更多的数据库服务器，装好 mysql，呈倍数扩容，4 台服务器，扩到 8 台服务器，再到 16 台服务器。</li>
<li>由 dba 负责将原先数据库服务器的库，迁移到新的数据库服务器上去，库迁移是有一些便捷的工具的。</li>
<li>我们这边就是修改一下配置，调整迁移的库所在数据库服务器的地址。</li>
<li>重新发布系统，上线，原先的路由规则变都不用变，直接可以基于 n 倍的数据库服务器的资源，继续进行线上系统的提供服务。</li>
</ol>
<h2 id="面试题-2"><a href="#面试题-2" class="headerlink" title="面试题"></a>面试题</h2><p>分库分表之后，id 主键如何处理？</p>
<h2 id="面试官心理分析-2"><a href="#面试官心理分析-2" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>其实这是分库分表之后你必然要面对的一个问题，就是 id 咋生成？因为要是分成多个表之后，每个表都是从 1 开始累加，那肯定不对啊，需要一个<strong>全局唯一</strong>的 id 来支持。所以这都是你实际生产环境中必须考虑的问题。</p>
<h2 id="面试题剖析-2"><a href="#面试题剖析-2" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="基于数据库的实现方案"><a href="#基于数据库的实现方案" class="headerlink" title="基于数据库的实现方案"></a>基于数据库的实现方案</h3><h4 id="数据库自增-id"><a href="#数据库自增-id" class="headerlink" title="数据库自增 id"></a>数据库自增 id</h4><p>这个就是说你的系统里每次得到一个 id，都是往一个库的一个表里插入一条没什么业务含义的数据，然后获取一个数据库自增的一个 id。拿到这个 id 之后再往对应的分库分表里去写入。</p>
<p>这个方案的好处就是方便简单，谁都会用；<strong>缺点就是单库生成</strong>自增 id，要是高并发的话，就会有瓶颈的；如果你硬是要改进一下，那么就专门开一个服务出来，这个服务每次就拿到当前 id 最大值，然后自己递增几个 id，一次性返回一批 id，然后再把当前最大 id 值修改成递增几个 id 之后的一个值；但是<strong>无论如何都是基于单个数据库</strong>。</p>
<p><strong>适合的场景</strong>：你分库分表就俩原因，要不就是单库并发太高，要不就是单库数据量太大；除非是你<strong>并发不高，但是数据量太大</strong>导致的分库分表扩容，你可以用这个方案，因为可能每秒最高并发最多就几百，那么就走单独的一个库和表生成自增主键即可。</p>
<h4 id="设置数据库-sequence-或者表自增字段步长"><a href="#设置数据库-sequence-或者表自增字段步长" class="headerlink" title="设置数据库 sequence 或者表自增字段步长"></a>设置数据库 sequence 或者表自增字段步长</h4><p>可以通过设置数据库 sequence 或者表的自增字段步长来进行水平伸缩。</p>
<p>比如说，现在有 8 个服务节点，每个服务节点使用一个 sequence 功能来产生 ID，每个 sequence 的起始 ID 不同，并且依次递增，步长都是 8。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/1571663912457.png" alt="1571663912457"></p>
<p><strong>适合的场景</strong>：在用户防止产生的 ID 重复时，这种方案实现起来比较简单，也能达到性能目标。但是服务节点固定，步长也固定，将来如果还要增加服务节点，就不好搞了。</p>
<h3 id="UUID"><a href="#UUID" class="headerlink" title="UUID"></a>UUID</h3><p>好处就是本地生成，不要基于数据库来了；不好之处就是，UUID 太长了、占用空间大，<strong>作为主键性能太差</strong>了；更重要的是，UUID 不具有有序性，会导致 B+ 树索引在写的时候有过多的随机写操作（连续的 ID 可以产生部分顺序写），还有，由于在写的时候不能产生有顺序的 append 操作，而需要进行 insert 操作，将会读取整个 B+ 树节点到内存，在插入这条记录后会将整个节点写回磁盘，这种操作在记录占用空间比较大的情况下，性能下降明显。</p>
<p>适合的场景：如果你是要随机生成个什么文件名、编号之类的，你可以用 UUID，但是作为主键是不能用 UUID 的。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UUID.randomUUID().toString().replace(“-”, “”) -&gt; sfsdf23423rr234sfdaf</span><br></pre></td></tr></table></figure>

<h3 id="获取系统当前时间"><a href="#获取系统当前时间" class="headerlink" title="获取系统当前时间"></a>获取系统当前时间</h3><p>这个就是获取当前时间即可，但是问题是，<strong>并发很高的时候</strong>，比如一秒并发几千，<strong>会有重复的情况</strong>，这个是肯定不合适的。基本就不用考虑了。</p>
<p>适合的场景：一般如果用这个方案，是将当前时间跟很多其他的业务字段拼接起来，作为一个 id，如果业务上你觉得可以接受，那么也是可以的。你可以将别的业务字段值跟当前时间拼接起来，组成一个全局唯一的编号。</p>
<h3 id="snowflake-算法"><a href="#snowflake-算法" class="headerlink" title="snowflake 算法"></a>snowflake 算法</h3><p>snowflake 算法是 twitter 开源的分布式 id 生成算法，采用 Scala 语言实现，是把一个 64 位的 long 型的 id，1 个 bit 是不用的，用其中的 41 bit 作为毫秒数，用 10 bit 作为工作机器 id，12 bit 作为序列号。</p>
<ul>
<li>1 bit：不用，为啥呢？因为二进制里第一个 bit 为如果是 1，那么都是负数，但是我们生成的 id 都是正数，所以第一个 bit 统一都是 0。</li>
<li>41 bit：表示的是时间戳，单位是毫秒。41 bit 可以表示的数字多达 <code>2^41 - 1</code>，也就是可以标识 <code>2^41 - 1</code> 个毫秒值，换算成年就是表示69年的时间。</li>
<li>10 bit：记录工作机器 id，代表的是这个服务最多可以部署在 2^10台机器上哪，也就是1024台机器。但是 10 bit 里 5 个 bit 代表机房 id，5 个 bit 代表机器 id。意思就是最多代表 <code>2^5</code>个机房（32个机房），每个机房里可以代表 <code>2^5</code> 个机器（32台机器）。</li>
<li>12 bit：这个是用来记录同一个毫秒内产生的不同 id，12 bit 可以代表的最大正整数是 <code>2^12 - 1 = 4096</code>，也就是说可以用这个 12 bit 代表的数字来区分<strong>同一个毫秒内</strong>的 4096 个不同的 id。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0 | 0001100 10100010 10111110 10001001 01011100 00 | 10001 | 1 1001 | 0000 00000000</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">IdWorker</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> workerId;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> datacenterId;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> sequence;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">IdWorker</span><span class="params">(<span class="keyword">long</span> workerId, <span class="keyword">long</span> datacenterId, <span class="keyword">long</span> sequence)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// sanity check for workerId</span></span><br><span class="line">        <span class="comment">// 这儿不就检查了一下，要求就是你传递进来的机房id和机器id不能超过32，不能小于0</span></span><br><span class="line">        <span class="keyword">if</span> (workerId &gt; maxWorkerId || workerId &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(</span><br><span class="line">                    String.format(<span class="string">"worker Id can't be greater than %d or less than 0"</span>, maxWorkerId));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (datacenterId &gt; maxDatacenterId || datacenterId &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(</span><br><span class="line">                    String.format(<span class="string">"datacenter Id can't be greater than %d or less than 0"</span>, maxDatacenterId));</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.printf(</span><br><span class="line">                <span class="string">"worker starting. timestamp left shift %d, datacenter id bits %d, worker id bits %d, sequence bits %d, workerid %d"</span>,</span><br><span class="line">                timestampLeftShift, datacenterIdBits, workerIdBits, sequenceBits, workerId);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">this</span>.workerId = workerId;</span><br><span class="line">        <span class="keyword">this</span>.datacenterId = datacenterId;</span><br><span class="line">        <span class="keyword">this</span>.sequence = sequence;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> twepoch = <span class="number">1288834974657L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> workerIdBits = <span class="number">5L</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> datacenterIdBits = <span class="number">5L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 这个是二进制运算，就是 5 bit最多只能有31个数字，也就是说机器id最多只能是32以内</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> maxWorkerId = -<span class="number">1L</span> ^ (-<span class="number">1L</span> &lt;&lt; workerIdBits);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 这个是一个意思，就是 5 bit最多只能有31个数字，机房id最多只能是32以内</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> maxDatacenterId = -<span class="number">1L</span> ^ (-<span class="number">1L</span> &lt;&lt; datacenterIdBits);</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> sequenceBits = <span class="number">12L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> workerIdShift = sequenceBits;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> datacenterIdShift = sequenceBits + workerIdBits;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> sequenceMask = -<span class="number">1L</span> ^ (-<span class="number">1L</span> &lt;&lt; sequenceBits);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> lastTimestamp = -<span class="number">1L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getWorkerId</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> workerId;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getDatacenterId</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> datacenterId;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getTimestamp</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> System.currentTimeMillis();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">long</span> <span class="title">nextId</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 这儿就是获取当前时间戳，单位是毫秒</span></span><br><span class="line">        <span class="keyword">long</span> timestamp = timeGen();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (timestamp &lt; lastTimestamp) &#123;</span><br><span class="line">            System.err.printf(<span class="string">"clock is moving backwards.  Rejecting requests until %d."</span>, lastTimestamp);</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(String.format(</span><br><span class="line">                    <span class="string">"Clock moved backwards.  Refusing to generate id for %d milliseconds"</span>, lastTimestamp - timestamp));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (lastTimestamp == timestamp) &#123;</span><br><span class="line">            <span class="comment">// 这个意思是说一个毫秒内最多只能有4096个数字</span></span><br><span class="line">            <span class="comment">// 无论你传递多少进来，这个位运算保证始终就是在4096这个范围内，避免你自己传递个sequence超过了4096这个范围</span></span><br><span class="line">            sequence = (sequence + <span class="number">1</span>) &amp; sequenceMask;</span><br><span class="line">            <span class="keyword">if</span> (sequence == <span class="number">0</span>) &#123;</span><br><span class="line">                timestamp = tilNextMillis(lastTimestamp);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            sequence = <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 这儿记录一下最近一次生成id的时间戳，单位是毫秒</span></span><br><span class="line">        lastTimestamp = timestamp;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 这儿就是将时间戳左移，放到 41 bit那儿；</span></span><br><span class="line">        <span class="comment">// 将机房 id左移放到 5 bit那儿；</span></span><br><span class="line">        <span class="comment">// 将机器id左移放到5 bit那儿；将序号放最后12 bit；</span></span><br><span class="line">        <span class="comment">// 最后拼接起来成一个 64 bit的二进制数字，转换成 10 进制就是个 long 型</span></span><br><span class="line">        <span class="keyword">return</span> ((timestamp - twepoch) &lt;&lt; timestampLeftShift) | (datacenterId &lt;&lt; datacenterIdShift)</span><br><span class="line">                | (workerId &lt;&lt; workerIdShift) | sequence;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">long</span> <span class="title">tilNextMillis</span><span class="params">(<span class="keyword">long</span> lastTimestamp)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> timestamp = timeGen();</span><br><span class="line">        <span class="keyword">while</span> (timestamp &lt;= lastTimestamp) &#123;</span><br><span class="line">            timestamp = timeGen();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> timestamp;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">long</span> <span class="title">timeGen</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> System.currentTimeMillis();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ---------------测试---------------</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        IdWorker worker = <span class="keyword">new</span> IdWorker(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">30</span>; i++) &#123;</span><br><span class="line">            System.out.println(worker.nextId());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>怎么说呢，大概这个意思吧，就是说 41 bit 是当前毫秒单位的一个时间戳，就这意思；然后 5 bit 是你传递进来的一个<strong>机房</strong> id（但是最大只能是 32 以内），另外 5 bit 是你传递进来的<strong>机器</strong> id（但是最大只能是 32 以内），剩下的那个 12 bit序列号，就是如果跟你上次生成 id 的时间还在一个毫秒内，那么会把顺序给你累加，最多在 4096 个序号以内。</p>
<p>所以你自己利用这个工具类，自己搞一个服务，然后对每个机房的每个机器都初始化这么一个东西，刚开始这个机房的这个机器的序号就是 0。然后每次接收到一个请求，说这个机房的这个机器要生成一个 id，你就找到对应的 Worker 生成。</p>
<p>利用这个 snowflake 算法，你可以开发自己公司的服务，甚至对于机房 id 和机器 id，反正给你预留了 5 bit + 5 bit，你换成别的有业务含义的东西也可以的。</p>
<p>这个 snowflake 算法相对来说还是比较靠谱的，所以你要真是搞分布式 id 生成，如果是高并发啥的，那么用这个应该性能比较好，一般每秒几万并发的场景，也足够你用了。</p>
<h2 id="面试题-3"><a href="#面试题-3" class="headerlink" title="面试题"></a>面试题</h2><p>现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表<strong>动态切换</strong>到分库分表上？</p>
<h2 id="面试官心理分析-3"><a href="#面试官心理分析-3" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>你看看，你现在已经明白为啥要分库分表了，你也知道常用的分库分表中间件了，你也设计好你们如何分库分表的方案了（水平拆分、垂直拆分、分表），那问题来了，你接下来该怎么把你那个单库单表的系统给迁移到分库分表上去？</p>
<p>所以这都是一环扣一环的，就是看你有没有全流程经历过这个过程。</p>
<h2 id="面试题剖析-3"><a href="#面试题剖析-3" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>这个其实从 low 到高大上有好几种方案，我们都玩儿过，我都给你说一下。</p>
<h3 id="停机迁移方案"><a href="#停机迁移方案" class="headerlink" title="停机迁移方案"></a>停机迁移方案</h3><p>我先给你说一个最 low 的方案，就是很简单，大家伙儿凌晨 12 点开始运维，网站或者 app 挂个公告，说 0 点到早上 6 点进行运维，无法访问。</p>
<p>接着到 0 点停机，系统停掉，没有流量写入了，此时老的单库单表数据库静止了。然后你之前得写好一个<strong>导数的一次性工具</strong>，此时直接跑起来，然后将单库单表的数据哗哗哗读出来，写到分库分表里面去。</p>
<p>导数完了之后，就 ok 了，修改系统的数据库连接配置啥的，包括可能代码和 SQL 也许有修改，那你就用最新的代码，然后直接启动连到新的分库分表上去。</p>
<p>验证一下，ok了，完美，大家伸个懒腰，看看看凌晨 4 点钟的北京夜景，打个滴滴回家吧。</p>
<p>但是这个方案比较 low，谁都能干，我们来看看高大上一点的方案。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/database-shard-method-1.png" alt="database-shard-method-1"></p>
<h3 id="双写迁移方案"><a href="#双写迁移方案" class="headerlink" title="双写迁移方案"></a>双写迁移方案</h3><p>这个是我们常用的一种迁移方案，比较靠谱一些，不用停机，不用看北京凌晨 4 点的风景。</p>
<p>简单来说，就是在线上系统里面，之前所有写库的地方，增删改操作，<strong>除了对老库增删改，都加上对新库的增删改</strong>，这就是所谓的<strong>双写</strong>，同时写俩库，老库和新库。</p>
<p>然后<strong>系统部署</strong>之后，新库数据差太远，用之前说的导数工具，跑起来读老库数据写新库，写的时候要根据 gmt_modified 这类字段判断这条数据最后修改的时间，除非是读出来的数据在新库里没有，或者是比新库的数据新才会写。简单来说，就是不允许用老数据覆盖新数据。</p>
<p>导完一轮之后，有可能数据还是存在不一致，那么就程序自动做一轮校验，比对新老库每个表的每条数据，接着如果有不一样的，就针对那些不一样的，从老库读数据再次写。反复循环，直到两个库每个表的数据都完全一致为止。</p>
<p>接着当数据完全一致了，就 ok 了，基于仅仅使用分库分表的最新代码，重新部署一次，不就仅仅基于分库分表在操作了么，还没有几个小时的停机时间，很稳。所以现在基本玩儿数据迁移之类的，都是这么干的。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/database-shard-method-2.png" alt="database-shard-method-2"></p>
<h2 id="lucene-和-es-的前世今生"><a href="#lucene-和-es-的前世今生" class="headerlink" title="lucene 和 es 的前世今生"></a>lucene 和 es 的前世今生</h2><p>lucene 是最先进、功能最强大的搜索库。如果直接基于 lucene 开发，非常复杂，即便写一些简单的功能，也要写大量的 Java 代码，需要深入理解原理。</p>
<p>elasticsearch 基于 lucene，隐藏了 lucene 的复杂性，提供了简单易用的 restful api / Java api 接口（另外还有其他语言的 api 接口）。</p>
<ul>
<li>分布式的文档存储引擎</li>
<li>分布式的搜索引擎和分析引擎</li>
<li>分布式，支持 PB 级数据</li>
</ul>
<h2 id="es-的核心概念"><a href="#es-的核心概念" class="headerlink" title="es 的核心概念"></a>es 的核心概念</h2><h3 id="Near-Realtime"><a href="#Near-Realtime" class="headerlink" title="Near Realtime"></a>Near Realtime</h3><p>近实时，有两层意思：</p>
<ul>
<li>从写入数据到数据可以被搜索到有一个小延迟（大概是 1s）</li>
<li>基于 es 执行搜索和分析可以达到秒级</li>
</ul>
<h3 id="Cluster-集群"><a href="#Cluster-集群" class="headerlink" title="Cluster 集群"></a>Cluster 集群</h3><p>集群包含多个节点，每个节点属于哪个集群都是通过一个配置来决定的，对于中小型应用来说，刚开始一个集群就一个节点很正常。</p>
<h3 id="Node-节点"><a href="#Node-节点" class="headerlink" title="Node 节点"></a>Node 节点</h3><p>Node 是集群中的一个节点，节点也有一个名称，默认是随机分配的。默认节点会去加入一个名称为 <code>elasticsearch</code> 的集群。如果直接启动一堆节点，那么它们会自动组成一个 elasticsearch 集群，当然一个节点也可以组成 elasticsearch 集群。</p>
<h3 id="Document-amp-field"><a href="#Document-amp-field" class="headerlink" title="Document &amp; field"></a>Document &amp; field</h3><p>文档是 es 中最小的数据单元，一个 document 可以是一条客户数据、一条商品分类数据、一条订单数据，通常用 json 数据结构来表示。每个 index 下的 type，都可以存储多条 document。一个 document 里面有多个 field，每个 field 就是一个数据字段。</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"product_id"</span>: <span class="string">"1"</span>,</span><br><span class="line">    <span class="attr">"product_name"</span>: <span class="string">"iPhone X"</span>,</span><br><span class="line">    <span class="attr">"product_desc"</span>: <span class="string">"苹果手机"</span>,</span><br><span class="line">    <span class="attr">"category_id"</span>: <span class="string">"2"</span>,</span><br><span class="line">    <span class="attr">"category_name"</span>: <span class="string">"电子产品"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Index"><a href="#Index" class="headerlink" title="Index"></a>Index</h3><p>索引包含了一堆有相似结构的文档数据，比如商品索引。一个索引包含很多 document，一个索引就代表了一类相似或者相同的 ducument。</p>
<h3 id="Type"><a href="#Type" class="headerlink" title="Type"></a>Type</h3><p>类型，每个索引里可以有一个或者多个 type，type 是 index 的一个逻辑分类，比如商品 index 下有多个 type：日化商品 type、电器商品 type、生鲜商品 type。每个 type 下的 document 的 field 可能不太一样。</p>
<h3 id="shard"><a href="#shard" class="headerlink" title="shard"></a>shard</h3><p>单台机器无法存储大量数据，es 可以将一个索引中的数据切分为多个 shard，分布在多台服务器上存储。有了 shard 就可以横向扩展，存储更多数据，让搜索和分析等操作分布到多台服务器上去执行，提升吞吐量和性能。每个 shard 都是一个 lucene index。</p>
<h3 id="replica"><a href="#replica" class="headerlink" title="replica"></a>replica</h3><p>任何一个服务器随时可能故障或宕机，此时 shard 可能就会丢失，因此可以为每个 shard 创建多个 replica 副本。replica 可以在 shard 故障时提供备用服务，保证数据不丢失，多个 replica 还可以提升搜索操作的吞吐量和性能。primary shard（建立索引时一次设置，不能修改，默认 5 个），replica shard（随时修改数量，默认 1 个），默认每个索引 10 个 shard，5 个 primary shard，5个 replica shard，最小的高可用配置，是 2 台服务器。</p>
<p>这么说吧，shard 分为 primary shard 和 replica shard。而 primary shard 一般简称为 shard，而 replica shard 一般简称为 replica。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/es-cluster-0.png" alt="es-cluster-0"></p>
<h2 id="es-核心概念-vs-db-核心概念"><a href="#es-核心概念-vs-db-核心概念" class="headerlink" title="es 核心概念 vs. db 核心概念"></a>es 核心概念 vs. db 核心概念</h2><table>
<thead>
<tr>
<th>es</th>
<th>db</th>
</tr>
</thead>
<tbody><tr>
<td>index</td>
<td>数据库</td>
</tr>
<tr>
<td>type</td>
<td>数据表</td>
</tr>
<tr>
<td>docuemnt</td>
<td>一行数据</td>
</tr>
</tbody></table>
<p>以上是一个简单的类比。</p>
<h2 id="面试题-4"><a href="#面试题-4" class="headerlink" title="面试题"></a>面试题</h2><p>es 的分布式架构原理能说一下么（es 是如何实现分布式的啊）？</p>
<h2 id="面试官心理分析-4"><a href="#面试官心理分析-4" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>在搜索这块，lucene 是最流行的搜索库。几年前业内一般都问，你了解 lucene 吗？你知道倒排索引的原理吗？现在早已经 out 了，因为现在很多项目都是直接用基于 lucene 的分布式搜索引擎—— ElasticSearch，简称为 es。</p>
<p>而现在分布式搜索基本已经成为大部分互联网行业的 Java 系统的标配，其中尤为流行的就是 es，前几年 es 没火的时候，大家一般用 solr。但是这两年基本大部分企业和项目都开始转向 es 了。</p>
<p>所以互联网面试，肯定会跟你聊聊分布式搜索引擎，也就一定会聊聊 es，如果你确实不知道，那你真的就 out 了。</p>
<p>如果面试官问你第一个问题，确实一般都会问你 es 的分布式架构设计能介绍一下么？就看看你对分布式搜索引擎架构的一个基本理解。</p>
<h2 id="面试题剖析-4"><a href="#面试题剖析-4" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>ElasticSearch 设计的理念就是分布式搜索引擎，底层其实还是基于 lucene 的。核心思想就是在多台机器上启动多个 es 进程实例，组成了一个 es 集群。</p>
<p>es 中存储数据的<strong>基本单位是索引</strong>，比如说你现在要在 es 中存储一些订单数据，你就应该在 es 中创建一个索引 <code>order_idx</code>，所有的订单数据就都写到这个索引里面去，一个索引差不多就是相当于是 mysql 里的一张表。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">index -&gt; type -&gt; mapping -&gt; document -&gt; field。</span><br></pre></td></tr></table></figure>

<p>这样吧，为了做个更直白的介绍，我在这里做个类比。但是切记，不要划等号，类比只是为了便于理解。</p>
<p>index 相当于 mysql 里的一张表。而 type 没法跟 mysql 里去对比，一个 index 里可以有多个 type，每个 type 的字段都是差不多的，但是有一些略微的差别。假设有一个 index，是订单 index，里面专门是放订单数据的。就好比说你在 mysql 中建表，有些订单是实物商品的订单，比如一件衣服、一双鞋子；有些订单是虚拟商品的订单，比如游戏点卡，话费充值。就两种订单大部分字段是一样的，但是少部分字段可能有略微的一些差别。</p>
<p>所以就会在订单 index 里，建两个 type，一个是实物商品订单 type，一个是虚拟商品订单 type，这两个 type 大部分字段是一样的，少部分字段是不一样的。</p>
<p>很多情况下，一个 index 里可能就一个 type，但是确实如果说是一个 index 里有多个 type 的情况（<strong>注意</strong>，<code>mapping types</code> 这个概念在 ElasticSearch 7.X 已被完全移除，详细说明可以参考<a href="https://github.com/elastic/elasticsearch/blob/6.5/docs/reference/mapping/removal_of_types.asciidoc" target="_blank" rel="noopener">官方文档</a>），你可以认为 index 是一个类别的表，具体的每个 type 代表了 mysql 中的一个表。每个 type 有一个 mapping，如果你认为一个 type 是具体的一个表，index 就代表多个 type 同属于的一个类型，而 mapping 就是这个 type 的<strong>表结构定义</strong>，你在 mysql 中创建一个表，肯定是要定义表结构的，里面有哪些字段，每个字段是什么类型。实际上你往 index 里的一个 type 里面写的一条数据，叫做一条 document，一条 document 就代表了 mysql 中某个表里的一行，每个 document 有多个 field，每个 field 就代表了这个 document 中的一个字段的值。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/es-index-type-mapping-document-field.png" alt="es-index-type-mapping-document-field"></p>
<p>你搞一个索引，这个索引可以拆分成多个 <code>shard</code>，每个 shard 存储部分数据。拆分多个 shard 是有好处的，一是<strong>支持横向扩展</strong>，比如你数据量是 3T，3 个 shard，每个 shard 就 1T 的数据，若现在数据量增加到 4T，怎么扩展，很简单，重新建一个有 4 个 shard 的索引，将数据导进去；二是<strong>提高性能</strong>，数据分布在多个 shard，即多台服务器上，所有的操作，都会在多台机器上并行分布式执行，提高了吞吐量和性能。</p>
<p>接着就是这个 shard 的数据实际是有多个备份，就是说每个 shard 都有一个 <code>primary shard</code>，负责写入数据，但是还有几个 <code>replica shard</code>。<code>primary shard</code> 写入数据之后，会将数据同步到其他几个 <code>replica shard</code> 上去。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/es-cluster.png" alt="es-cluster"></p>
<p>通过这个 replica 的方案，每个 shard 的数据都有多个备份，如果某个机器宕机了，没关系啊，还有别的数据副本在别的机器上呢。高可用了吧。</p>
<p>es 集群多个节点，会自动选举一个节点为 master 节点，这个 master 节点其实就是干一些管理的工作的，比如维护索引元数据、负责切换 primary shard 和 replica shard 身份等。要是 master 节点宕机了，那么会重新选举一个节点为 master 节点。</p>
<p>如果是非 master节点宕机了，那么会由 master 节点，让那个宕机节点上的 primary shard 的身份转移到其他机器上的 replica shard。接着你要是修复了那个宕机机器，重启了之后，master 节点会控制将缺失的 replica shard 分配过去，同步后续修改的数据之类的，让集群恢复正常。</p>
<p>说得更简单一点，就是说如果某个非 master 节点宕机了。那么此节点上的 primary shard 不就没了。那好，master 会让 primary shard 对应的 replica shard（在其他机器上）切换为 primary shard。如果宕机的机器修复了，修复后的节点也不再是 primary shard，而是 replica shard。</p>
<p>其实上述就是 ElasticSearch 作为分布式搜索引擎最基本的一个架构设计。</p>
<h2 id="面试题-5"><a href="#面试题-5" class="headerlink" title="面试题"></a>面试题</h2><p>es 在数据量很大的情况下（数十亿级别）如何提高查询效率啊？</p>
<h2 id="面试官心理分析-5"><a href="#面试官心理分析-5" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>这个问题是肯定要问的，说白了，就是看你有没有实际干过 es，因为啥？其实 es 性能并没有你想象中那么好的。很多时候数据量大了，特别是有几亿条数据的时候，可能你会懵逼的发现，跑个搜索怎么一下 <code>5~10s</code>，坑爹了。第一次搜索的时候，是  <code>5~10s</code>，后面反而就快了，可能就几百毫秒。</p>
<p>你就很懵，每个用户第一次访问都会比较慢，比较卡么？所以你要是没玩儿过 es，或者就是自己玩玩儿 demo，被问到这个问题容易懵逼，显示出你对 es 确实玩儿的不怎么样？</p>
<h2 id="面试题剖析-5"><a href="#面试题剖析-5" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>说实话，es 性能优化是没有什么银弹的，啥意思呢？就是<strong>不要期待着随手调一个参数，就可以万能的应对所有的性能慢的场景</strong>。也许有的场景是你换个参数，或者调整一下语法，就可以搞定，但是绝对不是所有场景都可以这样。</p>
<h3 id="性能优化的杀手锏——filesystem-cache"><a href="#性能优化的杀手锏——filesystem-cache" class="headerlink" title="性能优化的杀手锏——filesystem cache"></a>性能优化的杀手锏——filesystem cache</h3><p>你往 es 里写的数据，实际上都写到磁盘文件里去了，<strong>查询的时候</strong>，操作系统会将磁盘文件里的数据自动缓存到 <code>filesystem cache</code> 里面去。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/es-search-process.png" alt="es-search-process"></p>
<p>es 的搜索引擎严重依赖于底层的 <code>filesystem cache</code>，你如果给 <code>filesystem cache</code> 更多的内存，尽量让内存可以容纳所有的 <code>idx segment file</code> 索引数据文件，那么你搜索的时候就基本都是走内存的，性能会非常高。</p>
<p>性能差距究竟可以有多大？我们之前很多的测试和压测，如果走磁盘一般肯定上秒，搜索性能绝对是秒级别的，1秒、5秒、10秒。但如果是走 <code>filesystem cache</code>，是走纯内存的，那么一般来说性能比走磁盘要高一个数量级，基本上就是毫秒级的，从几毫秒到几百毫秒不等。</p>
<p>这里有个真实的案例。某个公司 es 节点有 3 台机器，每台机器看起来内存很多，64G，总内存就是 <code>64 * 3 = 192G</code>。每台机器给 es jvm heap 是 <code>32G</code>，那么剩下来留给 <code>filesystem cache</code> 的就是每台机器才 <code>32G</code>，总共集群里给 <code>filesystem cache</code> 的就是 <code>32 * 3 = 96G</code> 内存。而此时，整个磁盘上索引数据文件，在 3 台机器上一共占用了 <code>1T</code> 的磁盘容量，es 数据量是 <code>1T</code>，那么每台机器的数据量是 <code>300G</code>。这样性能好吗？ <code>filesystem cache</code> 的内存才 100G，十分之一的数据可以放内存，其他的都在磁盘，然后你执行搜索操作，大部分操作都是走磁盘，性能肯定差。</p>
<p>归根结底，你要让 es 性能要好，最佳的情况下，就是你的机器的内存，至少可以容纳你的总数据量的一半。</p>
<p>根据我们自己的生产环境实践经验，最佳的情况下，是仅仅在 es 中就存少量的数据，就是你要<strong>用来搜索的那些索引</strong>，如果内存留给 <code>filesystem cache</code> 的是 100G，那么你就将索引数据控制在 <code>100G</code> 以内，这样的话，你的数据几乎全部走内存来搜索，性能非常之高，一般可以在 1 秒以内。</p>
<p>比如说你现在有一行数据。<code>id,name,age ....</code> 30 个字段。但是你现在搜索，只需要根据 <code>id,name,age</code> 三个字段来搜索。如果你傻乎乎往 es 里写入一行数据所有的字段，就会导致说 <code>90%</code> 的数据是不用来搜索的，结果硬是占据了 es 机器上的 <code>filesystem cache</code> 的空间，单条数据的数据量越大，就会导致 <code>filesystem cahce</code> 能缓存的数据就越少。其实，仅仅写入 es 中要用来检索的<strong>少数几个字段</strong>就可以了，比如说就写入 es <code>id,name,age</code> 三个字段，然后你可以把其他的字段数据存在 mysql/hbase 里，我们一般是建议用 <code>es + hbase</code> 这么一个架构。</p>
<p>hbase 的特点是<strong>适用于海量数据的在线存储</strong>，就是对 hbase 可以写入海量数据，但是不要做复杂的搜索，做很简单的一些根据 id 或者范围进行查询的这么一个操作就可以了。从 es 中根据 name 和 age 去搜索，拿到的结果可能就 20 个 <code>doc id</code>，然后根据 <code>doc id</code> 到 hbase 里去查询每个 <code>doc id</code> 对应的<strong>完整的数据</strong>，给查出来，再返回给前端。</p>
<p>写入 es 的数据最好小于等于，或者是略微大于 es 的 filesystem cache 的内存容量。然后你从 es 检索可能就花费 20ms，然后再根据 es 返回的 id 去 hbase 里查询，查 20 条数据，可能也就耗费个 30ms，可能你原来那么玩儿，1T 数据都放 es，会每次查询都是 5~10s，现在可能性能就会很高，每次查询就是 50ms。</p>
<h3 id="数据预热"><a href="#数据预热" class="headerlink" title="数据预热"></a>数据预热</h3><p>假如说，哪怕是你就按照上述的方案去做了，es 集群中每个机器写入的数据量还是超过了 <code>filesystem cache</code> 一倍，比如说你写入一台机器 60G 数据，结果 <code>filesystem cache</code> 就 30G，还是有 30G 数据留在了磁盘上。</p>
<p>其实可以做<strong>数据预热</strong>。</p>
<p>举个例子，拿微博来说，你可以把一些大V，平时看的人很多的数据，你自己提前后台搞个系统，每隔一会儿，自己的后台系统去搜索一下热数据，刷到 <code>filesystem cache</code> 里去，后面用户实际上来看这个热数据的时候，他们就是直接从内存里搜索了，很快。</p>
<p>或者是电商，你可以将平时查看最多的一些商品，比如说 iphone 8，热数据提前后台搞个程序，每隔 1 分钟自己主动访问一次，刷到 <code>filesystem cache</code> 里去。</p>
<p>对于那些你觉得比较热的、经常会有人访问的数据，最好<strong>做一个专门的缓存预热子系统</strong>，就是对热数据每隔一段时间，就提前访问一下，让数据进入 <code>filesystem cache</code> 里面去。这样下次别人访问的时候，性能一定会好很多。</p>
<h3 id="冷热分离"><a href="#冷热分离" class="headerlink" title="冷热分离"></a>冷热分离</h3><p>es 可以做类似于 mysql 的水平拆分，就是说将大量的访问很少、频率很低的数据，单独写一个索引，然后将访问很频繁的热数据单独写一个索引。最好是将<strong>冷数据写入一个索引中，然后热数据写入另外一个索引中</strong>，这样可以确保热数据在被预热之后，尽量都让他们留在 <code>filesystem os cache</code> 里，<strong>别让冷数据给冲刷掉</strong>。</p>
<p>你看，假设你有 6 台机器，2 个索引，一个放冷数据，一个放热数据，每个索引 3 个 shard。3 台机器放热数据 index，另外 3 台机器放冷数据 index。然后这样的话，你大量的时间是在访问热数据 index，热数据可能就占总数据量的 10%，此时数据量很少，几乎全都保留在 <code>filesystem cache</code> 里面了，就可以确保热数据的访问性能是很高的。但是对于冷数据而言，是在别的 index 里的，跟热数据 index 不在相同的机器上，大家互相之间都没什么联系了。如果有人访问冷数据，可能大量数据是在磁盘上的，此时性能差点，就 10% 的人去访问冷数据，90% 的人在访问热数据，也无所谓了。</p>
<h3 id="document-模型设计"><a href="#document-模型设计" class="headerlink" title="document 模型设计"></a>document 模型设计</h3><p>对于 MySQL，我们经常有一些复杂的关联查询。在 es 里该怎么玩儿，es 里面的复杂的关联查询尽量别用，一旦用了性能一般都不太好。</p>
<p>最好是先在 Java 系统里就完成关联，将关联好的数据直接写入 es 中。搜索的时候，就不需要利用 es 的搜索语法来完成 join 之类的关联搜索了。</p>
<p>document 模型设计是非常重要的，很多操作，不要在搜索的时候才想去执行各种复杂的乱七八糟的操作。es 能支持的操作就那么多，不要考虑用 es 做一些它不好操作的事情。如果真的有那种操作，尽量在 document 模型设计的时候，写入的时候就完成。另外对于一些太复杂的操作，比如 join/nested/parent-child 搜索都要尽量避免，性能都很差的。</p>
<h3 id="分页性能优化"><a href="#分页性能优化" class="headerlink" title="分页性能优化"></a>分页性能优化</h3><p>es 的分页是较坑的，为啥呢？举个例子吧，假如你每页是 10 条数据，你现在要查询第 100 页，实际上是会把每个 shard 上存储的前 1000 条数据都查到一个协调节点上，如果你有个 5 个 shard，那么就有 5000 条数据，接着协调节点对这 5000 条数据进行一些合并、处理，再获取到最终第 100 页的 10 条数据。</p>
<p>分布式的，你要查第 100 页的 10 条数据，不可能说从 5 个 shard，每个 shard 就查 2 条数据，最后到协调节点合并成 10 条数据吧？你<strong>必须</strong>得从每个 shard 都查 1000 条数据过来，然后根据你的需求进行排序、筛选等等操作，最后再次分页，拿到里面第 100 页的数据。你翻页的时候，翻的越深，每个 shard 返回的数据就越多，而且协调节点处理的时间越长，非常坑爹。所以用 es 做分页的时候，你会发现越翻到后面，就越是慢。</p>
<p>我们之前也是遇到过这个问题，用 es 作分页，前几页就几十毫秒，翻到 10 页或者几十页的时候，基本上就要 5~10 秒才能查出来一页数据了。</p>
<p>有什么解决方案吗？</p>
<h4 id="不允许深度分页（默认深度分页性能很差）"><a href="#不允许深度分页（默认深度分页性能很差）" class="headerlink" title="不允许深度分页（默认深度分页性能很差）"></a>不允许深度分页（默认深度分页性能很差）</h4><p>跟产品经理说，你系统不允许翻那么深的页，默认翻的越深，性能就越差。</p>
<h4 id="类似于-app-里的推荐商品不断下拉出来一页一页的"><a href="#类似于-app-里的推荐商品不断下拉出来一页一页的" class="headerlink" title="类似于 app 里的推荐商品不断下拉出来一页一页的"></a>类似于 app 里的推荐商品不断下拉出来一页一页的</h4><p>类似于微博中，下拉刷微博，刷出来一页一页的，你可以用 <code>scroll api</code>，关于如何使用，自行上网搜索。</p>
<p>scroll 会一次性给你生成<strong>所有数据的一个快照</strong>，然后每次滑动向后翻页就是通过<strong>游标</strong> <code>scroll_id</code> 移动，获取下一页下一页这样子，性能会比上面说的那种分页性能要高很多很多，基本上都是毫秒级的。</p>
<p>但是，唯一的一点就是，这个适合于那种类似微博下拉翻页的，<strong>不能随意跳到任何一页的场景</strong>。也就是说，你不能先进入第 10 页，然后去第 120 页，然后又回到第 58 页，不能随意乱跳页。所以现在很多产品，都是不允许你随意翻页的，app，也有一些网站，做的就是你只能往下拉，一页一页的翻。</p>
<p>初始化时必须指定 <code>scroll</code> 参数，告诉 es 要保存此次搜索的上下文多长时间。你需要确保用户不会持续不断翻页翻几个小时，否则可能因为超时而失败。</p>
<p>除了用 <code>scroll api</code>，你也可以用 <code>search_after</code> 来做，<code>search_after</code> 的思想是使用前一页的结果来帮助检索下一页的数据，显然，这种方式也不允许你随意翻页，你只能一页页往后翻。初始化时，需要使用一个唯一值的字段作为 sort 字段。</p>
<h2 id="面试题-6"><a href="#面试题-6" class="headerlink" title="面试题"></a>面试题</h2><p>es 生产集群的部署架构是什么？每个索引的数据量大概有多少？每个索引大概有多少个分片？</p>
<h2 id="面试官心理分析-6"><a href="#面试官心理分析-6" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>这个问题，包括后面的 redis 什么的，谈到 es、redis、mysql 分库分表等等技术，面试必问！就是你生产环境咋部署的？说白了，这个问题没啥技术含量，就是看你有没有在真正的生产环境里干过这事儿！</p>
<p>有些同学可能是没在生产环境中干过的，没实际去拿线上机器部署过 es 集群，也没实际玩儿过，也没往 es 集群里面导入过几千万甚至是几亿的数据量，可能你就不太清楚这里面的一些生产项目中的细节。</p>
<p>如果你是自己就玩儿过 demo，没碰过真实的 es 集群，那你可能此时会懵。别懵，你一定要云淡风轻的回答出来这个问题，表示你确实干过这事儿。</p>
<h2 id="面试题剖析-6"><a href="#面试题剖析-6" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>其实这个问题没啥，如果你确实干过 es，那你肯定了解你们生产 es 集群的实际情况，部署了几台机器？有多少个索引？每个索引有多大数据量？每个索引给了多少个分片？你肯定知道！</p>
<p>但是如果你确实没干过，也别虚，我给你说一个基本的版本，你到时候就简单说一下就好了。</p>
<ul>
<li>es 生产集群我们部署了 5 台机器，每台机器是 6 核 64G 的，集群总内存是 320G。</li>
<li>我们 es 集群的日增量数据大概是 2000 万条，每天日增量数据大概是 500MB，每月增量数据大概是 6 亿，15G。目前系统已经运行了几个月，现在 es 集群里数据总量大概是 100G 左右。</li>
<li>目前线上有 5 个索引（这个结合你们自己业务来，看看自己有哪些数据可以放 es 的），每个索引的数据量大概是 20G，所以这个数据量之内，我们每个索引分配的是 8 个 shard，比默认的 5 个 shard 多了 3 个 shard。</li>
</ul>
<p>大概就这么说一下就行了。</p>
<h2 id="面试题-7"><a href="#面试题-7" class="headerlink" title="面试题"></a>面试题</h2><p>es 写入数据的工作原理是什么啊？es 查询数据的工作原理是什么啊？底层的 lucene 介绍一下呗？倒排索引了解吗？</p>
<h2 id="面试官心理分析-7"><a href="#面试官心理分析-7" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>问这个，其实面试官就是要看看你了解不了解 es 的一些基本原理，因为用 es 无非就是写入数据，搜索数据。你要是不明白你发起一个写入和搜索请求的时候，es 在干什么，那你真的是……</p>
<p>对 es 基本就是个黑盒，你还能干啥？你唯一能干的就是用 es 的 api 读写数据了。要是出点什么问题，你啥都不知道，那还能指望你什么呢？</p>
<h2 id="面试题剖析-7"><a href="#面试题剖析-7" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="es-写数据过程"><a href="#es-写数据过程" class="headerlink" title="es 写数据过程"></a>es 写数据过程</h3><ul>
<li>客户端选择一个 node 发送请求过去，这个 node 就是 <code>coordinating node</code>（协调节点）。</li>
<li><code>coordinating node</code> 对 document 进行<strong>路由</strong>，将请求转发给对应的 node（有 primary shard）。</li>
<li>实际的 node 上的 <code>primary shard</code> 处理请求，然后将数据同步到 <code>replica node</code>。</li>
<li><code>coordinating node</code> 如果发现 <code>primary node</code> 和所有 <code>replica node</code> 都搞定之后，就返回响应结果给客户端。</li>
</ul>
<p><img src="/blog4/2019/10/20/javaInterview2/es-write.png" alt="es-write"></p>
<h3 id="es-读数据过程"><a href="#es-读数据过程" class="headerlink" title="es 读数据过程"></a>es 读数据过程</h3><p>可以通过 <code>doc id</code> 来查询，会根据 <code>doc id</code> 进行 hash，判断出来当时把 <code>doc id</code> 分配到了哪个 shard 上面去，从那个 shard 去查询。</p>
<ul>
<li>客户端发送请求到<strong>任意</strong>一个 node，成为 <code>coordinate node</code>。</li>
<li><code>coordinate node</code> 对 <code>doc id</code> 进行哈希路由，将请求转发到对应的 node，此时会使用 <code>round-robin</code> <strong>随机轮询算法</strong>，在 <code>primary shard</code> 以及其所有 replica 中随机选择一个，让读请求负载均衡。</li>
<li>接收请求的 node 返回 document 给 <code>coordinate node</code>。</li>
<li><code>coordinate node</code> 返回 document 给客户端。</li>
</ul>
<h3 id="es-搜索数据过程"><a href="#es-搜索数据过程" class="headerlink" title="es 搜索数据过程"></a>es 搜索数据过程</h3><p>es 最强大的是做全文检索，就是比如你有三条数据：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">java真好玩儿啊</span><br><span class="line">java好难学啊</span><br><span class="line">j2ee特别牛</span><br></pre></td></tr></table></figure>

<p>你根据 <code>java</code> 关键词来搜索，将包含 <code>java</code>的 <code>document</code> 给搜索出来。es 就会给你返回：java真好玩儿啊，java好难学啊。</p>
<ul>
<li>客户端发送请求到一个 <code>coordinate node</code>。</li>
<li>协调节点将搜索请求转发到<strong>所有</strong>的 shard 对应的 <code>primary shard</code> 或 <code>replica shard</code>，都可以。</li>
<li>query phase：每个 shard 将自己的搜索结果（其实就是一些 <code>doc id</code>）返回给协调节点，由协调节点进行数据的合并、排序、分页等操作，产出最终结果。</li>
<li>fetch phase：接着由协调节点根据 <code>doc id</code> 去各个节点上<strong>拉取实际</strong>的 <code>document</code> 数据，最终返回给客户端。</li>
</ul>
<blockquote>
<p>写请求是写入 primary shard，然后同步给所有的 replica shard；读请求可以从 primary shard 或 replica shard 读取，采用的是随机轮询算法。</p>
</blockquote>
<h3 id="写数据底层原理"><a href="#写数据底层原理" class="headerlink" title="写数据底层原理"></a>写数据底层原理</h3><p><img src="/blog4/2019/10/20/javaInterview2/es-write-detail.png" alt="es-write-detail"></p>
<p>先写入内存 buffer，在 buffer 里的时候数据是搜索不到的；同时将数据写入 translog 日志文件。</p>
<p>如果 buffer 快满了，或者到一定时间，就会将内存 buffer 数据 <code>refresh</code> 到一个新的 <code>segment file</code> 中，但是此时数据不是直接进入 <code>segment file</code> 磁盘文件，而是先进入 <code>os cache</code> 。这个过程就是 <code>refresh</code>。</p>
<p>每隔 1 秒钟，es 将 buffer 中的数据写入一个<strong>新的</strong> <code>segment file</code>，每秒钟会产生一个<strong>新的磁盘文件</strong> <code>segment file</code>，这个 <code>segment file</code> 中就存储最近 1 秒内 buffer 中写入的数据。</p>
<p>但是如果 buffer 里面此时没有数据，那当然不会执行 refresh 操作，如果 buffer 里面有数据，默认 1 秒钟执行一次 refresh 操作，刷入一个新的 segment file 中。</p>
<p>操作系统里面，磁盘文件其实都有一个东西，叫做 <code>os cache</code>，即操作系统缓存，就是说数据写入磁盘文件之前，会先进入 <code>os cache</code>，先进入操作系统级别的一个内存缓存中去。只要 <code>buffer</code> 中的数据被 refresh 操作刷入 <code>os cache</code>中，这个数据就可以被搜索到了。</p>
<p>为什么叫 es 是<strong>准实时</strong>的？ <code>NRT</code>，全称 <code>near real-time</code>。默认是每隔 1 秒 refresh 一次的，所以 es 是准实时的，因为写入的数据 1 秒之后才能被看到。可以通过 es 的 <code>restful api</code> 或者 <code>java api</code>，<strong>手动</strong>执行一次 refresh 操作，就是手动将 buffer 中的数据刷入 <code>os cache</code>中，让数据立马就可以被搜索到。只要数据被输入 <code>os cache</code> 中，buffer 就会被清空了，因为不需要保留 buffer 了，数据在 translog 里面已经持久化到磁盘去一份了。</p>
<p>重复上面的步骤，新的数据不断进入 buffer 和 translog，不断将 <code>buffer</code> 数据写入一个又一个新的 <code>segment file</code> 中去，每次 <code>refresh</code> 完 buffer 清空，translog 保留。随着这个过程推进，translog 会变得越来越大。当 translog 达到一定长度的时候，就会触发 <code>commit</code> 操作。</p>
<p>commit 操作发生第一步，就是将 buffer 中现有数据 <code>refresh</code> 到 <code>os cache</code> 中去，清空 buffer。然后，将一个 <code>commit point</code> 写入磁盘文件，里面标识着这个 <code>commit point</code> 对应的所有 <code>segment file</code>，同时强行将 <code>os cache</code> 中目前所有的数据都 <code>fsync</code> 到磁盘文件中去。最后<strong>清空</strong> 现有 translog 日志文件，重启一个 translog，此时 commit 操作完成。</p>
<p>这个 commit 操作叫做 <code>flush</code>。默认 30 分钟自动执行一次 <code>flush</code>，但如果 translog 过大，也会触发 <code>flush</code>。flush 操作就对应着 commit 的全过程，我们可以通过 es api，手动执行 flush 操作，手动将 os cache 中的数据 fsync 强刷到磁盘上去。</p>
<p>translog 日志文件的作用是什么？你执行 commit 操作之前，数据要么是停留在 buffer 中，要么是停留在 os cache 中，无论是 buffer 还是 os cache 都是内存，一旦这台机器死了，内存中的数据就全丢了。所以需要将数据对应的操作写入一个专门的日志文件 <code>translog</code> 中，一旦此时机器宕机，再次重启的时候，es 会自动读取 translog 日志文件中的数据，恢复到内存 buffer 和 os cache 中去。</p>
<p>translog 其实也是先写入 os cache 的，默认每隔 5 秒刷一次到磁盘中去，所以默认情况下，可能有 5 秒的数据会仅仅停留在 buffer 或者 translog 文件的 os cache 中，如果此时机器挂了，会<strong>丢失</strong> 5 秒钟的数据。但是这样性能比较好，最多丢 5 秒的数据。也可以将 translog 设置成每次写操作必须是直接 <code>fsync</code> 到磁盘，但是性能会差很多。</p>
<p>实际上你在这里，如果面试官没有问你 es 丢数据的问题，你可以在这里给面试官炫一把，你说，其实 es 第一是准实时的，数据写入 1 秒后可以搜索到；可能会丢失数据的。有 5 秒的数据，停留在 buffer、translog os cache、segment file os cache 中，而不在磁盘上，此时如果宕机，会导致 5 秒的<strong>数据丢失</strong>。</p>
<p><strong>总结一下</strong>，数据先写入内存 buffer，然后每隔 1s，将数据 refresh 到 os cache，到了 os cache 数据就能被搜索到（所以我们才说 es 从写入到能被搜索到，中间有 1s 的延迟）。每隔 5s，将数据写入 translog 文件（这样如果机器宕机，内存数据全没，最多会有 5s 的数据丢失），translog 大到一定程度，或者默认每隔 30mins，会触发 commit 操作，将缓冲区的数据都 flush 到 segment file 磁盘文件中。</p>
<blockquote>
<p>数据写入 segment file 之后，同时就建立好了倒排索引。</p>
</blockquote>
<h3 id="删除-更新数据底层原理"><a href="#删除-更新数据底层原理" class="headerlink" title="删除/更新数据底层原理"></a>删除/更新数据底层原理</h3><p>如果是删除操作，commit 的时候会生成一个 <code>.del</code> 文件，里面将某个 doc 标识为 <code>deleted</code> 状态，那么搜索的时候根据 <code>.del</code> 文件就知道这个 doc 是否被删除了。</p>
<p>如果是更新操作，就是将原来的 doc 标识为 <code>deleted</code> 状态，然后新写入一条数据。</p>
<p>buffer 每 refresh 一次，就会产生一个 <code>segment file</code>，所以默认情况下是 1 秒钟一个 <code>segment file</code>，这样下来 <code>segment file</code> 会越来越多，此时会定期执行 merge。每次 merge 的时候，会将多个 <code>segment file</code> 合并成一个，同时这里会将标识为 <code>deleted</code> 的 doc 给<strong>物理删除掉</strong>，然后将新的 <code>segment file</code> 写入磁盘，这里会写一个 <code>commit point</code>，标识所有新的 <code>segment file</code>，然后打开 <code>segment file</code> 供搜索使用，同时删除旧的 <code>segment file</code>。</p>
<h3 id="底层-lucene"><a href="#底层-lucene" class="headerlink" title="底层 lucene"></a>底层 lucene</h3><p>简单来说，lucene 就是一个 jar 包，里面包含了封装好的各种建立倒排索引的算法代码。我们用 Java 开发的时候，引入 lucene jar，然后基于 lucene 的 api 去开发就可以了。</p>
<p>通过 lucene，我们可以将已有的数据建立索引，lucene 会在本地磁盘上面，给我们组织索引的数据结构。</p>
<h3 id="倒排索引"><a href="#倒排索引" class="headerlink" title="倒排索引"></a>倒排索引</h3><p>在搜索引擎中，每个文档都有一个对应的文档 ID，文档内容被表示为一系列关键词的集合。例如，文档 1 经过分词，提取了 20 个关键词，每个关键词都会记录它在文档中出现的次数和出现位置。</p>
<p>那么，倒排索引就是<strong>关键词到文档</strong> ID 的映射，每个关键词都对应着一系列的文件，这些文件中都出现了关键词。</p>
<p>举个栗子。</p>
<p>有以下文档：</p>
<table>
<thead>
<tr>
<th>DocId</th>
<th>Doc</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>谷歌地图之父跳槽 Facebook</td>
</tr>
<tr>
<td>2</td>
<td>谷歌地图之父加盟 Facebook</td>
</tr>
<tr>
<td>3</td>
<td>谷歌地图创始人拉斯离开谷歌加盟 Facebook</td>
</tr>
<tr>
<td>4</td>
<td>谷歌地图之父跳槽 Facebook 与 Wave 项目取消有关</td>
</tr>
<tr>
<td>5</td>
<td>谷歌地图之父拉斯加盟社交网站 Facebook</td>
</tr>
</tbody></table>
<p>对文档进行分词之后，得到以下<strong>倒排索引</strong>。</p>
<table>
<thead>
<tr>
<th>WordId</th>
<th>Word</th>
<th>DocIds</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>谷歌</td>
<td>1,2,3,4,5</td>
</tr>
<tr>
<td>2</td>
<td>地图</td>
<td>1,2,3,4,5</td>
</tr>
<tr>
<td>3</td>
<td>之父</td>
<td>1,2,4,5</td>
</tr>
<tr>
<td>4</td>
<td>跳槽</td>
<td>1,4</td>
</tr>
<tr>
<td>5</td>
<td>Facebook</td>
<td>1,2,3,4,5</td>
</tr>
<tr>
<td>6</td>
<td>加盟</td>
<td>2,3,5</td>
</tr>
<tr>
<td>7</td>
<td>创始人</td>
<td>3</td>
</tr>
<tr>
<td>8</td>
<td>拉斯</td>
<td>3,5</td>
</tr>
<tr>
<td>9</td>
<td>离开</td>
<td>3</td>
</tr>
<tr>
<td>10</td>
<td>与</td>
<td>4</td>
</tr>
<tr>
<td>..</td>
<td>..</td>
<td>..</td>
</tr>
</tbody></table>
<p>另外，实用的倒排索引还可以记录更多的信息，比如文档频率信息，表示在文档集合中有多少个文档包含某个单词。</p>
<p>那么，有了倒排索引，搜索引擎可以很方便地响应用户的查询。比如用户输入查询 <code>Facebook</code>，搜索系统查找倒排索引，从中读出包含这个单词的文档，这些文档就是提供给用户的搜索结果。</p>
<p>要注意倒排索引的两个重要细节：</p>
<ul>
<li>倒排索引中的所有词项对应一个或多个文档；</li>
<li>倒排索引中的词项<strong>根据字典顺序升序排列</strong></li>
</ul>
<blockquote>
<p>上面只是一个简单的栗子，并没有严格按照字典顺序升序排列。</p>
</blockquote>
<h2 id="面试题-8"><a href="#面试题-8" class="headerlink" title="面试题"></a>面试题</h2><ul>
<li>为什么使用消息队列？</li>
<li>消息队列有什么优点和缺点？</li>
<li>Kafka、ActiveMQ、RabbitMQ、RocketMQ 都有什么区别，以及适合哪些场景？</li>
</ul>
<h2 id="面试官心理分析-8"><a href="#面试官心理分析-8" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>其实面试官主要是想看看：</p>
<ul>
<li><p><strong>第一</strong>，你知不知道你们系统里为什么要用消息队列这个东西？<br><br>不少候选人，说自己项目里用了 Redis、MQ，但是其实他并不知道自己为什么要用这个东西。其实说白了，就是为了用而用，或者是别人设计的架构，他从头到尾都没思考过。<br><br>没有对自己的架构问过为什么的人，一定是平时没有思考的人，面试官对这类候选人印象通常很不好。因为面试官担心你进了团队之后只会木头木脑的干呆活儿，不会自己思考。</p>
</li>
<li><p><strong>第二</strong>，你既然用了消息队列这个东西，你知不知道用了有什么好处&amp;坏处？<br><br>你要是没考虑过这个，那你盲目弄个 MQ 进系统里，后面出了问题你是不是就自己溜了给公司留坑？你要是没考虑过引入一个技术可能存在的弊端和风险，面试官把这类候选人招进来了，基本可能就是挖坑型选手。就怕你干 1 年挖一堆坑，自己跳槽了，给公司留下无穷后患。</p>
</li>
<li><p><strong>第三</strong>，既然你用了 MQ，可能是某一种 MQ，那么你当时做没做过调研？<br><br>你别傻乎乎的自己拍脑袋看个人喜好就瞎用了一个 MQ，比如 Kafka，甚至都从没调研过业界流行的 MQ 到底有哪几种。每一个 MQ 的优点和缺点是什么。每一个 MQ <strong>没有绝对的好坏</strong>，但是就是看用在哪个场景可以<strong>扬长避短，利用其优势，规避其劣势</strong>。<br><br>如果是一个不考虑技术选型的候选人招进了团队，leader 交给他一个任务，去设计个什么系统，他在里面用一些技术，可能都没考虑过选型，最后选的技术可能并不一定合适，一样是留坑。</p>
</li>
</ul>
<h2 id="面试题剖析-8"><a href="#面试题剖析-8" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="为什么使用消息队列"><a href="#为什么使用消息队列" class="headerlink" title="为什么使用消息队列"></a>为什么使用消息队列</h3><p>其实就是问问你消息队列都有哪些使用场景，然后你项目里具体是什么场景，说说你在这个场景里用消息队列是什么？</p>
<p>面试官问你这个问题，<strong>期望的一个回答</strong>是说，你们公司有个什么<strong>业务场景</strong>，这个业务场景有个什么技术挑战，如果不用 MQ 可能会很麻烦，但是你现在用了 MQ 之后带给了你很多的好处。</p>
<p>先说一下消息队列常见的使用场景吧，其实场景有很多，但是比较核心的有 3 个：<strong>解耦</strong>、<strong>异步</strong>、<strong>削峰</strong>。</p>
<h4 id="解耦"><a href="#解耦" class="headerlink" title="解耦"></a>解耦</h4><p>看这么个场景。A 系统发送数据到 BCD 三个系统，通过接口调用发送。如果 E 系统也要这个数据呢？那如果 C 系统现在不需要了呢？A 系统负责人几乎崩溃……</p>
<p><img src="/blog4/2019/10/20/javaInterview2/mq-1.png" alt="mq-1"></p>
<p>在这个场景中，A 系统跟其它各种乱七八糟的系统严重耦合，A 系统产生一条比较关键的数据，很多系统都需要 A 系统将这个数据发送过来。A 系统要时时刻刻考虑 BCDE 四个系统如果挂了该咋办？要不要重发，要不要把消息存起来？头发都白了啊！</p>
<p>如果使用 MQ，A 系统产生一条数据，发送到 MQ 里面去，哪个系统需要数据自己去 MQ 里面消费。如果新系统需要数据，直接从 MQ 里消费即可；如果某个系统不需要这条数据了，就取消对 MQ 消息的消费即可。这样下来，A 系统压根儿不需要去考虑要给谁发送数据，不需要维护这个代码，也不需要考虑人家是否调用成功、失败超时等情况。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/mq-2.png" alt="mq-2"></p>
<p><strong>总结</strong>：通过一个 MQ，Pub/Sub 发布订阅消息这么一个模型，A 系统就跟其它系统彻底解耦了。</p>
<p><strong>面试技巧</strong>：你需要去考虑一下你负责的系统中是否有类似的场景，就是一个系统或者一个模块，调用了多个系统或者模块，互相之间的调用很复杂，维护起来很麻烦。但是其实这个调用是不需要直接同步调用接口的，如果用 MQ 给它异步化解耦，也是可以的，你就需要去考虑在你的项目里，是不是可以运用这个 MQ 去进行系统的解耦。在简历中体现出来这块东西，用 MQ 作解耦。</p>
<h4 id="异步"><a href="#异步" class="headerlink" title="异步"></a>异步</h4><p>再来看一个场景，A 系统接收一个请求，需要在自己本地写库，还需要在 BCD 三个系统写库，自己本地写库要 3ms，BCD 三个系统分别写库要 300ms、450ms、200ms。最终请求总延时是 3 + 300 + 450 + 200 = 953ms，接近 1s，用户感觉搞个什么东西，慢死了慢死了。用户通过浏览器发起请求，等待个 1s，这几乎是不可接受的。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/mq-3.png" alt="mq-3"></p>
<p>一般互联网类的企业，对于用户直接的操作，一般要求是每个请求都必须在 200 ms 以内完成，对用户几乎是无感知的。</p>
<p>如果<strong>使用 MQ</strong>，那么 A 系统连续发送 3 条消息到 MQ 队列中，假如耗时 5ms，A 系统从接受一个请求到返回响应给用户，总时长是 3 + 5 = 8ms，对于用户而言，其实感觉上就是点个按钮，8ms 以后就直接返回了，爽！网站做得真好，真快！</p>
<p><img src="/blog4/2019/10/20/javaInterview2/mq-4.png" alt="mq-4"></p>
<h4 id="削峰"><a href="#削峰" class="headerlink" title="削峰"></a>削峰</h4><p>每天 0:00 到 12:00，A 系统风平浪静，每秒并发请求数量就 50 个。结果每次一到 12:00 ~ 13:00 ，每秒并发请求数量突然会暴增到 5k+ 条。但是系统是直接基于 MySQL 的，大量的请求涌入 MySQL，每秒钟对 MySQL 执行约 5k 条 SQL。</p>
<p>一般的 MySQL，扛到每秒 2k 个请求就差不多了，如果每秒请求到 5k 的话，可能就直接把 MySQL 给打死了，导致系统崩溃，用户也就没法再使用系统了。</p>
<p>但是高峰期一过，到了下午的时候，就成了低峰期，可能也就 1w 的用户同时在网站上操作，每秒中的请求数量可能也就 50 个请求，对整个系统几乎没有任何的压力。</p>
<p>![mq-5].(/images/mq-5.png)</p>
<p>如果使用 MQ，每秒 5k 个请求写入 MQ，A 系统每秒钟最多处理 2k 个请求，因为 MySQL 每秒钟最多处理 2k 个。A 系统从 MQ 中慢慢拉取请求，每秒钟就拉取 2k 个请求，不要超过自己每秒能处理的最大请求数量就 ok，这样下来，哪怕是高峰期的时候，A 系统也绝对不会挂掉。而 MQ 每秒钟 5k 个请求进来，就 2k 个请求出去，结果就导致在中午高峰期（1 个小时），可能有几十万甚至几百万的请求积压在 MQ 中。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/mq-6.png" alt="mq-6"></p>
<p>这个短暂的高峰期积压是 ok 的，因为高峰期过了之后，每秒钟就 50 个请求进 MQ，但是 A 系统依然会按照每秒 2k 个请求的速度在处理。所以说，只要高峰期一过，A 系统就会快速将积压的消息给解决掉。</p>
<h3 id="消息队列有什么优缺点"><a href="#消息队列有什么优缺点" class="headerlink" title="消息队列有什么优缺点"></a>消息队列有什么优缺点</h3><p>优点上面已经说了，就是<strong>在特殊场景下有其对应的好处</strong>，<strong>解耦</strong>、<strong>异步</strong>、<strong>削峰</strong>。</p>
<p>缺点有以下几个：</p>
<ul>
<li><p>系统可用性降低<br><br>系统引入的外部依赖越多，越容易挂掉。本来你就是 A 系统调用 BCD 三个系统的接口就好了，人 ABCD 四个系统好好的，没啥问题，你偏加个 MQ 进来，万一 MQ 挂了咋整，MQ 一挂，整套系统崩溃的，你不就完了？如何保证消息队列的高可用，可以<a href="/docs/high-concurrency/how-to-ensure-high-availability-of-message-queues.md">点击这里查看</a>。</p>
</li>
<li><p>系统复杂度提高<br><br>硬生生加个 MQ 进来，你怎么<a href="/docs/high-concurrency/how-to-ensure-that-messages-are-not-repeatedly-consumed.md">保证消息没有重复消费</a>？怎么<a href="/docs/high-concurrency/how-to-ensure-the-reliable-transmission-of-messages.md">处理消息丢失的情况</a>？怎么保证消息传递的顺序性？头大头大，问题一大堆，痛苦不已。</p>
</li>
<li><p>一致性问题<br><br>A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，咋整？你这数据就不一致了。</p>
</li>
</ul>
<p>所以消息队列实际是一种非常复杂的架构，你引入它有很多好处，但是也得针对它带来的坏处做各种额外的技术方案和架构来规避掉，做好之后，你会发现，妈呀，系统复杂度提升了一个数量级，也许是复杂了 10 倍。但是关键时刻，用，还是得用的。</p>
<h3 id="Kafka、ActiveMQ、RabbitMQ、RocketMQ-有什么优缺点？"><a href="#Kafka、ActiveMQ、RabbitMQ、RocketMQ-有什么优缺点？" class="headerlink" title="Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点？"></a>Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点？</h3><table>
<thead>
<tr>
<th>特性</th>
<th>ActiveMQ</th>
<th>RabbitMQ</th>
<th>RocketMQ</th>
<th>Kafka</th>
</tr>
</thead>
<tbody><tr>
<td>单机吞吐量</td>
<td>万级，比 RocketMQ、Kafka 低一个数量级</td>
<td>同 ActiveMQ</td>
<td>10 万级，支撑高吞吐</td>
<td>10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景</td>
</tr>
<tr>
<td>topic 数量对吞吐量的影响</td>
<td></td>
<td></td>
<td>topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic</td>
<td>topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源</td>
</tr>
<tr>
<td>时效性</td>
<td>ms 级</td>
<td>微秒级，这是 RabbitMQ 的一大特点，延迟最低</td>
<td>ms 级</td>
<td>延迟在 ms 级以内</td>
</tr>
<tr>
<td>可用性</td>
<td>高，基于主从架构实现高可用</td>
<td>同 ActiveMQ</td>
<td>非常高，分布式架构</td>
<td>非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用</td>
</tr>
<tr>
<td>消息可靠性</td>
<td>有较低的概率丢失数据</td>
<td>基本不丢</td>
<td>经过参数优化配置，可以做到 0 丢失</td>
<td>同 RocketMQ</td>
</tr>
<tr>
<td>功能支持</td>
<td>MQ 领域的功能极其完备</td>
<td>基于 erlang 开发，并发能力很强，性能极好，延时很低</td>
<td>MQ 功能较为完善，还是分布式的，扩展性好</td>
<td>功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用</td>
</tr>
</tbody></table>
<p>综上，各种对比之后，有如下建议：</p>
<p>一般的业务系统要引入 MQ，最早大家都用 ActiveMQ，但是现在确实大家用的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃，所以大家还是算了吧，我个人不推荐用这个了；</p>
<p>后来大家开始用 RabbitMQ，但是确实 erlang 语言阻止了大量的 Java 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高；</p>
<p>不过现在确实越来越多的公司会去用 RocketMQ，确实很不错，毕竟是阿里出品，但社区可能有突然黄掉的风险（目前 RocketMQ 已捐给 <a href="https://github.com/apache/rocketmq" target="_blank" rel="noopener">Apache</a>，但 GitHub 上的活跃度其实不算高）对自己公司技术实力有绝对自信的，推荐用 RocketMQ，否则回去老老实实用 RabbitMQ 吧，人家有活跃的开源社区，绝对不会黄。</p>
<p>所以<strong>中小型公司</strong>，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的选择；<strong>大型公司</strong>，基础架构研发实力较强，用 RocketMQ 是很好的选择。</p>
<p>如果是<strong>大数据领域</strong>的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。</p>
<h2 id="面试题-9"><a href="#面试题-9" class="headerlink" title="面试题"></a>面试题</h2><p>如何设计一个高并发系统？</p>
<h2 id="面试官心理分析-9"><a href="#面试官心理分析-9" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>说实话，如果面试官问你这个题目，那么你必须要使出全身吃奶劲了。为啥？因为你没看到现在很多公司招聘的 JD 里都是说啥，有高并发就经验者优先。</p>
<p>如果你确实有真才实学，在互联网公司里干过高并发系统，那你确实拿 offer 基本如探囊取物，没啥问题。面试官也绝对不会这样来问你，否则他就是蠢。</p>
<p>假设你在某知名电商公司干过高并发系统，用户上亿，一天流量几十亿，高峰期并发量上万，甚至是十万。那么人家一定会仔细盘问你的系统架构，你们系统啥架构？怎么部署的？部署了多少台机器？缓存咋用的？MQ 咋用的？数据库咋用的？就是深挖你到底是如何扛住高并发的。</p>
<p>因为真正干过高并发的人一定知道，脱离了业务的系统架构都是在纸上谈兵，真正在复杂业务场景而且还高并发的时候，那系统架构一定不是那么简单的，用个 redis，用 mq 就能搞定？当然不是，真实的系统架构搭配上业务之后，会比这种简单的所谓“高并发架构”要复杂很多倍。</p>
<p>如果有面试官问你个问题说，如何设计一个高并发系统？那么不好意思，<strong>一定是因为你实际上没干过高并发系统</strong>。面试官看你简历就没啥出彩的，感觉就不咋地，所以就会问问你，如何设计一个高并发系统？其实说白了本质就是看看你有没有自己研究过，有没有一定的知识积累。</p>
<p>最好的当然是招聘个真正干过高并发的哥儿们咯，但是这种哥儿们人数稀缺，不好招。所以可能次一点的就是招一个自己研究过的哥儿们，总比招一个啥也不会的哥儿们好吧！</p>
<p>所以这个时候你必须得做一把个人秀了，秀出你所有关于高并发的知识！</p>
<h2 id="面试题剖析-9"><a href="#面试题剖析-9" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>其实所谓的高并发，如果你要理解这个问题呢，其实就得从高并发的根源出发，为啥会有高并发？为啥高并发就很牛逼？</p>
<p>我说的浅显一点，很简单，就是因为刚开始系统都是连接数据库的，但是要知道数据库支撑到每秒并发两三千的时候，基本就快完了。所以才有说，很多公司，刚开始干的时候，技术比较 low，结果业务发展太快，有的时候系统扛不住压力就挂了。</p>
<p>当然会挂了，凭什么不挂？你数据库如果瞬间承载每秒 5000/8000，甚至上万的并发，一定会宕机，因为比如 mysql 就压根儿扛不住这么高的并发量。</p>
<p>所以为啥高并发牛逼？就是因为现在用互联网的人越来越多，很多 app、网站、系统承载的都是高并发请求，可能高峰期每秒并发量几千，很正常的。如果是什么双十一之类的，每秒并发几万几十万都有可能。</p>
<p>那么如此之高的并发量，加上原本就如此之复杂的业务，咋玩儿？真正厉害的，一定是在复杂业务系统里玩儿过高并发架构的人，但是你没有，那么我给你说一下你该怎么回答这个问题：</p>
<p>可以分为以下 6 点：</p>
<ul>
<li>系统拆分</li>
<li>缓存</li>
<li>MQ</li>
<li>分库分表</li>
<li>读写分离</li>
<li>ElasticSearch</li>
</ul>
<p><img src="/blog4/2019/10/20/javaInterview2/high-concurrency-system-design.png" alt="high-concurrency-system-design"></p>
<h3 id="系统拆分"><a href="#系统拆分" class="headerlink" title="系统拆分"></a>系统拆分</h3><p>将一个系统拆分为多个子系统，用 dubbo 来搞。然后每个系统连一个数据库，这样本来就一个库，现在多个数据库，不也可以扛高并发么。</p>
<h3 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h3><p>缓存，必须得用缓存。大部分的高并发场景，都是<strong>读多写少</strong>，那你完全可以在数据库和缓存里都写一份，然后读的时候大量走缓存不就得了。毕竟人家 redis 轻轻松松单机几万的并发。所以你可以考虑考虑你的项目里，那些承载主要请求的<strong>读场景，怎么用缓存来抗高并发</strong>。</p>
<h3 id="MQ"><a href="#MQ" class="headerlink" title="MQ"></a>MQ</h3><p>MQ，必须得用 MQ。可能你还是会出现高并发写的场景，比如说一个业务操作里要频繁搞数据库几十次，增删改增删改，疯了。那高并发绝对搞挂你的系统，你要是用 redis 来承载写那肯定不行，人家是缓存，数据随时就被 LRU 了，数据格式还无比简单，没有事务支持。所以该用 mysql 还得用 mysql 啊。那你咋办？用 MQ 吧，大量的写请求灌入 MQ 里，排队慢慢玩儿，<strong>后边系统消费后慢慢写</strong>，控制在 mysql 承载范围之内。所以你得考虑考虑你的项目里，那些承载复杂写业务逻辑的场景里，如何用 MQ 来异步写，提升并发性。MQ 单机抗几万并发也是 ok 的，这个之前还特意说过。</p>
<h3 id="分库分表"><a href="#分库分表" class="headerlink" title="分库分表"></a>分库分表</h3><p>分库分表，可能到了最后数据库层面还是免不了抗高并发的要求，好吧，那么就将一个数据库拆分为多个库，多个库来扛更高的并发；然后将一个表<strong>拆分为多个表</strong>，每个表的数据量保持少一点，提高 sql 跑的性能。</p>
<h3 id="读写分离"><a href="#读写分离" class="headerlink" title="读写分离"></a>读写分离</h3><p>读写分离，这个就是说大部分时候数据库可能也是读多写少，没必要所有请求都集中在一个库上吧，可以搞个主从架构，<strong>主库写</strong>入，<strong>从库读</strong>取，搞一个读写分离。<strong>读流量太多</strong>的时候，还可以<strong>加更多的从库</strong>。</p>
<h3 id="ElasticSearch"><a href="#ElasticSearch" class="headerlink" title="ElasticSearch"></a>ElasticSearch</h3><p>Elasticsearch，简称 es。es 是分布式的，可以随便扩容，分布式天然就可以支撑高并发，因为动不动就可以扩容加机器来扛更高的并发。那么一些比较简单的查询、统计类的操作，可以考虑用 es 来承载，还有一些全文搜索类的操作，也可以考虑用 es 来承载。</p>
<p>上面的 6 点，基本就是高并发系统肯定要干的一些事儿，大家可以仔细结合之前讲过的知识考虑一下，到时候你可以系统的把这块阐述一下，然后每个部分要注意哪些问题，之前都讲过了，你都可以阐述阐述，表明你对这块是有点积累的。</p>
<p>说句实话，毕竟你真正厉害的一点，不是在于弄明白一些技术，或者大概知道一个高并发系统应该长什么样？其实实际上在真正的复杂的业务系统里，做高并发要远远比上面提到的点要复杂几十倍到上百倍。你需要考虑：哪些需要分库分表，哪些不需要分库分表，单库单表跟分库分表如何 join，哪些数据要放到缓存里去，放哪些数据才可以扛住高并发的请求，你需要完成对一个复杂业务系统的分析之后，然后逐步逐步的加入高并发的系统架构的改造，这个过程是无比复杂的，一旦做过一次，并且做好了，你在这个市场上就会非常的吃香。</p>
<p>其实大部分公司，真正看重的，不是说你掌握高并发相关的一些基本的架构知识，架构中的一些技术，RocketMQ、Kafka、Redis、Elasticsearch，高并发这一块，你了解了，也只能是次一等的人才。对一个有几十万行代码的复杂的分布式系统，一步一步架构、设计以及实践过高并发架构的人，这个经验是难能可贵的。</p>
<h2 id="面试题-10"><a href="#面试题-10" class="headerlink" title="面试题"></a>面试题</h2><p>如何保证消息队列的高可用？</p>
<h2 id="面试官心理分析-10"><a href="#面试官心理分析-10" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>如果有人问到你 MQ 的知识，<strong>高可用是必问的</strong>。<a href="/docs/high-concurrency/why-mq.md">上一讲</a>提到，MQ 会导致<strong>系统可用性降低</strong>。所以只要你用了 MQ，接下来问的一些要点肯定就是围绕着 MQ 的那些缺点怎么来解决了。</p>
<p>要是你傻乎乎的就干用了一个 MQ，各种问题从来没考虑过，那你就杯具了，面试官对你的感觉就是，只会简单使用一些技术，没任何思考，马上对你的印象就不太好了。这样的同学招进来要是做个 20k 薪资以内的普通小弟还凑合，要是做薪资 20k+ 的高工，那就惨了，让你设计个系统，里面肯定一堆坑，出了事故公司受损失，团队一起背锅。</p>
<h2 id="面试题剖析-10"><a href="#面试题剖析-10" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>这个问题这么问是很好的，因为不能问你 Kafka 的高可用性怎么保证？ActiveMQ 的高可用性怎么保证？一个面试官要是这么问就显得很没水平，人家可能用的就是 RabbitMQ，没用过 Kafka，你上来问人家 Kafka 干什么？这不是摆明了刁难人么。</p>
<p>所以有水平的面试官，问的是 MQ 的高可用性怎么保证？这样就是你用过哪个 MQ，你就说说你对那个 MQ 的高可用性的理解。</p>
<h3 id="RabbitMQ-的高可用性"><a href="#RabbitMQ-的高可用性" class="headerlink" title="RabbitMQ 的高可用性"></a>RabbitMQ 的高可用性</h3><p>RabbitMQ 是比较有代表性的，因为是<strong>基于主从</strong>（非分布式）做高可用性的，我们就以 RabbitMQ 为例子讲解第一种 MQ 的高可用性怎么实现。</p>
<p>RabbitMQ 有三种模式：单机模式、普通集群模式、镜像集群模式。</p>
<h4 id="单机模式"><a href="#单机模式" class="headerlink" title="单机模式"></a>单机模式</h4><p>单机模式，就是 Demo 级别的，一般就是你本地启动了玩玩儿的😄，没人生产用单机模式。</p>
<h4 id="普通集群模式（无高可用性）"><a href="#普通集群模式（无高可用性）" class="headerlink" title="普通集群模式（无高可用性）"></a>普通集群模式（无高可用性）</h4><p>普通集群模式，意思就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。你<strong>创建的 queue，只会放在一个 RabbitMQ 实例上</strong>，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/mq-7.png" alt="mq-7"></p>
<p>这种方式确实很麻烦，也不怎么好，<strong>没做到所谓的分布式</strong>，就是个普通集群。因为这导致你要么消费者每次随机连接一个实例然后拉取数据，要么固定连接那个 queue 所在实例消费数据，前者有<strong>数据拉取的开销</strong>，后者导致<strong>单实例性能瓶颈</strong>。</p>
<p>而且如果那个放 queue 的实例宕机了，会导致接下来其他实例就无法从那个实例拉取，如果你<strong>开启了消息持久化</strong>，让 RabbitMQ 落地存储消息的话，<strong>消息不一定会丢</strong>，得等这个实例恢复了，然后才可以继续从这个 queue 拉取数据。</p>
<p>所以这个事儿就比较尴尬了，这就<strong>没有什么所谓的高可用性</strong>，<strong>这方案主要是提高吞吐量的</strong>，就是说让集群中多个节点来服务某个 queue 的读写操作。</p>
<h4 id="镜像集群模式（高可用性）"><a href="#镜像集群模式（高可用性）" class="headerlink" title="镜像集群模式（高可用性）"></a>镜像集群模式（高可用性）</h4><p>这种模式，才是所谓的 RabbitMQ 的高可用模式。跟普通集群模式不一样的是，在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会<strong>存在于多个实例上</strong>，就是说，每个 RabbitMQ 节点都有这个 queue 的一个<strong>完整镜像</strong>，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把<strong>消息同步</strong>到多个实例的 queue 上。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/mq-8.png" alt="mq-8"></p>
<p>那么<strong>如何开启这个镜像集群模式</strong>呢？其实很简单，RabbitMQ 有很好的管理控制台，就是在后台新增一个策略，这个策略是<strong>镜像集群模式的策略</strong>，指定的时候是可以要求数据同步到所有节点的，也可以要求同步到指定数量的节点，再次创建 queue 的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。</p>
<p>这样的话，好处在于，你任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。坏处在于，第一，这个性能开销也太大了吧，消息需要同步到所有机器上，导致网络带宽压力和消耗很重！第二，这么玩儿，不是分布式的，就<strong>没有扩展性可言</strong>了，如果某个 queue 负载很重，你加机器，新增的机器也包含了这个 queue 的所有数据，并<strong>没有办法线性扩展</strong>你的 queue。你想，如果这个 queue 的数据量很大，大到这个机器上的容量无法容纳了，此时该怎么办呢？</p>
<h3 id="Kafka-的高可用性"><a href="#Kafka-的高可用性" class="headerlink" title="Kafka 的高可用性"></a>Kafka 的高可用性</h3><p>Kafka 一个最基本的架构认识：由多个 broker 组成，每个 broker 是一个节点；你创建一个 topic，这个 topic 可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上，每个 partition 就放一部分数据。</p>
<p>这就是<strong>天然的分布式消息队列</strong>，就是说一个 topic 的数据，是<strong>分散放在多个机器上的，每个机器就放一部分数据</strong>。</p>
<p>实际上 RabbmitMQ 之类的，并不是分布式消息队列，它就是传统的消息队列，只不过提供了一些集群、HA(High Availability, 高可用性) 的机制而已，因为无论怎么玩儿，RabbitMQ 一个 queue 的数据都是放在一个节点里的，镜像集群下，也是每个节点都放这个 queue 的完整数据。</p>
<p>Kafka 0.8 以前，是没有 HA 机制的，就是任何一个 broker 宕机了，那个 broker 上的 partition 就废了，没法写也没法读，没有什么高可用性可言。</p>
<p>比如说，我们假设创建了一个 topic，指定其 partition 数量是 3 个，分别在三台机器上。但是，如果第二台机器宕机了，会导致这个 topic 的 1/3 的数据就丢了，因此这个是做不到高可用的。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/kafka-before.png" alt="kafka-before"></p>
<p>Kafka 0.8 以后，提供了 HA 机制，就是 replica（复制品） 副本机制。每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本。所有 replica 会选举一个 leader 出来，那么生产和消费都跟这个 leader 打交道，然后其他 replica 就是 follower。写的时候，leader 会负责把数据同步到所有 follower 上去，读的时候就直接读 leader 上的数据即可。只能读写 leader？很简单，<strong>要是你可以随意读写每个 follower，那么就要 care 数据一致性的问题</strong>，系统复杂度太高，很容易出问题。Kafka 会均匀地将一个 partition 的所有 replica 分布在不同的机器上，这样才可以提高容错性。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/kafka-after.png" alt="kafka-after"></p>
<p>这么搞，就有所谓的<strong>高可用性</strong>了，因为如果某个 broker 宕机了，没事儿，那个 broker上面的 partition 在其他机器上都有副本的。如果这个宕机的 broker 上面有某个 partition 的 leader，那么此时会从 follower 中<strong>重新选举</strong>一个新的 leader 出来，大家继续读写那个新的 leader 即可。这就有所谓的高可用性了。</p>
<p><strong>写数据</strong>的时候，生产者就写 leader，然后 leader 将数据落地写本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据。一旦所有 follower 同步好数据了，就会发送 ack 给 leader，leader 收到所有 follower 的 ack 之后，就会返回写成功的消息给生产者。（当然，这只是其中一种模式，还可以适当调整这个行为）</p>
<p><strong>消费</strong>的时候，只会从 leader 去读，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到。</p>
<p>看到这里，相信你大致明白了 Kafka 是如何保证高可用机制的了，对吧？不至于一无所知，现场还能给面试官画画图。要是遇上面试官确实是 Kafka 高手，深挖了问，那你只能说不好意思，太深入的你没研究过。</p>
<h2 id="面试题-11"><a href="#面试题-11" class="headerlink" title="面试题"></a>面试题</h2><p>如何保证 redis 的高并发和高可用？redis 的主从复制原理能介绍一下么？redis 的哨兵原理能介绍一下么？</p>
<h2 id="面试官心理分析-11"><a href="#面试官心理分析-11" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>其实问这个问题，主要是考考你，redis 单机能承载多高并发？如果单机扛不住如何扩容扛更多的并发？redis 会不会挂？既然 redis 会挂那怎么保证 redis 是高可用的？</p>
<p>其实针对的都是项目中你肯定要考虑的一些问题，如果你没考虑过，那确实你对生产系统中的问题思考太少。</p>
<h2 id="面试题剖析-11"><a href="#面试题剖析-11" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>如果你用 redis 缓存技术的话，肯定要考虑如何用 redis 来加多台机器，保证 redis 是高并发的，还有就是如何让 redis 保证自己不是挂掉以后就直接死掉了，即 redis 高可用。</p>
<p>由于此节内容较多，因此，会分为两个小节进行讲解。</p>
<ul>
<li><a href="/docs/high-concurrency/redis-master-slave.md">redis 主从架构</a></li>
<li><a href="/docs/high-concurrency/redis-sentinel.md">redis 基于哨兵实现高可用</a></li>
</ul>
<p>redis 实现<strong>高并发</strong>主要依靠<strong>主从架构</strong>，一主多从，一般来说，很多项目其实就足够了，单主用来写入数据，单机几万 QPS，多从用来查询数据，多个从实例可以提供每秒 10w 的 QPS。</p>
<p>如果想要在实现高并发的同时，容纳大量的数据，那么就需要 redis 集群，使用 redis 集群之后，可以提供每秒几十万的读写并发。</p>
<p>redis 高可用，如果是做主从架构部署，那么加上哨兵就可以了，就可以实现，任何一个实例宕机，可以进行主备切换。</p>
<h2 id="面试题-12"><a href="#面试题-12" class="headerlink" title="面试题"></a>面试题</h2><p>如何保证消息不被重复消费？或者说，如何保证消息消费的幂等性？</p>
<h2 id="面试官心理分析-12"><a href="#面试官心理分析-12" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>其实这是很常见的一个问题，这俩问题基本可以连起来问。既然是消费消息，那肯定要考虑会不会重复消费？能不能避免重复消费？或者重复消费了也别造成系统异常可以吗？这个是 MQ 领域的基本问题，其实本质上还是问你<strong>使用消息队列如何保证幂等性</strong>，这个是你架构里要考虑的一个问题。</p>
<h2 id="面试题剖析-12"><a href="#面试题剖析-12" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>回答这个问题，首先你别听到重复消息这个事儿，就一无所知吧，你<strong>先大概说一说可能会有哪些重复消费的问题</strong>。</p>
<p>首先，比如 RabbitMQ、RocketMQ、Kafka，都有可能会出现消息重复消费的问题，正常。因为这问题通常不是 MQ 自己保证的，是由我们开发来保证的。挑一个 Kafka 来举个例子，说说怎么重复消费吧。</p>
<p>Kafka 实际上有个 offset 的概念，就是每个消息写进去，都有一个 offset，代表消息的序号，然后 consumer 消费了数据之后，<strong>每隔一段时间</strong>（定时定期），会把自己消费过的消息的 offset 提交一下，表示“我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的 offset 来继续消费吧”。</p>
<p>但是凡事总有意外，比如我们之前生产经常遇到的，就是你有时候重启系统，看你怎么重启了，如果碰到点着急的，直接 kill 进程了，再重启。这会导致 consumer 有些消息处理了，但是没来得及提交 offset，尴尬了。重启之后，少数消息会再次消费一次。</p>
<p>举个栗子。</p>
<p>有这么个场景。数据 1/2/3 依次进入 kafka，kafka 会给这三条数据每条分配一个 offset，代表这条数据的序号，我们就假设分配的 offset 依次是 152/153/154。消费者从 kafka 去消费的时候，也是按照这个顺序去消费。假如当消费者消费了 <code>offset=153</code> 的这条数据，刚准备去提交 offset 到 zookeeper，此时消费者进程被重启了。那么此时消费过的数据 1/2 的 offset 并没有提交，kafka 也就不知道你已经消费了 <code>offset=153</code> 这条数据。那么重启之后，消费者会找 kafka 说，嘿，哥儿们，你给我接着把上次我消费到的那个地方后面的数据继续给我传递过来。由于之前的 offset 没有提交成功，那么数据 1/2 会再次传过来，如果此时消费者没有去重的话，那么就会导致重复消费。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/mq-10.png" alt="mq-10"></p>
<p>如果消费者干的事儿是拿一条数据就往数据库里写一条，会导致说，你可能就把数据 1/2 在数据库里插入了 2 次，那么数据就错啦。</p>
<p>其实重复消费不可怕，可怕的是你没考虑到重复消费之后，<strong>怎么保证幂等性</strong>。</p>
<p>举个例子吧。假设你有个系统，消费一条消息就往数据库里插入一条数据，要是你一个消息重复两次，你不就插入了两条，这数据不就错了？但是你要是消费到第二次的时候，自己判断一下是否已经消费过了，若是就直接扔了，这样不就保留了一条数据，从而保证了数据的正确性。</p>
<p>一条数据重复出现两次，数据库里就只有一条数据，这就保证了系统的幂等性。</p>
<p>幂等性，通俗点说，就一个数据，或者一个请求，给你重复来多次，你得确保对应的数据是不会改变的，<strong>不能出错</strong>。</p>
<p>所以第二个问题来了，怎么保证消息队列消费的幂等性？</p>
<p>其实还是得结合业务来思考，我这里给几个思路：</p>
<ul>
<li>比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update 一下好吧。</li>
<li>比如你是写 Redis，那没问题了，反正每次都是 set，天然幂等性。</li>
<li>比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的 id，类似订单 id 之类的东西，然后你这里消费到了之后，先根据这个 id 去比如 Redis 里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个 id 写 Redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。</li>
<li>比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。</li>
</ul>
<p><img src="/blog4/2019/10/20/javaInterview2/mq-11.png" alt="mq-11"></p>
<p>当然，如何保证 MQ 的消费是幂等性的，需要结合具体的业务来看。</p>
<h2 id="面试题-13"><a href="#面试题-13" class="headerlink" title="面试题"></a>面试题</h2><p>如何保证消息的顺序性？</p>
<h2 id="面试官心理分析-13"><a href="#面试官心理分析-13" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>其实这个也是用 MQ 的时候必问的话题，第一看看你了不了解顺序这个事儿？第二看看你有没有办法保证消息是有顺序的？这是生产系统中常见的问题。</p>
<h2 id="面试题剖析-13"><a href="#面试题剖析-13" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>我举个例子，我们以前做过一个 mysql <code>binlog</code> 同步的系统，压力还是非常大的，日同步数据要达到上亿，就是说数据从一个 mysql 库原封不动地同步到另一个 mysql 库里面去（mysql -&gt; mysql）。常见的一点在于说比如大数据 team，就需要同步一个 mysql 库过来，对公司的业务系统的数据做各种复杂的操作。</p>
<p>你在 mysql 里增删改一条数据，对应出来了增删改 3 条 <code>binlog</code> 日志，接着这三条 <code>binlog</code> 发送到 MQ 里面，再消费出来依次执行，起码得保证人家是按照顺序来的吧？不然本来是：增加、修改、删除；你楞是换了顺序给执行成删除、修改、增加，不全错了么。</p>
<p>本来这个数据同步过来，应该最后这个数据被删除了；结果你搞错了这个顺序，最后这个数据保留下来了，数据同步就出错了。</p>
<p>先看看顺序会错乱的俩场景：</p>
<ul>
<li><strong>RabbitMQ</strong>：一个 queue，多个 consumer。比如，生产者向 RabbitMQ 里发送了三条数据，顺序依次是 data1/data2/data3，压入的是 RabbitMQ 的一个内存队列。有三个消费者分别从 MQ 中消费这三条数据中的一条，结果消费者2先执行完操作，把 data2 存入数据库，然后是 data1/data3。这不明显乱了。</li>
</ul>
<p><img src="/blog4/2019/10/20/javaInterview2/rabbitmq-order-01.png" alt="rabbitmq-order-01"></p>
<ul>
<li><strong>Kafka</strong>：比如说我们建了一个 topic，有三个 partition。生产者在写的时候，其实可以指定一个 key，比如说我们指定了某个订单 id 作为 key，那么这个订单相关的数据，一定会被分发到同一个 partition 中去，而且这个 partition 中的数据一定是有顺序的。<br>消费者从 partition 中取出来数据的时候，也一定是有顺序的。到这里，顺序还是 ok 的，没有错乱。接着，我们在消费者里可能会搞<strong>多个线程来并发处理消息</strong>。因为如果消费者是单线程消费处理，而处理比较耗时的话，比如处理一条消息耗时几十 ms，那么 1 秒钟只能处理几十条消息，这吞吐量太低了。而多个线程并发跑的话，顺序可能就乱掉了。</li>
</ul>
<p><img src="/blog4/2019/10/20/javaInterview2/kafka-order-01.png" alt="kafka-order-01"></p>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><h4 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h4><p>拆分多个 queue，每个 queue 一个 consumer，就是多一些 queue 而已，确实是麻烦点；或者就一个 queue 但是对应一个 consumer，然后这个 consumer 内部用内存队列做排队，然后分发给底层不同的 worker 来处理。<br><img src="/blog4/2019/10/20/javaInterview2/rabbitmq-order-02.png" alt="rabbitmq-order-02"></p>
<h4 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h4><ul>
<li>一个 topic，一个 partition，一个 consumer，内部单线程消费，单线程吞吐量太低，一般不会用这个。</li>
<li>写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性。</li>
</ul>
<p><img src="/blog4/2019/10/20/javaInterview2/./images/kafka-order-02.png" alt="kafka-order-02">面试题</p>
<p>如何保证消息的顺序性？</p>
<h2 id="面试官心理分析-14"><a href="#面试官心理分析-14" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>其实这个也是用 MQ 的时候必问的话题，第一看看你了不了解顺序这个事儿？第二看看你有没有办法保证消息是有顺序的？这是生产系统中常见的问题。</p>
<h2 id="面试题剖析-14"><a href="#面试题剖析-14" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>我举个例子，我们以前做过一个 mysql <code>binlog</code> 同步的系统，压力还是非常大的，日同步数据要达到上亿，就是说数据从一个 mysql 库原封不动地同步到另一个 mysql 库里面去（mysql -&gt; mysql）。常见的一点在于说比如大数据 team，就需要同步一个 mysql 库过来，对公司的业务系统的数据做各种复杂的操作。</p>
<p>你在 mysql 里增删改一条数据，对应出来了增删改 3 条 <code>binlog</code> 日志，接着这三条 <code>binlog</code> 发送到 MQ 里面，再消费出来依次执行，起码得保证人家是按照顺序来的吧？不然本来是：增加、修改、删除；你楞是换了顺序给执行成删除、修改、增加，不全错了么。</p>
<p>本来这个数据同步过来，应该最后这个数据被删除了；结果你搞错了这个顺序，最后这个数据保留下来了，数据同步就出错了。</p>
<p>先看看顺序会错乱的俩场景：</p>
<ul>
<li><strong>RabbitMQ</strong>：一个 queue，多个 consumer。比如，生产者向 RabbitMQ 里发送了三条数据，顺序依次是 data1/data2/data3，压入的是 RabbitMQ 的一个内存队列。有三个消费者分别从 MQ 中消费这三条数据中的一条，结果消费者2先执行完操作，把 data2 存入数据库，然后是 data1/data3。这不明显乱了。</li>
</ul>
<p><img src="/blog4/2019/10/20/javaInterview2/D:/%25E5%25B0%259A%25E7%25A1%2585%25E8%25B0%25B7%2520%2520java%2520EE/%25E9%259D%25A2%25E8%25AF%2595/Java-Interview-Advanced/docs/high-concurrency/images/rabbitmq-order-01.png" alt="rabbitmq-order-01"></p>
<ul>
<li><strong>Kafka</strong>：比如说我们建了一个 topic，有三个 partition。生产者在写的时候，其实可以指定一个 key，比如说我们指定了某个订单 id 作为 key，那么这个订单相关的数据，一定会被分发到同一个 partition 中去，而且这个 partition 中的数据一定是有顺序的。<br>消费者从 partition 中取出来数据的时候，也一定是有顺序的。到这里，顺序还是 ok 的，没有错乱。接着，我们在消费者里可能会搞<strong>多个线程来并发处理消息</strong>。因为如果消费者是单线程消费处理，而处理比较耗时的话，比如处理一条消息耗时几十 ms，那么 1 秒钟只能处理几十条消息，这吞吐量太低了。而多个线程并发跑的话，顺序可能就乱掉了。</li>
</ul>
<p><img src="/blog4/2019/10/20/javaInterview2/D:/%25E5%25B0%259A%25E7%25A1%2585%25E8%25B0%25B7%2520%2520java%2520EE/%25E9%259D%25A2%25E8%25AF%2595/Java-Interview-Advanced/docs/high-concurrency/images/kafka-order-01.png" alt="kafka-order-01"></p>
<h3 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h3><h4 id="RabbitMQ-1"><a href="#RabbitMQ-1" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h4><p>拆分多个 queue，每个 queue 一个 consumer，就是多一些 queue 而已，确实是麻烦点；或者就一个 queue 但是对应一个 consumer，然后这个 consumer 内部用内存队列做排队，然后分发给底层不同的 worker 来处理。<br><img src="/blog4/2019/10/20/javaInterview2/D:/%25E5%25B0%259A%25E7%25A1%2585%25E8%25B0%25B7%2520%2520java%2520EE/%25E9%259D%25A2%25E8%25AF%2595/Java-Interview-Advanced/docs/high-concurrency/images/rabbitmq-order-02.png" alt="rabbitmq-order-02"></p>
<h4 id="Kafka-1"><a href="#Kafka-1" class="headerlink" title="Kafka"></a>Kafka</h4><ul>
<li>一个 topic，一个 partition，一个 consumer，内部单线程消费，单线程吞吐量太低，一般不会用这个。</li>
<li>写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性。</li>
</ul>
<p><img src="/blog4/2019/10/20/javaInterview2/1571665034985.png" alt="1571665034985"></p>
<h2 id="面试题-14"><a href="#面试题-14" class="headerlink" title="面试题"></a>面试题</h2><p>如果让你写一个消息队列，该如何进行架构设计？说一下你的思路。</p>
<h2 id="面试官心理分析-15"><a href="#面试官心理分析-15" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>其实聊到这个问题，一般面试官要考察两块：</p>
<ul>
<li>你有没有对某一个消息队列做过较为深入的原理的了解，或者从整体了解把握住一个消息队列的架构原理。</li>
<li>看看你的设计能力，给你一个常见的系统，就是消息队列系统，看看你能不能从全局把握一下整体架构设计，给出一些关键点出来。</li>
</ul>
<p>说实话，问类似问题的时候，大部分人基本都会蒙，因为平时从来没有思考过类似的问题，大多数人就是平时埋头用，从来不去思考背后的一些东西。类似的问题，比如，如果让你来设计一个 Spring 框架你会怎么做？如果让你来设计一个 Dubbo 框架你会怎么做？如果让你来设计一个 MyBatis 框架你会怎么做？</p>
<h2 id="面试题剖析-15"><a href="#面试题剖析-15" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>其实回答这类问题，说白了，不求你看过那技术的源码，起码你要大概知道那个技术的基本原理、核心组成部分、基本架构构成，然后参照一些开源的技术把一个系统设计出来的思路说一下就好。</p>
<p>比如说这个消息队列系统，我们从以下几个角度来考虑一下：</p>
<ul>
<li><p>首先这个 mq 得支持可伸缩性吧，就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统呗，参照一下 kafka 的设计理念，broker -&gt; topic -&gt; partition，每个 partition 放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给 topic 增加 partition，然后做数据迁移，增加机器，不就可以存放更多数据，提供更高的吞吐量了？</p>
</li>
<li><p>其次你得考虑一下这个 mq 的数据要不要落地磁盘吧？那肯定要了，落磁盘才能保证别进程挂了数据就丢了。那落磁盘的时候怎么落啊？顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这就是 kafka 的思路。</p>
</li>
<li><p>其次你考虑一下你的 mq 的可用性啊？这个事儿，具体参考之前可用性那个环节讲解的 kafka 的高可用保障机制。多副本 -&gt; leader &amp; follower -&gt; broker 挂了重新选举 leader 即可对外服务。</p>
</li>
<li><p>能不能支持数据 0 丢失啊？可以的，参考我们之前说的那个 kafka 数据零丢失方案。</p>
</li>
</ul>
<p>mq 肯定是很复杂的，面试官问你这个问题，其实是个开放题，他就是看看你有没有从架构角度整体构思和设计的思维以及能力。确实这个问题可以刷掉一大批人，因为大部分人平时不思考这些东西。</p>
<h2 id="面试题-15"><a href="#面试题-15" class="headerlink" title="面试题"></a>面试题</h2><p>如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？</p>
<h2 id="面试官心理分析-16"><a href="#面试官心理分析-16" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>你看这问法，其实本质针对的场景，都是说，可能你的消费端出了问题，不消费了；或者消费的速度极其慢。接着就坑爹了，可能你的消息队列集群的磁盘都快写满了，都没人消费，这个时候怎么办？或者是这整个就积压了几个小时，你这个时候怎么办？或者是你积压的时间太长了，导致比如 RabbitMQ 设置了消息过期时间后就没了怎么办？</p>
<p>所以就这事儿，其实线上挺常见的，一般不出，一出就是大 case。一般常见于，举个例子，消费端每次消费之后要写 mysql，结果 mysql 挂了，消费端 hang 那儿了，不动了；或者是消费端出了个什么岔子，导致消费速度极其慢。</p>
<h2 id="面试题剖析-16"><a href="#面试题剖析-16" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>关于这个事儿，我们一个一个来梳理吧，先假设一个场景，我们现在消费端出故障了，然后大量消息在 mq 里积压，现在出事故了，慌了。</p>
<h3 id="大量消息在-mq-里积压了几个小时了还没解决"><a href="#大量消息在-mq-里积压了几个小时了还没解决" class="headerlink" title="大量消息在 mq 里积压了几个小时了还没解决"></a>大量消息在 mq 里积压了几个小时了还没解决</h3><p>几千万条数据在 MQ 里积压了七八个小时，从下午 4 点多，积压到了晚上 11 点多。这个是我们真实遇到过的一个场景，确实是线上故障了，这个时候要不然就是修复 consumer 的问题，让它恢复消费速度，然后傻傻的等待几个小时消费完毕。这个肯定不能在面试的时候说吧。</p>
<p>一个消费者一秒是 1000 条，一秒 3 个消费者是 3000 条，一分钟就是 18 万条。所以如果你积压了几百万到上千万的数据，即使消费者恢复了，也需要大概 1 小时的时间才能恢复过来。</p>
<p>一般这个时候，只能临时紧急扩容了，具体操作步骤和思路如下：</p>
<ul>
<li>先修复 consumer 的问题，确保其恢复消费速度，然后将现有 consumer 都停掉。</li>
<li>新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量。</li>
<li>然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，<strong>消费之后不做耗时的处理</strong>，直接均匀轮询写入临时建立好的 10 倍数量的 queue。</li>
<li>接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。</li>
<li>等快速消费完积压数据之后，<strong>得恢复原先部署的架构</strong>，<strong>重新</strong>用原先的 consumer 机器来消费消息。</li>
</ul>
<h3 id="mq-中的消息过期失效了"><a href="#mq-中的消息过期失效了" class="headerlink" title="mq 中的消息过期失效了"></a>mq 中的消息过期失效了</h3><p>假设你用的是 RabbitMQ，RabbtiMQ 是可以设置过期时间的，也就是 TTL。如果消息在 queue 中积压超过一定的时间就会被 RabbitMQ 给清理掉，这个数据就没了。那这就是第二个坑了。这就不是说数据会大量积压在 mq 里，而是<strong>大量的数据会直接搞丢</strong>。</p>
<p>这个情况下，就不是说要增加 consumer 消费积压的消息，因为实际上没啥积压，而是丢了大量的消息。我们可以采取一个方案，就是<strong>批量重导</strong>，这个我们之前线上也有类似的场景干过。就是大量积压的时候，我们当时就直接丢弃数据了，然后等过了高峰期以后，比如大家一起喝咖啡熬夜到晚上12点以后，用户都睡觉了。这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入 mq 里面去，把白天丢的数据给他补回来。也只能是这样了。</p>
<p>假设 1 万个订单积压在 mq 里面，没有处理，其中 1000 个订单都丢了，你只能手动写程序把那 1000 个订单给查出来，手动发到 mq 里去再补一次。</p>
<h3 id="mq-都快写满了"><a href="#mq-都快写满了" class="headerlink" title="mq 都快写满了"></a>mq 都快写满了</h3><p>如果消息积压在 mq 里，你很长时间都没有处理掉，此时导致 mq 都快写满了，咋办？这个还有别的办法吗？没有，谁让你第一个方案执行的太慢了，你临时写程序，接入数据来消费，<strong>消费一个丢弃一个，都不要了</strong>，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据吧。</p>
<h2 id="面试题-16"><a href="#面试题-16" class="headerlink" title="面试题"></a>面试题</h2><p>你们有没有做 MySQL 读写分离？如何实现 MySQL 的读写分离？MySQL 主从复制原理的是啥？如何解决 MySQL 主从同步的延时问题？</p>
<h2 id="面试官心理分析-17"><a href="#面试官心理分析-17" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>高并发这个阶段，肯定是需要做读写分离的，啥意思？因为实际上大部分的互联网公司，一些网站，或者是 app，其实都是读多写少。所以针对这个情况，就是写一个主库，但是主库挂多个从库，然后从多个从库来读，那不就可以支撑更高的读并发压力了吗？</p>
<h2 id="面试题剖析-17"><a href="#面试题剖析-17" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="如何实现-MySQL-的读写分离？"><a href="#如何实现-MySQL-的读写分离？" class="headerlink" title="如何实现 MySQL 的读写分离？"></a>如何实现 MySQL 的读写分离？</h3><p>其实很简单，就是基于主从复制架构，简单来说，就搞一个主库，挂多个从库，然后我们就单单只是写主库，然后主库会自动把数据给同步到从库上去。</p>
<h3 id="MySQL-主从复制原理的是啥？"><a href="#MySQL-主从复制原理的是啥？" class="headerlink" title="MySQL 主从复制原理的是啥？"></a>MySQL 主从复制原理的是啥？</h3><p>主库将变更写入 binlog 日志，然后从库连接到主库之后，从库有一个 IO 线程，将主库的 binlog 日志拷贝到自己本地，写入一个 relay 中继日志中。接着从库中有一个 SQL 线程会从中继日志读取 binlog，然后执行 binlog 日志中的内容，也就是在自己本地再次执行一遍 SQL，这样就可以保证自己跟主库的数据是一样的。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/mysql-master-slave.png" alt="mysql-master-slave"></p>
<p>这里有一个非常重要的一点，就是从库同步主库数据的过程是串行化的，也就是说主库上并行的操作，在从库上会串行执行。所以这就是一个非常重要的点了，由于从库从主库拷贝日志以及串行执行 SQL 的特点，在高并发场景下，从库的数据一定会比主库慢一些，是<strong>有延时</strong>的。所以经常出现，刚写入主库的数据可能是读不到的，要过几十毫秒，甚至几百毫秒才能读取到。</p>
<p>而且这里还有另外一个问题，就是如果主库突然宕机，然后恰好数据还没同步到从库，那么有些数据可能在从库上是没有的，有些数据可能就丢失了。</p>
<p>所以 MySQL 实际上在这一块有两个机制，一个是<strong>半同步复制</strong>，用来解决主库数据丢失问题；一个是<strong>并行复制</strong>，用来解决主从同步延时问题。</p>
<p>这个所谓<strong>半同步复制</strong>，也叫 <code>semi-sync</code> 复制，指的就是主库写入 binlog 日志之后，就会将<strong>强制</strong>此时立即将数据同步到从库，从库将日志写入自己本地的 relay log 之后，接着会返回一个 ack 给主库，主库接收到<strong>至少一个从库</strong>的 ack 之后才会认为写操作完成了。</p>
<p>所谓<strong>并行复制</strong>，指的是从库开启多个线程，并行读取 relay log 中不同库的日志，然后<strong>并行重放不同库的日志</strong>，这是库级别的并行。</p>
<h3 id="MySQL-主从同步延时问题（精华）"><a href="#MySQL-主从同步延时问题（精华）" class="headerlink" title="MySQL 主从同步延时问题（精华）"></a>MySQL 主从同步延时问题（精华）</h3><p>以前线上确实处理过因为主从同步延时问题而导致的线上的 bug，属于小型的生产事故。</p>
<p>是这个么场景。有个同学是这样写代码逻辑的。先插入一条数据，再把它查出来，然后更新这条数据。在生产环境高峰期，写并发达到了 2000/s，这个时候，主从复制延时大概是在小几十毫秒。线上会发现，每天总有那么一些数据，我们期望更新一些重要的数据状态，但在高峰期时候却没更新。用户跟客服反馈，而客服就会反馈给我们。</p>
<p>我们通过 MySQL 命令：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span> <span class="keyword">status</span></span><br></pre></td></tr></table></figure>

<p>查看 <code>Seconds_Behind_Master</code>，可以看到从库复制主库的数据落后了几 ms。</p>
<p>一般来说，如果主从延迟较为严重，有以下解决方案：</p>
<ul>
<li>分库，将一个主库拆分为多个主库，每个主库的写并发就减少了几倍，此时主从延迟可以忽略不计。</li>
<li>打开 MySQL 支持的并行复制，多个库并行复制。如果说某个库的写入并发就是特别高，单库写并发达到了 2000/s，并行复制还是没意义。</li>
<li>重写代码，写代码的同学，要慎重，插入数据时立马查询可能查不到。</li>
<li>如果确实是存在必须先插入，立马要求就查询到，然后立马就要反过来执行一些操作，对这个查询<strong>设置直连主库</strong>。<strong>不推荐</strong>这种方法，你要是这么搞，读写分离的意义就丧失了。</li>
</ul>
<h2 id="面试题-17"><a href="#面试题-17" class="headerlink" title="面试题"></a>面试题</h2><p>了解什么是 redis 的雪崩、穿透和击穿？redis 崩溃之后会怎么样？系统该如何应对这种情况？如何处理 redis 的穿透？</p>
<h2 id="面试官心理分析-18"><a href="#面试官心理分析-18" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>其实这是问到缓存必问的，因为缓存雪崩和穿透，是缓存最大的两个问题，要么不出现，一旦出现就是致命性的问题，所以面试官一定会问你。</p>
<h2 id="面试题剖析-18"><a href="#面试题剖析-18" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><p>对于系统 A，假设每天高峰期每秒 5000 个请求，本来缓存在高峰期可以扛住每秒 4000 个请求，但是缓存机器意外发生了全盘宕机。缓存挂了，此时 1 秒 5000 个请求全部落数据库，数据库必然扛不住，它会报一下警，然后就挂了。此时，如果没有采用什么特别的方案来处理这个故障，DBA 很着急，重启数据库，但是数据库立马又被新的流量给打死了。</p>
<p>这就是缓存雪崩。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/redis-caching-avalanche.png" alt="redis-caching-avalanche"></p>
<p>大约在 3 年前，国内比较知名的一个互联网公司，曾因为缓存事故，导致雪崩，后台系统全部崩溃，事故从当天下午持续到晚上凌晨 3~4 点，公司损失了几千万。</p>
<p>缓存雪崩的事前事中事后的解决方案如下。</p>
<ul>
<li>事前：redis 高可用，主从+哨兵，redis cluster，避免全盘崩溃。</li>
<li>事中：本地 ehcache 缓存 + hystrix 限流&amp;降级，避免 MySQL 被打死。</li>
<li>事后：redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。</li>
</ul>
<p><img src="/blog4/2019/10/20/javaInterview2/redis-caching-avalanche-solution.png" alt="redis-caching-avalanche-solution"></p>
<p>用户发送一个请求，系统 A 收到请求后，先查本地 ehcache 缓存，如果没查到再查 redis。如果 ehcache 和 redis 都没有，再查数据库，将数据库中的结果，写入 ehcache 和 redis 中。</p>
<p>限流组件，可以设置每秒的请求，有多少能通过组件，剩余的未通过的请求，怎么办？<strong>走降级</strong>！可以返回一些默认的值，或者友情提示，或者空白的值。</p>
<p>好处：</p>
<ul>
<li>数据库绝对不会死，限流组件确保了每秒只有多少个请求能通过。</li>
<li>只要数据库不死，就是说，对用户来说，2/5 的请求都是可以被处理的。</li>
<li>只要有 2/5 的请求可以被处理，就意味着你的系统没死，对用户来说，可能就是点击几次刷不出来页面，但是多点几次，就可以刷出来一次。</li>
</ul>
<h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><p>对于系统A，假设一秒 5000 个请求，结果其中 4000 个请求是黑客发出的恶意攻击。</p>
<p>黑客发出的那 4000 个攻击，缓存中查不到，每次你去数据库里查，也查不到。</p>
<p>举个栗子。数据库 id 是从 1 开始的，结果黑客发过来的请求 id 全部都是负数。这样的话，缓存中不会有，请求每次都“<strong>视缓存于无物</strong>”，直接查询数据库。这种恶意攻击场景的缓存穿透就会直接把数据库给打死。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/redis-caching-penetration.png" alt="redis-caching-penetration"></p>
<p>解决方式很简单，每次系统 A 从数据库中只要没查到，就写一个空值到缓存里去，比如 <code>set -999 UNKNOWN</code>。然后设置一个过期时间，这样的话，下次有相同的 key 来访问的时候，在缓存失效之前，都可以直接从缓存中取数据。</p>
<h3 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h3><p>缓存击穿，就是说某个 key 非常热点，访问非常频繁，处于集中式高并发访问的情况，当这个 key 在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库，就像是在一道屏障上凿开了一个洞。</p>
<p>解决方式也很简单，可以将热点数据设置为永远不过期；或者基于 redis or zookeeper 实现互斥锁，等待第一个请求构建完缓存之后，再释放锁，进而其它请求才能通过该 key 访问数据。</p>
<h2 id="面试题-18"><a href="#面试题-18" class="headerlink" title="面试题"></a>面试题</h2><p>redis 的并发竞争问题是什么？如何解决这个问题？了解 redis 事务的 CAS 方案吗？</p>
<h2 id="面试官心理分析-19"><a href="#面试官心理分析-19" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>这个也是线上非常常见的一个问题，就是<strong>多客户端同时并发写</strong>一个 key，可能本来应该先到的数据后到了，导致数据版本错了；或者是多客户端同时获取一个 key，修改值之后再写回去，只要顺序错了，数据就错了。</p>
<p>而且 redis 自己就有天然解决这个问题的 CAS 类的乐观锁方案。</p>
<h2 id="面试题剖析-19"><a href="#面试题剖析-19" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>某个时刻，多个系统实例都去更新某个 key。可以基于 zookeeper 实现分布式锁。每个系统通过 zookeeper 获取分布式锁，确保同一时间，只能有一个系统实例在操作某个 key，别人都不允许读和写。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/zookeeper-distributed-lock.png" alt="zookeeper-distributed-lock"></p>
<p>你要写入缓存的数据，都是从 mysql 里查出来的，都得写入 mysql 中，写入 mysql 中的时候必须保存一个时间戳，从 mysql 查出来的时候，时间戳也查出来。</p>
<p>每次要<strong>写之前，先判断</strong>一下当前这个 value 的时间戳是否比缓存里的 value 的时间戳要新。如果是的话，那么可以写，否则，就不能用旧的数据覆盖新的数据。</p>
<h2 id="面试题-19"><a href="#面试题-19" class="headerlink" title="面试题"></a>面试题</h2><p>redis 集群模式的工作原理能说一下么？在集群模式下，redis 的 key 是如何寻址的？分布式寻址都有哪些算法？了解一致性 hash 算法吗？</p>
<h2 id="面试官心理分析-20"><a href="#面试官心理分析-20" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>在前几年，redis 如果要搞几个节点，每个节点存储一部分的数据，得<strong>借助一些中间件</strong>来实现，比如说有 <code>codis</code>，或者 <code>twemproxy</code>，都有。有一些 redis 中间件，你读写 redis 中间件，redis 中间件负责将你的数据分布式存储在多台机器上的 redis 实例中。</p>
<p>这两年，redis 不断在发展，redis 也不断有新的版本，现在的 redis 集群模式，可以做到在多台机器上，部署多个 redis 实例，每个实例存储一部分的数据，同时每个 redis 主实例可以挂 redis 从实例，自动确保说，如果 redis 主实例挂了，会自动切换到 redis 从实例上来。</p>
<p>现在 redis 的新版本，大家都是用 redis cluster 的，也就是 redis 原生支持的 redis 集群模式，那么面试官肯定会就 redis cluster 对你来个几连炮。要是你没用过 redis cluster，正常，以前很多人用 codis 之类的客户端来支持集群，但是起码你得研究一下 redis cluster 吧。</p>
<p>如果你的数据量很少，主要是承载高并发高性能的场景，比如你的缓存一般就几个 G，单机就足够了，可以使用 replication，一个 master 多个 slaves，要几个 slave 跟你要求的读吞吐量有关，然后自己搭建一个 sentinel 集群去保证 redis 主从架构的高可用性。</p>
<p>redis cluster，主要是针对<strong>海量数据+高并发+高可用</strong>的场景。redis cluster 支撑 N 个 redis master node，每个 master node 都可以挂载多个 slave node。这样整个 redis 就可以横向扩容了。如果你要支撑更大数据量的缓存，那就横向扩容更多的 master 节点，每个 master 节点就能存放更多的数据了。</p>
<h2 id="面试题剖析-20"><a href="#面试题剖析-20" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="redis-cluster-介绍"><a href="#redis-cluster-介绍" class="headerlink" title="redis cluster 介绍"></a>redis cluster 介绍</h3><ul>
<li>自动将数据进行分片，每个 master 上放一部分数据</li>
<li>提供内置的高可用支持，部分 master 不可用时，还是可以继续工作的</li>
</ul>
<p>在 redis cluster 架构下，每个 redis 要放开两个端口号，比如一个是 6379，另外一个就是 加1w 的端口号，比如 16379。</p>
<p>16379 端口号是用来进行节点间通信的，也就是 cluster bus 的东西，cluster bus 的通信，用来进行故障检测、配置更新、故障转移授权。cluster bus 用了另外一种二进制的协议，<code>gossip</code> 协议，用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间。</p>
<h3 id="节点间的内部通信机制"><a href="#节点间的内部通信机制" class="headerlink" title="节点间的内部通信机制"></a>节点间的内部通信机制</h3><h4 id="基本通信原理"><a href="#基本通信原理" class="headerlink" title="基本通信原理"></a>基本通信原理</h4><p>集群元数据的维护有两种方式：集中式、Gossip 协议。redis cluster 节点间采用 gossip 协议进行通信。</p>
<p><strong>集中式</strong>是将集群元数据（节点信息、故障等等）几种存储在某个节点上。集中式元数据集中存储的一个典型代表，就是大数据领域的 <code>storm</code>。它是分布式的大数据实时计算引擎，是集中式的元数据存储的结构，底层基于 zookeeper（分布式协调的中间件）对所有元数据进行存储维护。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/zookeeper-centralized-storage.png" alt="zookeeper-centralized-storage"></p>
<p>redis 维护集群元数据采用另一个方式， <code>gossip</code> 协议，所有节点都持有一份元数据，不同的节点如果出现了元数据的变更，就不断将元数据发送给其它的节点，让其它节点也进行元数据的变更。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/redis-gossip.png" alt="redis-gossip"></p>
<p><strong>集中式</strong>的<strong>好处</strong>在于，元数据的读取和更新，时效性非常好，一旦元数据出现了变更，就立即更新到集中式的存储中，其它节点读取的时候就可以感知到；<strong>不好</strong>在于，所有的元数据的更新压力全部集中在一个地方，可能会导致元数据的存储有压力。</p>
<p>gossip 好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续打到所有节点上去更新，降低了压力；不好在于，元数据的更新有延时，可能导致集群中的一些操作会有一些滞后。</p>
<ul>
<li><p>10000 端口：每个节点都有一个专门用于节点间通信的端口，就是自己提供服务的端口号+10000，比如 7001，那么用于节点间通信的就是 17001 端口。每个节点每隔一段时间都会往另外几个节点发送 <code>ping</code> 消息，同时其它几个节点接收到 <code>ping</code> 之后返回 <code>pong</code>。</p>
</li>
<li><p>交换的信息：信息包括故障信息，节点的增加和删除，hash slot 信息等等。</p>
</li>
</ul>
<h4 id="gossip-协议"><a href="#gossip-协议" class="headerlink" title="gossip 协议"></a>gossip 协议</h4><p>gossip 协议包含多种消息，包含 <code>ping</code>,<code>pong</code>,<code>meet</code>,<code>fail</code> 等等。</p>
<ul>
<li>meet：某个节点发送 meet 给新加入的节点，让新节点加入集群中，然后新节点就会开始与其它节点进行通信。</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-trib.rb add-node</span><br></pre></td></tr></table></figure>

<p>其实内部就是发送了一个 gossip meet 消息给新加入的节点，通知那个节点去加入我们的集群。</p>
<ul>
<li>ping：每个节点都会频繁给其它节点发送 ping，其中包含自己的状态还有自己维护的集群元数据，互相通过 ping 交换元数据。</li>
<li>pong：返回 ping 和 meeet，包含自己的状态和其它信息，也用于信息广播和更新。</li>
<li>fail：某个节点判断另一个节点 fail 之后，就发送 fail 给其它节点，通知其它节点说，某个节点宕机啦。</li>
</ul>
<h4 id="ping-消息深入"><a href="#ping-消息深入" class="headerlink" title="ping 消息深入"></a>ping 消息深入</h4><p>ping 时要携带一些元数据，如果很频繁，可能会加重网络负担。</p>
<p>每个节点每秒会执行 10 次 ping，每次会选择 5 个最久没有通信的其它节点。当然如果发现某个节点通信延时达到了 <code>cluster_node_timeout / 2</code>，那么立即发送 ping，避免数据交换延时过长，落后的时间太长了。比如说，两个节点之间都 10 分钟没有交换数据了，那么整个集群处于严重的元数据不一致的情况，就会有问题。所以 <code>cluster_node_timeout</code> 可以调节，如果调得比较大，那么会降低 ping 的频率。</p>
<p>每次 ping，会带上自己节点的信息，还有就是带上 1/10 其它节点的信息，发送出去，进行交换。至少包含 <code>3</code> 个其它节点的信息，最多包含 <code>总节点数减 2</code> 个其它节点的信息。</p>
<h3 id="分布式寻址算法"><a href="#分布式寻址算法" class="headerlink" title="分布式寻址算法"></a>分布式寻址算法</h3><ul>
<li>hash 算法（大量缓存重建）</li>
<li>一致性 hash 算法（自动缓存迁移）+ 虚拟节点（自动负载均衡）</li>
<li>redis cluster 的 hash slot 算法</li>
</ul>
<h4 id="hash-算法"><a href="#hash-算法" class="headerlink" title="hash 算法"></a>hash 算法</h4><p>来了一个 key，首先计算 hash 值，然后对节点数取模。然后打在不同的 master 节点上。一旦某一个 master 节点宕机，所有请求过来，都会基于最新的剩余 master 节点数去取模，尝试去取数据。这会导致<strong>大部分的请求过来，全部无法拿到有效的缓存</strong>，导致大量的流量涌入数据库。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/../../../../images/hash.png" alt="hash"></p>
<h4 id="一致性-hash-算法"><a href="#一致性-hash-算法" class="headerlink" title="一致性 hash 算法"></a>一致性 hash 算法</h4><p>一致性 hash 算法将整个 hash 值空间组织成一个虚拟的圆环，整个空间按顺时针方向组织，下一步将各个 master 节点（使用服务器的 ip 或主机名）进行 hash。这样就能确定每个节点在其哈希环上的位置。</p>
<p>来了一个 key，首先计算 hash 值，并确定此数据在环上的位置，从此位置沿环<strong>顺时针“行走”</strong>，遇到的第一个 master 节点就是 key 所在位置。</p>
<p>在一致性哈希算法中，如果一个节点挂了，受影响的数据仅仅是此节点到环空间前一个节点（沿着逆时针方向行走遇到的第一个节点）之间的数据，其它不受影响。增加一个节点也同理。</p>
<p>燃鹅，一致性哈希算法在节点太少时，容易因为节点分布不均匀而造成<strong>缓存热点</strong>的问题。为了解决这种热点问题，一致性 hash 算法引入了虚拟节点机制，即对每一个节点计算多个 hash，每个计算结果位置都放置一个虚拟节点。这样就实现了数据的均匀分布，负载均衡。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/consistent-hashing-algorithm.png" alt="consistent-hashing-algorithm"></p>
<h4 id="redis-cluster-的-hash-slot-算法"><a href="#redis-cluster-的-hash-slot-算法" class="headerlink" title="redis cluster 的 hash slot 算法"></a>redis cluster 的 hash slot 算法</h4><p>redis cluster 有固定的 <code>16384</code> 个 hash slot，对每个 <code>key</code> 计算 <code>CRC16</code> 值，然后对 <code>16384</code> 取模，可以获取 key 对应的 hash slot。</p>
<p>redis cluster 中每个 master 都会持有部分 slot，比如有 3 个 master，那么可能每个 master 持有 5000 多个 hash slot。hash slot 让 node 的增加和移除很简单，增加一个 master，就将其他 master 的 hash slot 移动部分过去，减少一个 master，就将它的 hash slot 移动到其他 master 上去。移动 hash slot 的成本是非常低的。客户端的 api，可以对指定的数据，让他们走同一个 hash slot，通过 <code>hash tag</code> 来实现。</p>
<p>任何一台机器宕机，另外两个节点，不影响的。因为 key 找的是 hash slot，不是机器。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/hash-slot.png" alt="hash-slot"></p>
<h3 id="redis-cluster-的高可用与主备切换原理"><a href="#redis-cluster-的高可用与主备切换原理" class="headerlink" title="redis cluster 的高可用与主备切换原理"></a>redis cluster 的高可用与主备切换原理</h3><p>redis cluster 的高可用的原理，几乎跟哨兵是类似的。</p>
<h4 id="判断节点宕机"><a href="#判断节点宕机" class="headerlink" title="判断节点宕机"></a>判断节点宕机</h4><p>如果一个节点认为另外一个节点宕机，那么就是 <code>pfail</code>，<strong>主观宕机</strong>。如果多个节点都认为另外一个节点宕机了，那么就是 <code>fail</code>，<strong>客观宕机</strong>，跟哨兵的原理几乎一样，sdown，odown。</p>
<p>在 <code>cluster-node-timeout</code> 内，某个节点一直没有返回 <code>pong</code>，那么就被认为 <code>pfail</code>。</p>
<p>如果一个节点认为某个节点 <code>pfail</code> 了，那么会在 <code>gossip ping</code> 消息中，<code>ping</code> 给其他节点，如果<strong>超过半数</strong>的节点都认为 <code>pfail</code> 了，那么就会变成 <code>fail</code>。</p>
<h4 id="从节点过滤"><a href="#从节点过滤" class="headerlink" title="从节点过滤"></a>从节点过滤</h4><p>对宕机的 master node，从其所有的 slave node 中，选择一个切换成 master node。</p>
<p>检查每个 slave node 与 master node 断开连接的时间，如果超过了 <code>cluster-node-timeout * cluster-slave-validity-factor</code>，那么就<strong>没有资格</strong>切换成 <code>master</code>。</p>
<h4 id="从节点选举"><a href="#从节点选举" class="headerlink" title="从节点选举"></a>从节点选举</h4><p>每个从节点，都根据自己对 master 复制数据的 offset，来设置一个选举时间，offset 越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举。</p>
<p>所有的 master node 开始 slave 选举投票，给要进行选举的 slave 进行投票，如果大部分 master node<code>（N/2 + 1）</code>都投票给了某个从节点，那么选举通过，那个从节点可以切换成 master。</p>
<p>从节点执行主备切换，从节点切换为主节点。</p>
<h4 id="与哨兵比较"><a href="#与哨兵比较" class="headerlink" title="与哨兵比较"></a>与哨兵比较</h4><p>整个流程跟哨兵相比，非常类似，所以说，redis cluster 功能强大，直接集成了 replication 和 sentinel 的功能。</p>
<h2 id="面试题-20"><a href="#面试题-20" class="headerlink" title="面试题"></a>面试题</h2><p>如何保证缓存与数据库的双写一致性？</p>
<h2 id="面试官心理分析-21"><a href="#面试官心理分析-21" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>你只要用缓存，就可能会涉及到缓存与数据库双存储双写，你只要是双写，就一定会有数据一致性的问题，那么你如何解决一致性问题？</p>
<h2 id="面试题剖析-21"><a href="#面试题剖析-21" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>一般来说，如果允许缓存可以稍微的跟数据库偶尔有不一致的情况，也就是说如果你的系统<strong>不是严格要求</strong> “缓存+数据库” 必须保持一致性的话，最好不要做这个方案，即：<strong>读请求和写请求串行化</strong>，串到一个<strong>内存队列</strong>里去。</p>
<p>串行化可以保证一定不会出现不一致的情况，但是它也会导致系统的吞吐量大幅度降低，用比正常情况下多几倍的机器去支撑线上的一个请求。</p>
<h3 id="Cache-Aside-Pattern"><a href="#Cache-Aside-Pattern" class="headerlink" title="Cache Aside Pattern"></a>Cache Aside Pattern</h3><p>最经典的缓存+数据库读写的模式，就是 Cache Aside Pattern。</p>
<ul>
<li>读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。</li>
<li>更新的时候，<strong>先更新数据库，然后再删除缓存</strong>。</li>
</ul>
<p><strong>为什么是删除缓存，而不是更新缓存？</strong></p>
<p>原因很简单，很多时候，在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。</p>
<p>比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。</p>
<p>另外更新缓存的代价有时候是很高的。是不是说，每次修改数据库的时候，都一定要将其对应的缓存更新一份？也许有的场景是这样，但是对于<strong>比较复杂的缓存数据计算的场景</strong>，就不是这样了。如果你频繁修改一个缓存涉及的多个表，缓存也频繁更新。但是问题在于，<strong>这个缓存到底会不会被频繁访问到？</strong></p>
<p>举个栗子，一个缓存涉及的表的字段，在 1 分钟内就修改了 20 次，或者是 100 次，那么缓存更新 20 次、100 次；但是这个缓存在 1 分钟内只被读取了 1 次，有<strong>大量的冷数据</strong>。实际上，如果你只是删除缓存的话，那么在 1 分钟内，这个缓存不过就重新计算一次而已，开销大幅度降低。<strong>用到缓存才去算缓存。</strong></p>
<p>其实删除缓存，而不是更新缓存，就是一个 lazy 计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算。像 mybatis，hibernate，都有懒加载思想。查询一个部门，部门带了一个员工的 list，没有必要说每次查询部门，都里面的 1000 个员工的数据也同时查出来啊。80% 的情况，查这个部门，就只是要访问这个部门的信息就可以了。先查部门，同时要访问里面的员工，那么这个时候只有在你要访问里面的员工的时候，才会去数据库里面查询 1000 个员工。</p>
<h3 id="最初级的缓存不一致问题及解决方案"><a href="#最初级的缓存不一致问题及解决方案" class="headerlink" title="最初级的缓存不一致问题及解决方案"></a>最初级的缓存不一致问题及解决方案</h3><p>问题：先更新数据库，再删除缓存。如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/redis-junior-inconsistent.png" alt="redis-junior-inconsistent"></p>
<p>解决思路：先删除缓存，再更新数据库。如果数据库更新失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致。因为读的时候缓存没有，所以去读了数据库中的旧数据，然后更新到缓存中。</p>
<h3 id="比较复杂的数据不一致问题分析"><a href="#比较复杂的数据不一致问题分析" class="headerlink" title="比较复杂的数据不一致问题分析"></a>比较复杂的数据不一致问题分析</h3><p>数据发生了变更，先删除了缓存，然后要去修改数据库，此时还没修改。一个请求过来，去读缓存，发现缓存空了，去查询数据库，<strong>查到了修改前的旧数据</strong>，放到了缓存中。随后数据变更的程序完成了数据库的修改。完了，数据库和缓存中的数据不一样了…</p>
<p><strong>为什么上亿流量高并发场景下，缓存会出现这个问题？</strong></p>
<p>只有在对一个数据在并发的进行读写的时候，才可能会出现这种问题。其实如果说你的并发量很低的话，特别是读并发很低，每天访问量就 1 万次，那么很少的情况下，会出现刚才描述的那种不一致的场景。但是问题是，如果每天的是上亿的流量，每秒并发读是几万，每秒只要有数据更新的请求，就<strong>可能会出现上述的数据库+缓存不一致的情况</strong>。</p>
<p><strong>解决方案如下：</strong></p>
<p>更新数据的时候，根据<strong>数据的唯一标识</strong>，将操作路由之后，发送到一个 jvm 内部队列中。读取数据的时候，如果发现数据不在缓存中，那么将重新读取数据+更新缓存的操作，根据唯一标识路由之后，也发送同一个 jvm 内部队列中。</p>
<p>一个队列对应一个工作线程，每个工作线程<strong>串行</strong>拿到对应的操作，然后一条一条的执行。这样的话，一个数据变更的操作，先删除缓存，然后再去更新数据库，但是还没完成更新。此时如果一个读请求过来，没有读到缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成。</p>
<p>这里有一个<strong>优化点</strong>，一个队列中，其实<strong>多个更新缓存请求串在一起是没意义的</strong>，因此可以做过滤，如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新请求操作进去了，直接等待前面的更新操作请求完成即可。</p>
<p>待那个队列对应的工作线程完成了上一个操作的数据库的修改之后，才会去执行下一个操作，也就是缓存更新的操作，此时会从数据库中读取最新的值，然后写入缓存中。</p>
<p>如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回；如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值。</p>
<p>高并发的场景下，该解决方案要注意的问题：</p>
<ul>
<li>读请求长时阻塞</li>
</ul>
<p>由于读请求进行了非常轻度的异步化，所以一定要注意读超时的问题，每个读请求必须在超时时间范围内返回。</p>
<p>该解决方案，最大的风险点在于说，<strong>可能数据更新很频繁</strong>，导致队列中积压了大量更新操作在里面，然后<strong>读请求会发生大量的超时</strong>，最后导致大量的请求直接走数据库。务必通过一些模拟真实的测试，看看更新数据的频率是怎样的。</p>
<p>另外一点，因为一个队列中，可能会积压针对多个数据项的更新操作，因此需要根据自己的业务情况进行测试，可能需要<strong>部署多个服务</strong>，每个服务分摊一些数据的更新操作。如果一个内存队列里居然会挤压 100 个商品的库存修改操作，每隔库存修改操作要耗费 10ms 去完成，那么最后一个商品的读请求，可能等待 10 * 100 = 1000ms = 1s 后，才能得到数据，这个时候就导致<strong>读请求的长时阻塞</strong>。</p>
<p>一定要做根据实际业务系统的运行情况，去进行一些压力测试，和模拟线上环境，去看看最繁忙的时候，内存队列可能会挤压多少更新操作，可能会导致最后一个更新操作对应的读请求，会 hang 多少时间，如果读请求在 200ms 返回，如果你计算过后，哪怕是最繁忙的时候，积压 10 个更新操作，最多等待 200ms，那还可以的。</p>
<p><strong>如果一个内存队列中可能积压的更新操作特别多</strong>，那么你就要<strong>加机器</strong>，让每个机器上部署的服务实例处理更少的数据，那么每个内存队列中积压的更新操作就会越少。</p>
<p>其实根据之前的项目经验，一般来说，数据的写频率是很低的，因此实际上正常来说，在队列中积压的更新操作应该是很少的。像这种针对读高并发、读缓存架构的项目，一般来说写请求是非常少的，每秒的 QPS 能到几百就不错了。</p>
<p>我们来<strong>实际粗略测算一下</strong>。</p>
<p>如果一秒有 500 的写操作，如果分成 5 个时间片，每 200ms 就 100 个写操作，放到 20 个内存队列中，每个内存队列，可能就积压 5 个写操作。每个写操作性能测试后，一般是在 20ms 左右就完成，那么针对每个内存队列的数据的读请求，也就最多 hang 一会儿，200ms 以内肯定能返回了。</p>
<p>经过刚才简单的测算，我们知道，单机支撑的写 QPS 在几百是没问题的，如果写 QPS 扩大了 10 倍，那么就扩容机器，扩容 10 倍的机器，每个机器 20 个队列。</p>
<ul>
<li>读请求并发量过高</li>
</ul>
<p>这里还必须做好压力测试，确保恰巧碰上上述情况的时候，还有一个风险，就是突然间大量读请求会在几十毫秒的延时 hang 在服务上，看服务能不能扛的住，需要多少机器才能扛住最大的极限情况的峰值。</p>
<p>但是因为并不是所有的数据都在同一时间更新，缓存也不会同一时间失效，所以每次可能也就是少数数据的缓存失效了，然后那些数据对应的读请求过来，并发量应该也不会特别大。</p>
<ul>
<li>多服务实例部署的请求路由</li>
</ul>
<p>可能这个服务部署了多个实例，那么必须<strong>保证</strong>说，执行数据更新操作，以及执行缓存更新操作的请求，都通过 Nginx 服务器<strong>路由到相同的服务实例上</strong>。</p>
<p>比如说，对同一个商品的读写请求，全部路由到同一台机器上。可以自己去做服务间的按照某个请求参数的 hash 路由，也可以用 Nginx 的 hash 路由功能等等。</p>
<ul>
<li>热点商品的路由问题，导致请求的倾斜</li>
</ul>
<p>万一某个商品的读写请求特别高，全部打到相同的机器的相同的队列里面去了，可能会造成某台机器的压力过大。就是说，因为只有在商品数据更新的时候才会清空缓存，然后才会导致读写并发，所以其实要根据业务系统去看，如果更新频率不是太高的话，这个问题的影响并不是特别大，但是的确可能某些机器的负载会高一些。</p>
<h2 id="面试题-21"><a href="#面试题-21" class="headerlink" title="面试题"></a>面试题</h2><p>项目中缓存是如何使用的？为什么要用缓存？缓存使用不当会造成什么后果？</p>
<h2 id="面试官心理分析-22"><a href="#面试官心理分析-22" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>这个问题，互联网公司必问，要是一个人连缓存都不太清楚，那确实比较尴尬。</p>
<p>只要问到缓存，上来第一个问题，肯定是先问问你项目哪里用了缓存？为啥要用？不用行不行？如果用了以后可能会有什么不良的后果？</p>
<p>这就是看看你对缓存这个东西背后有没有思考，如果你就是傻乎乎的瞎用，没法给面试官一个合理的解答，那面试官对你印象肯定不太好，觉得你平时思考太少，就知道干活儿。</p>
<h2 id="面试题剖析-22"><a href="#面试题剖析-22" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="项目中缓存是如何使用的？"><a href="#项目中缓存是如何使用的？" class="headerlink" title="项目中缓存是如何使用的？"></a>项目中缓存是如何使用的？</h3><p>这个，需要结合自己项目的业务来。</p>
<h3 id="为什么要用缓存？"><a href="#为什么要用缓存？" class="headerlink" title="为什么要用缓存？"></a>为什么要用缓存？</h3><p>用缓存，主要有两个用途：<strong>高性能</strong>、<strong>高并发</strong>。</p>
<h4 id="高性能"><a href="#高性能" class="headerlink" title="高性能"></a>高性能</h4><p>假设这么个场景，你有个操作，一个请求过来，吭哧吭哧你各种乱七八糟操作 mysql，半天查出来一个结果，耗时 600ms。但是这个结果可能接下来几个小时都不会变了，或者变了也可以不用立即反馈给用户。那么此时咋办？</p>
<p>缓存啊，折腾 600ms 查出来的结果，扔缓存里，一个 key 对应一个 value，下次再有人查，别走 mysql 折腾 600ms 了，直接从缓存里，通过一个 key 查出来一个 value，2ms 搞定。性能提升 300 倍。</p>
<p>就是说对于一些需要复杂操作耗时查出来的结果，且确定后面不怎么变化，但是有很多读请求，那么直接将查询出来的结果放在缓存中，后面直接读缓存就好。</p>
<h4 id="高并发"><a href="#高并发" class="headerlink" title="高并发"></a>高并发</h4><p>mysql 这么重的数据库，压根儿设计不是让你玩儿高并发的，虽然也可以玩儿，但是天然支持不好。mysql 单机支撑到 <code>2000QPS</code> 也开始容易报警了。</p>
<p>所以要是你有个系统，高峰期一秒钟过来的请求有 1万，那一个 mysql 单机绝对会死掉。你这个时候就只能上缓存，把很多数据放缓存，别放 mysql。缓存功能简单，说白了就是 <code>key-value</code> 式操作，单机支撑的并发量轻松一秒几万十几万，支撑高并发 so easy。单机承载并发量是 mysql 单机的几十倍。</p>
<blockquote>
<p>缓存是走内存的，内存天然就支撑高并发。</p>
</blockquote>
<h3 id="用了缓存之后会有什么不良后果？"><a href="#用了缓存之后会有什么不良后果？" class="headerlink" title="用了缓存之后会有什么不良后果？"></a>用了缓存之后会有什么不良后果？</h3><p>常见的缓存问题有以下几个：</p>
<ul>
<li><a href="/docs/high-concurrency/redis-consistence.md">缓存与数据库双写不一致</a></li>
<li><a href="/docs/high-concurrency/redis-caching-avalanche-and-caching-penetration.md">缓存雪崩、缓存穿透</a></li>
<li><a href="/docs/high-concurrency/redis-cas.md">缓存并发竞争</a></li>
</ul>
<p>后面再详细说明。</p>
<h2 id="面试题-22"><a href="#面试题-22" class="headerlink" title="面试题"></a>面试题</h2><p>redis 都有哪些数据类型？分别在哪些场景下使用比较合适？</p>
<h2 id="面试官心理分析-23"><a href="#面试官心理分析-23" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>除非是面试官感觉看你简历，是工作 3 年以内的比较初级的同学，可能对技术没有很深入的研究，面试官才会问这类问题。否则，在宝贵的面试时间里，面试官实在不想多问。</p>
<p>其实问这个问题，主要有两个原因：</p>
<ul>
<li>看看你到底有没有全面的了解 redis 有哪些功能，一般怎么来用，啥场景用什么，就怕你别就会最简单的 KV 操作；</li>
<li>看看你在实际项目里都怎么玩儿过 redis。</li>
</ul>
<p>要是你回答的不好，没说出几种数据类型，也没说什么场景，你完了，面试官对你印象肯定不好，觉得你平时就是做个简单的 set 和 get。</p>
<h2 id="面试题剖析-23"><a href="#面试题剖析-23" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>redis 主要有以下几种数据类型：</p>
<ul>
<li>string</li>
<li>hash</li>
<li>list</li>
<li>set</li>
<li>sorted set</li>
</ul>
<h3 id="string"><a href="#string" class="headerlink" title="string"></a>string</h3><p>这是最简单的类型，就是普通的 set 和 get，做简单的 KV 缓存。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">set</span> college szu</span><br></pre></td></tr></table></figure>

<h3 id="hash"><a href="#hash" class="headerlink" title="hash"></a>hash</h3><p>这个是类似 map 的一种结构，这个一般就是可以将结构化的数据，比如一个对象（前提是<strong>这个对象没嵌套其他的对象</strong>）给缓存在 redis 里，然后每次读写缓存的时候，可以就操作 hash 里的<strong>某个字段</strong>。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hset person name bingo</span><br><span class="line">hset person age 20</span><br><span class="line">hset person id 1</span><br><span class="line">hget person name</span><br></pre></td></tr></table></figure>

<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">person = &#123;</span><br><span class="line">    "name": "bingo",</span><br><span class="line">    "age": 20,</span><br><span class="line">    "id": 1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="list"><a href="#list" class="headerlink" title="list"></a>list</h3><p>list 是有序列表，这个可以玩儿出很多花样。</p>
<p>比如可以通过 list 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西。</p>
<p>比如可以通过 lrange 命令，读取某个闭区间内的元素，可以基于 list 实现分页查询，这个是很棒的一个功能，基于 redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 0开始位置，-1结束位置，结束位置为-1时，表示列表的最后一个位置，即查看所有。</span></span><br><span class="line">lrange mylist 0 -1</span><br></pre></td></tr></table></figure>

<p>比如可以搞个简单的消息队列，从 list 头怼进去，从 list 尾巴那里弄出来。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">lpush mylist 1</span><br><span class="line">lpush mylist 2</span><br><span class="line">lpush mylist 3 4 5</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1</span></span><br><span class="line">rpop mylist</span><br></pre></td></tr></table></figure>

<h3 id="set"><a href="#set" class="headerlink" title="set"></a>set</h3><p>set 是无序集合，自动去重。</p>
<p>直接基于 set 将系统里需要去重的数据扔进去，自动就给去重了，如果你需要对一些数据进行快速的全局去重，你当然也可以基于 jvm 内存里的 HashSet 进行去重，但是如果你的某个系统部署在多台机器上呢？得基于 redis 进行全局的 set 去重。</p>
<p>可以基于 set 玩儿交集、并集、差集的操作，比如交集吧，可以把两个人的粉丝列表整一个交集，看看俩人的共同好友是谁？对吧。</p>
<p>把两个大 V 的粉丝都放在两个 set 中，对两个 set 做交集。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-------操作一个set-------</span></span><br><span class="line"><span class="comment"># 添加元素</span></span><br><span class="line">sadd mySet 1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看全部元素</span></span><br><span class="line">smembers mySet</span><br><span class="line"></span><br><span class="line"><span class="comment"># 判断是否包含某个值</span></span><br><span class="line">sismember mySet 3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除某个/些元素</span></span><br><span class="line">srem mySet 1</span><br><span class="line">srem mySet 2 4</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看元素个数</span></span><br><span class="line">scard mySet</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机删除一个元素</span></span><br><span class="line">spop mySet</span><br><span class="line"></span><br><span class="line"><span class="comment">#-------操作多个set-------</span></span><br><span class="line"><span class="comment"># 将一个set的元素移动到另外一个set</span></span><br><span class="line">smove yourSet mySet 2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 求两set的交集</span></span><br><span class="line">sinter yourSet mySet</span><br><span class="line"></span><br><span class="line"><span class="comment"># 求两set的并集</span></span><br><span class="line">sunion yourSet mySet</span><br><span class="line"></span><br><span class="line"><span class="comment"># 求在yourSet中而不在mySet中的元素</span></span><br><span class="line">sdiff yourSet mySet</span><br></pre></td></tr></table></figure>

<h3 id="sorted-set"><a href="#sorted-set" class="headerlink" title="sorted set"></a>sorted set</h3><p>sorted set 是排序的 set，去重但可以排序，写进去的时候给一个分数，自动根据分数排序。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">zadd board 85 zhangsan</span><br><span class="line">zadd board 72 lisi</span><br><span class="line">zadd board 96 wangwu</span><br><span class="line">zadd board 63 zhaoliu</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取排名前三的用户（默认是升序，所以需要 rev 改为降序）</span></span><br><span class="line">zrevrange board 0 3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取某用户的排名</span></span><br><span class="line">zrank board zhaoliu</span><br></pre></td></tr></table></figure>

<h2 id="面试题-23"><a href="#面试题-23" class="headerlink" title="面试题"></a>面试题</h2><p>redis 的过期策略都有哪些？内存淘汰机制都有哪些？手写一下 LRU 代码实现？</p>
<h2 id="面试官心理分析-24"><a href="#面试官心理分析-24" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>如果你连这个问题都不知道，上来就懵了，回答不出来，那线上你写代码的时候，想当然的认为写进 redis 的数据就一定会存在，后面导致系统各种 bug，谁来负责？</p>
<p>常见的有两个问题：</p>
<ul>
<li>往 redis 写入的数据怎么没了？</li>
</ul>
<p>可能有同学会遇到，在生产环境的 redis 经常会丢掉一些数据，写进去了，过一会儿可能就没了。我的天，同学，你问这个问题就说明 redis 你就没用对啊。redis 是缓存，你给当存储了是吧？</p>
<p>啥叫缓存？用内存当缓存。内存是无限的吗，内存是很宝贵而且是有限的，磁盘是廉价而且是大量的。可能一台机器就几十个 G 的内存，但是可以有几个 T 的硬盘空间。redis 主要是基于内存来进行高性能、高并发的读写操作的。</p>
<p>那既然内存是有限的，比如 redis 就只能用 10G，你要是往里面写了 20G 的数据，会咋办？当然会干掉 10G 的数据，然后就保留 10G 的数据了。那干掉哪些数据？保留哪些数据？当然是干掉不常用的数据，保留常用的数据了。</p>
<ul>
<li>数据明明过期了，怎么还占用着内存？</li>
</ul>
<p>这是由 redis 的过期策略来决定。</p>
<h2 id="面试题剖析-24"><a href="#面试题剖析-24" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="redis-过期策略"><a href="#redis-过期策略" class="headerlink" title="redis 过期策略"></a>redis 过期策略</h3><p>redis 过期策略是：<strong>定期删除+惰性删除</strong>。</p>
<p>所谓<strong>定期删除</strong>，指的是 redis 默认是每隔 100ms 就随机抽取一些设置了过期时间的 key，检查其是否过期，如果过期就删除。</p>
<p>假设 redis 里放了 10w 个 key，都设置了过期时间，你每隔几百毫秒，就检查 10w 个 key，那 redis 基本上就死了，cpu 负载会很高的，消耗在你的检查过期 key 上了。注意，这里可不是每隔 100ms 就遍历所有的设置过期时间的 key，那样就是一场性能上的<strong>灾难</strong>。实际上 redis 是每隔 100ms <strong>随机抽取</strong>一些 key 来检查和删除的。</p>
<p>但是问题是，定期删除可能会导致很多过期 key 到了时间并没有被删除掉，那咋整呢？所以就是惰性删除了。这就是说，在你获取某个 key 的时候，redis 会检查一下 ，这个 key 如果设置了过期时间那么是否过期了？如果过期了此时就会删除，不会给你返回任何东西。</p>
<blockquote>
<p>获取 key 的时候，如果此时 key 已经过期，就删除，不会返回任何东西。</p>
</blockquote>
<p>但是实际上这还是有问题的，如果定期删除漏掉了很多过期 key，然后你也没及时去查，也就没走惰性删除，此时会怎么样？如果大量过期 key 堆积在内存里，导致 redis 内存块耗尽了，咋整？</p>
<p>答案是：<strong>走内存淘汰机制</strong>。</p>
<h3 id="内存淘汰机制"><a href="#内存淘汰机制" class="headerlink" title="内存淘汰机制"></a>内存淘汰机制</h3><p>redis 内存淘汰机制有以下几个：</p>
<ul>
<li>noeviction: 当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用吧，实在是太恶心了。</li>
<li><strong>allkeys-lru</strong>：当内存不足以容纳新写入数据时，在<strong>键空间</strong>中，移除最近最少使用的 key（这个是<strong>最常用</strong>的）。</li>
<li>allkeys-random：当内存不足以容纳新写入数据时，在<strong>键空间</strong>中，随机移除某个 key，这个一般没人用吧，为啥要随机，肯定是把最近最少使用的 key 给干掉啊。</li>
<li>volatile-lru：当内存不足以容纳新写入数据时，在<strong>设置了过期时间的键空间</strong>中，移除最近最少使用的 key（这个一般不太合适）。</li>
<li>volatile-random：当内存不足以容纳新写入数据时，在<strong>设置了过期时间的键空间</strong>中，<strong>随机移除</strong>某个 key。</li>
<li>volatile-ttl：当内存不足以容纳新写入数据时，在<strong>设置了过期时间的键空间</strong>中，有<strong>更早过期时间</strong>的 key 优先移除。</li>
</ul>
<h3 id="手写一个-LRU-算法"><a href="#手写一个-LRU-算法" class="headerlink" title="手写一个 LRU 算法"></a>手写一个 LRU 算法</h3><p>你可以现场手写最原始的 LRU 算法，那个代码量太大了，似乎不太现实。</p>
<p>不求自己纯手工从底层开始打造出自己的 LRU，但是起码要知道如何利用已有的 JDK 数据结构实现一个 Java 版的 LRU。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LRUCache</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">LinkedHashMap</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> CACHE_SIZE;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 传递进来最多能缓存多少数据</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> cacheSize 缓存大小</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">LRUCache</span><span class="params">(<span class="keyword">int</span> cacheSize)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// true 表示让 linkedHashMap 按照访问顺序来进行排序，最近访问的放在头部，最老访问的放在尾部。</span></span><br><span class="line">        <span class="keyword">super</span>((<span class="keyword">int</span>) Math.ceil(cacheSize / <span class="number">0.75</span>) + <span class="number">1</span>, <span class="number">0.75f</span>, <span class="keyword">true</span>);</span><br><span class="line">        CACHE_SIZE = cacheSize;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">boolean</span> <span class="title">removeEldestEntry</span><span class="params">(Map.Entry&lt;K, V&gt; eldest)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 当 map中的数据量大于指定的缓存个数的时候，就自动删除最老的数据。</span></span><br><span class="line">        <span class="keyword">return</span> size() &gt; CACHE_SIZE;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="Redis-主从架构"><a href="#Redis-主从架构" class="headerlink" title="Redis 主从架构"></a>Redis 主从架构</h1><p>单机的 redis，能够承载的 QPS 大概就在上万到几万不等。对于缓存来说，一般都是用来支撑<strong>读高并发</strong>的。因此架构做成主从(master-slave)架构，一主多从，主负责写，并且将数据复制到其它的 slave 节点，从节点负责读。所有的<strong>读请求全部走从节点</strong>。这样也可以很轻松实现水平扩容，<strong>支撑读高并发</strong>。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/redis-master-slave.png" alt="redis-master-slave"></p>
<p>redis replication -&gt; 主从架构 -&gt; 读写分离 -&gt; 水平扩容支撑读高并发</p>
<h2 id="redis-replication-的核心机制"><a href="#redis-replication-的核心机制" class="headerlink" title="redis replication 的核心机制"></a>redis replication 的核心机制</h2><ul>
<li>redis 采用<strong>异步方式</strong>复制数据到 slave 节点，不过 redis2.8 开始，slave node 会周期性地确认自己每次复制的数据量；</li>
<li>一个 master node 是可以配置多个 slave node 的；</li>
<li>slave node 也可以连接其他的 slave node；</li>
<li>slave node 做复制的时候，不会 block master node 的正常工作；</li>
<li>slave node 在做复制的时候，也不会 block 对自己的查询操作，它会用旧的数据集来提供服务；但是复制完成的时候，需要删除旧数据集，加载新数据集，这个时候就会暂停对外服务了；</li>
<li>slave node 主要用来进行横向扩容，做读写分离，扩容的 slave node 可以提高读的吞吐量。</li>
</ul>
<p>注意，如果采用了主从架构，那么建议必须<strong>开启</strong> master node 的<a href="/docs/high-concurrency/redis-persistence.md">持久化</a>，不建议用 slave node 作为 master node 的数据热备，因为那样的话，如果你关掉 master 的持久化，可能在 master 宕机重启的时候数据是空的，然后可能一经过复制， slave node 的数据也丢了。</p>
<p>另外，master 的各种备份方案，也需要做。万一本地的所有文件丢失了，从备份中挑选一份 rdb 去恢复 master，这样才能<strong>确保启动的时候，是有数据的</strong>，即使采用了后续讲解的<a href="/docs/high-concurrency/redis-sentinel.md">高可用机制</a>，slave node 可以自动接管 master node，但也可能 sentinel 还没检测到 master failure，master node 就自动重启了，还是可能导致上面所有的 slave node 数据被清空。</p>
<h2 id="redis-主从复制的核心原理"><a href="#redis-主从复制的核心原理" class="headerlink" title="redis 主从复制的核心原理"></a>redis 主从复制的核心原理</h2><p>当启动一个 slave node 的时候，它会发送一个 <code>PSYNC</code> 命令给 master node。</p>
<p>如果这是 slave node 初次连接到 master node，那么会触发一次 <code>full resynchronization</code> 全量复制。此时 master 会启动一个后台线程，开始生成一份 <code>RDB</code> 快照文件，同时还会将从客户端 client 新收到的所有写命令缓存在内存中。<code>RDB</code> 文件生成完毕后， master 会将这个 <code>RDB</code> 发送给 slave，slave 会先<strong>写入本地磁盘，然后再从本地磁盘加载到内存</strong>中，接着 master 会将内存中缓存的写命令发送到 slave，slave 也会同步这些数据。slave node 如果跟 master node 有网络故障，断开了连接，会自动重连，连接之后 master node 仅会复制给 slave 部分缺少的数据。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/redis-master-slave-replication.png" alt="redis-master-slave-replication"></p>
<h3 id="主从复制的断点续传"><a href="#主从复制的断点续传" class="headerlink" title="主从复制的断点续传"></a>主从复制的断点续传</h3><p>从 redis2.8 开始，就支持主从复制的断点续传，如果主从复制过程中，网络连接断掉了，那么可以接着上次复制的地方，继续复制下去，而不是从头开始复制一份。</p>
<p>master node 会在内存中维护一个 backlog，master 和 slave 都会保存一个 replica offset 还有一个 master run id，offset 就是保存在 backlog 中的。如果 master 和 slave 网络连接断掉了，slave 会让 master 从上次 replica offset 开始继续复制，如果没有找到对应的 offset，那么就会执行一次 <code>resynchronization</code>。</p>
<blockquote>
<p>如果根据 host+ip 定位 master node，是不靠谱的，如果 master node 重启或者数据出现了变化，那么 slave node 应该根据不同的 run id 区分。</p>
</blockquote>
<h3 id="无磁盘化复制"><a href="#无磁盘化复制" class="headerlink" title="无磁盘化复制"></a>无磁盘化复制</h3><p>master 在内存中直接创建 <code>RDB</code>，然后发送给 slave，不会在自己本地落地磁盘了。只需要在配置文件中开启 <code>repl-diskless-sync yes</code> 即可。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">repl-diskless-sync yes</span><br><span class="line"></span><br><span class="line"><span class="comment"># 等待 5s 后再开始复制，因为要等更多 slave 重新连接过来</span></span><br><span class="line">repl-diskless-sync-delay 5</span><br></pre></td></tr></table></figure>

<h3 id="过期-key-处理"><a href="#过期-key-处理" class="headerlink" title="过期 key 处理"></a>过期 key 处理</h3><p>slave 不会过期 key，只会等待 master 过期 key。如果 master 过期了一个 key，或者通过 LRU 淘汰了一个 key，那么会模拟一条 del 命令发送给 slave。</p>
<h2 id="复制的完整流程"><a href="#复制的完整流程" class="headerlink" title="复制的完整流程"></a>复制的完整流程</h2><p>slave node 启动时，会在自己本地保存 master node 的信息，包括 master node 的<code>host</code>和<code>ip</code>，但是复制流程没开始。</p>
<p>slave node 内部有个定时任务，每秒检查是否有新的 master node 要连接和复制，如果发现，就跟 master node 建立 socket 网络连接。然后 slave node 发送 <code>ping</code> 命令给 master node。如果 master 设置了 requirepass，那么 slave node 必须发送 masterauth 的口令过去进行认证。master node <strong>第一次执行全量复制</strong>，将所有数据发给 slave node。而在后续，master node 持续将写命令，异步复制给 slave node。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/redis-master-slave-replication-detail.png" alt="redis-master-slave-replication-detail"></p>
<h3 id="全量复制"><a href="#全量复制" class="headerlink" title="全量复制"></a>全量复制</h3><ul>
<li>master 执行 bgsave ，在本地生成一份 rdb 快照文件。</li>
<li>master node 将 rdb 快照文件发送给 slave node，如果 rdb 复制时间超过 60秒（repl-timeout），那么 slave node 就会认为复制失败，可以适当调大这个参数(对于千兆网卡的机器，一般每秒传输 100MB，6G 文件，很可能超过 60s)</li>
<li>master node 在生成 rdb 时，会将所有新的写命令缓存在内存中，在 slave node 保存了 rdb 之后，再将新的写命令复制给 slave node。</li>
<li>如果在复制期间，内存缓冲区持续消耗超过 64MB，或者一次性超过 256MB，那么停止复制，复制失败。</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">client-output-buffer-limit slave 256MB 64MB 60</span><br></pre></td></tr></table></figure>

<ul>
<li>slave node 接收到 rdb 之后，清空自己的旧数据，然后重新加载 rdb 到自己的内存中，同时<strong>基于旧的数据版本</strong>对外提供服务。</li>
<li>如果 slave node 开启了 AOF，那么会立即执行 BGREWRITEAOF，重写 AOF。</li>
</ul>
<h3 id="增量复制"><a href="#增量复制" class="headerlink" title="增量复制"></a>增量复制</h3><ul>
<li>如果全量复制过程中，master-slave 网络连接断掉，那么 slave 重新连接 master 时，会触发增量复制。</li>
<li>master 直接从自己的 backlog 中获取部分丢失的数据，发送给 slave node，默认 backlog 就是 1MB。</li>
<li>master 就是根据 slave 发送的 psync 中的 offset 来从 backlog 中获取数据的。</li>
</ul>
<h3 id="heartbeat"><a href="#heartbeat" class="headerlink" title="heartbeat"></a>heartbeat</h3><p>主从节点互相都会发送 heartbeat 信息。</p>
<p>master 默认每隔 10秒 发送一次 heartbeat，slave node 每隔 1秒 发送一个 heartbeat。</p>
<h3 id="异步复制"><a href="#异步复制" class="headerlink" title="异步复制"></a>异步复制</h3><p>master 每次接收到写命令之后，先在内部写入数据，然后异步发送给 slave node。</p>
<h2 id="redis-如何才能做到高可用"><a href="#redis-如何才能做到高可用" class="headerlink" title="redis 如何才能做到高可用"></a>redis 如何才能做到高可用</h2><p>如果系统在 365 天内，有 99.99% 的时间，都是可以哗哗对外提供服务的，那么就说系统是高可用的。</p>
<p>一个 slave 挂掉了，是不会影响可用性的，还有其它的 slave 在提供相同数据下的相同的对外的查询服务。</p>
<p>但是，如果 master node 死掉了，会怎么样？没法写数据了，写缓存的时候，全部失效了。slave node 还有什么用呢，没有 master 给它们复制数据了，系统相当于不可用了。</p>
<p>redis 的高可用架构，叫做 <code>failover</code> <strong>故障转移</strong>，也可以叫做主备切换。</p>
<p>master node 在故障时，自动检测，并且将某个 slave node 自动切换为 master node 的过程，叫做主备切换。这个过程，实现了 redis 的主从架构下的高可用。</p>
<p>后面会详细说明 redis <a href="/docs/high-concurrency/redis-sentinel.md">基于哨兵的高可用性</a>。</p>
<h2 id="面试题-24"><a href="#面试题-24" class="headerlink" title="面试题"></a>面试题</h2><p>redis 的持久化有哪几种方式？不同的持久化机制都有什么优缺点？持久化机制具体底层是如何实现的？</p>
<h2 id="面试官心理分析-25"><a href="#面试官心理分析-25" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>redis 如果仅仅只是将数据缓存在内存里面，如果 redis 宕机了再重启，内存里的数据就全部都弄丢了啊。你必须得用 redis 的持久化机制，将数据写入内存的同时，异步的慢慢的将数据写入磁盘文件里，进行持久化。</p>
<p>如果 redis 宕机重启，自动从磁盘上加载之前持久化的一些数据就可以了，也许会丢失少许数据，但是至少不会将所有数据都弄丢。</p>
<p>这个其实一样，针对的都是 redis 的生产环境可能遇到的一些问题，就是 redis 要是挂了再重启，内存里的数据不就全丢了？能不能重启的时候把数据给恢复了？</p>
<h2 id="面试题剖析-25"><a href="#面试题剖析-25" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>持久化主要是做灾难恢复、数据恢复，也可以归类到高可用的一个环节中去，比如你 redis 整个挂了，然后 redis 就不可用了，你要做的事情就是让 redis 变得可用，尽快变得可用。</p>
<p>重启 redis，尽快让它对外提供服务，如果没做数据备份，这时候 redis 启动了，也不可用啊，数据都没了。</p>
<p>很可能说，大量的请求过来，缓存全部无法命中，在 redis 里根本找不到数据，这个时候就死定了，出现<strong>缓存雪崩</strong>问题。所有请求没有在 redis 命中，就会去 mysql 数据库这种数据源头中去找，一下子 mysql 承接高并发，然后就挂了…</p>
<p>如果你把 redis 持久化做好，备份和恢复方案做到企业级的程度，那么即使你的 redis 故障了，也可以通过备份数据，快速恢复，一旦恢复立即对外提供服务。</p>
<h3 id="redis-持久化的两种方式"><a href="#redis-持久化的两种方式" class="headerlink" title="redis 持久化的两种方式"></a>redis 持久化的两种方式</h3><ul>
<li>RDB：RDB 持久化机制，是对 redis 中的数据执行<strong>周期性</strong>的持久化。</li>
<li>AOF：AOF 机制对每条写入命令作为日志，以 <code>append-only</code> 的模式写入一个日志文件中，在 redis 重启的时候，可以通过<strong>回放</strong> AOF 日志中的写入指令来重新构建整个数据集。</li>
</ul>
<p>通过 RDB 或 AOF，都可以将 redis 内存中的数据给持久化到磁盘上面来，然后可以将这些数据备份到别的地方去，比如说阿里云等云服务。</p>
<p>如果 redis 挂了，服务器上的内存和磁盘上的数据都丢了，可以从云服务上拷贝回来之前的数据，放到指定的目录中，然后重新启动 redis，redis 就会自动根据持久化数据文件中的数据，去恢复内存中的数据，继续对外提供服务。</p>
<p>如果同时使用 RDB 和 AOF 两种持久化机制，那么在 redis 重启的时候，会使用 <strong>AOF</strong> 来重新构建数据，因为 AOF 中的<strong>数据更加完整</strong>。</p>
<h4 id="RDB-优缺点"><a href="#RDB-优缺点" class="headerlink" title="RDB 优缺点"></a>RDB 优缺点</h4><ul>
<li><p>RDB 会生成多个数据文件，每个数据文件都代表了某一个时刻中 redis 的数据，这种多个数据文件的方式，<strong>非常适合做冷备</strong>，可以将这种完整的数据文件发送到一些远程的安全存储上去，比如说 Amazon 的 S3 云服务上去，在国内可以是阿里云的 ODPS 分布式存储上，以预定好的备份策略来定期备份 redis 中的数据。</p>
</li>
<li><p>RDB 对 redis 对外提供的读写服务，影响非常小，可以让 redis <strong>保持高性能</strong>，因为 redis 主进程只需要 fork 一个子进程，让子进程执行磁盘 IO 操作来进行 RDB 持久化即可。</p>
</li>
<li><p>相对于 AOF 持久化机制来说，直接基于 RDB 数据文件来重启和恢复 redis 进程，更加快速。</p>
</li>
<li><p>如果想要在 redis 故障时，尽可能少的丢失数据，那么 RDB 没有 AOF 好。一般来说，RDB 数据快照文件，都是每隔 5 分钟，或者更长时间生成一次，这个时候就得接受一旦 redis 进程宕机，那么会丢失最近 5 分钟的数据。</p>
</li>
<li><p>RDB 每次在 fork 子进程来执行 RDB 快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒。</p>
</li>
</ul>
<h4 id="AOF-优缺点"><a href="#AOF-优缺点" class="headerlink" title="AOF 优缺点"></a>AOF 优缺点</h4><ul>
<li>AOF 可以更好的保护数据不丢失，一般 AOF 会每隔 1 秒，通过一个后台线程执行一次<code>fsync</code>操作，最多丢失 1 秒钟的数据。</li>
<li>AOF 日志文件以 <code>append-only</code> 模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损，即使文件尾部破损，也很容易修复。</li>
<li>AOF 日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在 <code>rewrite</code> log 的时候，会对其中的指令进行压缩，创建出一份需要恢复数据的最小日志出来。在创建新日志文件的时候，老的日志文件还是照常写入。当新的 merge 后的日志文件 ready 的时候，再交换新老日志文件即可。</li>
<li>AOF 日志文件的命令通过非常可读的方式进行记录，这个特性非常<strong>适合做灾难性的误删除的紧急恢复</strong>。比如某人不小心用 <code>flushall</code> 命令清空了所有数据，只要这个时候后台 <code>rewrite</code> 还没有发生，那么就可以立即拷贝 AOF 文件，将最后一条 <code>flushall</code> 命令给删了，然后再将该 <code>AOF</code> 文件放回去，就可以通过恢复机制，自动恢复所有数据。</li>
<li>对于同一份数据来说，AOF 日志文件通常比 RDB 数据快照文件更大。</li>
<li>AOF 开启后，支持的写 QPS 会比 RDB 支持的写 QPS 低，因为 AOF 一般会配置成每秒 <code>fsync</code> 一次日志文件，当然，每秒一次 <code>fsync</code>，性能也还是很高的。（如果实时写入，那么 QPS 会大降，redis 性能会大大降低）</li>
<li>以前 AOF 发生过 bug，就是通过 AOF 记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以说，类似 AOF 这种较为复杂的基于命令日志 / merge / 回放的方式，比基于 RDB 每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有 bug。不过 AOF 就是为了避免 rewrite 过程导致的 bug，因此每次 rewrite 并不是基于旧的指令日志进行 merge 的，而是<strong>基于当时内存中的数据进行指令的重新构建</strong>，这样健壮性会好很多。</li>
</ul>
<h3 id="RDB-和-AOF-到底该如何选择"><a href="#RDB-和-AOF-到底该如何选择" class="headerlink" title="RDB 和 AOF 到底该如何选择"></a>RDB 和 AOF 到底该如何选择</h3><ul>
<li>不要仅仅使用 RDB，因为那样会导致你丢失很多数据；</li>
<li>也不要仅仅使用 AOF，因为那样有两个问题：第一，你通过 AOF 做冷备，没有 RDB 做冷备来的恢复速度更快；第二，RDB 每次简单粗暴生成数据快照，更加健壮，可以避免 AOF 这种复杂的备份和恢复机制的 bug；</li>
<li>redis 支持同时开启开启两种持久化方式，我们可以综合使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为数据恢复的第一选择; 用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复。</li>
</ul>
<h2 id="面试题-25"><a href="#面试题-25" class="headerlink" title="面试题"></a>面试题</h2><p>生产环境中的 redis 是怎么部署的？</p>
<h2 id="面试官心理分析-26"><a href="#面试官心理分析-26" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>看看你了解不了解你们公司的 redis 生产集群的部署架构，如果你不了解，那么确实你就很失职了，你的 redis 是主从架构？集群架构？用了哪种集群方案？有没有做高可用保证？有没有开启持久化机制确保可以进行数据恢复？线上 redis 给几个 G 的内存？设置了哪些参数？压测后你们 redis 集群承载多少 QPS？</p>
<p>兄弟，这些你必须是门儿清的，否则你确实是没好好思考过。</p>
<h2 id="面试题剖析-26"><a href="#面试题剖析-26" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>redis cluster，10 台机器，5 台机器部署了 redis 主实例，另外 5 台机器部署了 redis 的从实例，每个主实例挂了一个从实例，5 个节点对外提供读写服务，每个节点的读写高峰qps可能可以达到每秒 5 万，5 台机器最多是 25 万读写请求/s。</p>
<p>机器是什么配置？32G 内存+ 8 核 CPU + 1T 磁盘，但是分配给 redis 进程的是10g内存，一般线上生产环境，redis 的内存尽量不要超过 10g，超过 10g 可能会有问题。</p>
<p>5 台机器对外提供读写，一共有 50g 内存。</p>
<p>因为每个主实例都挂了一个从实例，所以是高可用的，任何一个主实例宕机，都会自动故障迁移，redis 从实例会自动变成主实例继续提供读写服务。</p>
<p>你往内存里写的是什么数据？每条数据的大小是多少？商品数据，每条数据是 10kb。100 条数据是 1mb，10 万条数据是 1g。常驻内存的是 200 万条商品数据，占用内存是 20g，仅仅不到总内存的 50%。目前高峰期每秒就是 3500 左右的请求量。</p>
<p>其实大型的公司，会有基础架构的 team 负责缓存集群的运维。</p>
<h1 id="Redis-哨兵集群实现高可用"><a href="#Redis-哨兵集群实现高可用" class="headerlink" title="Redis 哨兵集群实现高可用"></a>Redis 哨兵集群实现高可用</h1><h2 id="哨兵的介绍"><a href="#哨兵的介绍" class="headerlink" title="哨兵的介绍"></a>哨兵的介绍</h2><p>sentinel，中文名是哨兵。哨兵是 redis 集群机构中非常重要的一个组件，主要有以下功能：</p>
<ul>
<li>集群监控：负责监控 redis master 和 slave 进程是否正常工作。</li>
<li>消息通知：如果某个 redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。</li>
<li>故障转移：如果 master node 挂掉了，会自动转移到 slave node 上。</li>
<li>配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址。</li>
</ul>
<p>哨兵用于实现 redis 集群的高可用，本身也是分布式的，作为一个哨兵集群去运行，互相协同工作。</p>
<ul>
<li>故障转移时，判断一个 master node 是否宕机了，需要大部分的哨兵都同意才行，涉及到了分布式选举的问题。</li>
<li>即使部分哨兵节点挂掉了，哨兵集群还是能正常工作的，因为如果一个作为高可用机制重要组成部分的故障转移系统本身是单点的，那就很坑爹了。</li>
</ul>
<h2 id="哨兵的核心知识"><a href="#哨兵的核心知识" class="headerlink" title="哨兵的核心知识"></a>哨兵的核心知识</h2><ul>
<li>哨兵至少需要 3 个实例，来保证自己的健壮性。</li>
<li>哨兵 + redis 主从的部署架构，是<strong>不保证数据零丢失</strong>的，只能保证 redis 集群的高可用性。</li>
<li>对于哨兵 + redis 主从这种复杂的部署架构，尽量在测试环境和生产环境，都进行充足的测试和演练。</li>
</ul>
<p>哨兵集群必须部署 2 个以上节点，如果哨兵集群仅仅部署了 2 个哨兵实例，quorum = 1。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">+----+         +----+</span><br><span class="line">| M1 |---------| R1 |</span><br><span class="line">| S1 |         | S2 |</span><br><span class="line">+----+         +----+</span><br></pre></td></tr></table></figure>

<p>配置 <code>quorum=1</code>，如果 master 宕机， s1 和 s2 中只要有 1 个哨兵认为 master 宕机了，就可以进行切换，同时 s1 和 s2 会选举出一个哨兵来执行故障转移。但是同时这个时候，需要 majority，也就是大多数哨兵都是运行的。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">2 个哨兵，majority=2</span><br><span class="line">3 个哨兵，majority=2</span><br><span class="line">4 个哨兵，majority=2</span><br><span class="line">5 个哨兵，majority=3</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>如果此时仅仅是 M1 进程宕机了，哨兵 s1 正常运行，那么故障转移是 OK 的。但是如果是整个 M1 和 S1 运行的机器宕机了，那么哨兵只有 1 个，此时就没有 majority 来允许执行故障转移，虽然另外一台机器上还有一个 R1，但是故障转移不会执行。</p>
<p>经典的 3 节点哨兵集群是这样的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">       +----+</span><br><span class="line">       | M1 |</span><br><span class="line">       | S1 |</span><br><span class="line">       +----+</span><br><span class="line">          |</span><br><span class="line">+----+    |    +----+</span><br><span class="line">| R2 |----+----| R3 |</span><br><span class="line">| S2 |         | S3 |</span><br><span class="line">+----+         +----+</span><br></pre></td></tr></table></figure>

<p>配置 <code>quorum=2</code>，如果 M1 所在机器宕机了，那么三个哨兵还剩下 2 个，S2 和 S3 可以一致认为 master 宕机了，然后选举出一个来执行故障转移，同时 3 个哨兵的 majority 是 2，所以还剩下的 2 个哨兵运行着，就可以允许执行故障转移。</p>
<h2 id="redis-哨兵主备切换的数据丢失问题"><a href="#redis-哨兵主备切换的数据丢失问题" class="headerlink" title="redis 哨兵主备切换的数据丢失问题"></a>redis 哨兵主备切换的数据丢失问题</h2><h3 id="两种情况和导致数据丢失"><a href="#两种情况和导致数据丢失" class="headerlink" title="两种情况和导致数据丢失"></a>两种情况和导致数据丢失</h3><p>主备切换的过程，可能会导致数据丢失：</p>
<ul>
<li>异步复制导致的数据丢失</li>
</ul>
<p>因为 master-&gt;slave 的复制是异步的，所以可能有部分数据还没复制到 slave，master 就宕机了，此时这部分数据就丢失了。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/async-replication-data-lose-case.png" alt="async-replication-data-lose-case"></p>
<ul>
<li>脑裂导致的数据丢失</li>
</ul>
<p>脑裂，也就是说，某个 master 所在机器突然<strong>脱离了正常的网络</strong>，跟其他 slave 机器不能连接，但是实际上 master 还运行着。此时哨兵可能就会<strong>认为</strong> master 宕机了，然后开启选举，将其他 slave 切换成了 master。这个时候，集群里就会有两个 master ，也就是所谓的<strong>脑裂</strong>。</p>
<p>此时虽然某个 slave 被切换成了 master，但是可能 client 还没来得及切换到新的 master，还继续向旧 master 写数据。因此旧 master 再次恢复的时候，会被作为一个 slave 挂到新的 master 上去，自己的数据会清空，重新从新的 master 复制数据。而新的 master 并没有后来 client 写入的数据，因此，这部分数据也就丢失了。</p>
<p><img src="/blog4/2019/10/20/javaInterview2/redis-cluster-split-brain.png" alt="redis-cluster-split-brain"></p>
<h3 id="数据丢失问题的解决方案"><a href="#数据丢失问题的解决方案" class="headerlink" title="数据丢失问题的解决方案"></a>数据丢失问题的解决方案</h3><p>进行如下配置：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">min-slaves-to-write 1</span><br><span class="line">min-slaves-max-lag 10</span><br></pre></td></tr></table></figure>

<p>表示，要求至少有 1 个 slave，数据复制和同步的延迟不能超过 10 秒。</p>
<p>如果说一旦所有的 slave，数据复制和同步的延迟都超过了 10 秒钟，那么这个时候，master 就不会再接收任何请求了。</p>
<ul>
<li>减少异步复制数据的丢失</li>
</ul>
<p>有了 <code>min-slaves-max-lag</code> 这个配置，就可以确保说，一旦 slave 复制数据和 ack 延时太长，就认为可能 master 宕机后损失的数据太多了，那么就拒绝写请求，这样可以把 master 宕机时由于部分数据未同步到 slave 导致的数据丢失降低的可控范围内。</p>
<ul>
<li>减少脑裂的数据丢失</li>
</ul>
<p>如果一个 master 出现了脑裂，跟其他 slave 丢了连接，那么上面两个配置可以确保说，如果不能继续给指定数量的 slave 发送数据，而且 slave 超过 10 秒没有给自己 ack 消息，那么就直接拒绝客户端的写请求。因此在脑裂场景下，最多就丢失 10 秒的数据。</p>
<h2 id="sdown-和-odown-转换机制"><a href="#sdown-和-odown-转换机制" class="headerlink" title="sdown 和 odown 转换机制"></a>sdown 和 odown 转换机制</h2><ul>
<li>sdown 是主观宕机，就一个哨兵如果自己觉得一个 master 宕机了，那么就是主观宕机</li>
<li>odown 是客观宕机，如果 quorum 数量的哨兵都觉得一个 master 宕机了，那么就是客观宕机</li>
</ul>
<p>sdown 达成的条件很简单，如果一个哨兵 ping 一个 master，超过了 <code>is-master-down-after-milliseconds</code> 指定的毫秒数之后，就主观认为 master 宕机了；如果一个哨兵在指定时间内，收到了 quorum 数量的其它哨兵也认为那个 master 是 sdown 的，那么就认为是 odown 了。</p>
<h2 id="哨兵集群的自动发现机制"><a href="#哨兵集群的自动发现机制" class="headerlink" title="哨兵集群的自动发现机制"></a>哨兵集群的自动发现机制</h2><p>哨兵互相之间的发现，是通过 redis 的 <code>pub/sub</code> 系统实现的，每个哨兵都会往 <code>__sentinel__:hello</code> 这个 channel 里发送一个消息，这时候所有其他哨兵都可以消费到这个消息，并感知到其他的哨兵的存在。</p>
<p>每隔两秒钟，每个哨兵都会往自己监控的某个 master+slaves 对应的 <code>__sentinel__:hello</code> channel 里<strong>发送一个消息</strong>，内容是自己的 host、ip 和 runid 还有对这个 master 的监控配置。</p>
<p>每个哨兵也会去<strong>监听</strong>自己监控的每个 master+slaves 对应的 <code>__sentinel__:hello</code> channel，然后去感知到同样在监听这个 master+slaves 的其他哨兵的存在。</p>
<p>每个哨兵还会跟其他哨兵交换对 <code>master</code> 的监控配置，互相进行监控配置的同步。</p>
<h2 id="slave-配置的自动纠正"><a href="#slave-配置的自动纠正" class="headerlink" title="slave 配置的自动纠正"></a>slave 配置的自动纠正</h2><p>哨兵会负责自动纠正 slave 的一些配置，比如 slave 如果要成为潜在的 master 候选人，哨兵会确保 slave 复制现有 master 的数据；如果 slave 连接到了一个错误的 master 上，比如故障转移之后，那么哨兵会确保它们连接到正确的 master 上。</p>
<h2 id="slave-gt-master-选举算法"><a href="#slave-gt-master-选举算法" class="headerlink" title="slave-&gt;master 选举算法"></a>slave-&gt;master 选举算法</h2><p>如果一个 master 被认为 odown 了，而且 majority 数量的哨兵都允许主备切换，那么某个哨兵就会执行主备切换操作，此时首先要选举一个 slave 来，会考虑 slave 的一些信息：</p>
<ul>
<li>跟 master 断开连接的时长</li>
<li>slave 优先级</li>
<li>复制 offset</li>
<li>run id</li>
</ul>
<p>如果一个 slave 跟 master 断开连接的时间已经超过了 <code>down-after-milliseconds</code> 的 10 倍，外加 master 宕机的时长，那么 slave 就被认为不适合选举为 master。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(down-after-milliseconds * 10) + milliseconds_since_master_is_in_SDOWN_state</span><br></pre></td></tr></table></figure>

<p>接下来会对 slave 进行排序：</p>
<ul>
<li>按照 slave 优先级进行排序，slave priority 越低，优先级就越高。</li>
<li>如果 slave priority 相同，那么看 replica offset，哪个 slave 复制了越多的数据，offset 越靠后，优先级就越高。</li>
<li>如果上面两个条件都相同，那么选择一个 run id 比较小的那个 slave。</li>
</ul>
<h2 id="quorum-和-majority"><a href="#quorum-和-majority" class="headerlink" title="quorum 和 majority"></a>quorum 和 majority</h2><p>每次一个哨兵要做主备切换，首先需要 quorum 数量的哨兵认为 odown，然后选举出一个哨兵来做切换，这个哨兵还需要得到 majority 哨兵的授权，才能正式执行切换。</p>
<p>如果 quorum &lt; majority，比如 5 个哨兵，majority 就是 3，quorum 设置为 2，那么就 3 个哨兵授权就可以执行切换。</p>
<p>但是如果 quorum &gt;= majority，那么必须 quorum 数量的哨兵都授权，比如 5 个哨兵，quorum 是 5，那么必须 5 个哨兵都同意授权，才能执行切换。</p>
<h2 id="configuration-epoch"><a href="#configuration-epoch" class="headerlink" title="configuration epoch"></a>configuration epoch</h2><p>哨兵会对一套 redis master+slaves 进行监控，有相应的监控的配置。</p>
<p>执行切换的那个哨兵，会从要切换到的新 master（salve-&gt;master）那里得到一个 configuration epoch，这就是一个 version 号，每次切换的 version 号都必须是唯一的。</p>
<p>如果第一个选举出的哨兵切换失败了，那么其他哨兵，会等待 failover-timeout 时间，然后接替继续执行切换，此时会重新获取一个新的 configuration epoch，作为新的 version 号。</p>
<h2 id="configuration-传播"><a href="#configuration-传播" class="headerlink" title="configuration 传播"></a>configuration 传播</h2><p>哨兵完成切换之后，会在自己本地更新生成最新的 master 配置，然后同步给其他的哨兵，就是通过之前说的 <code>pub/sub</code> 消息机制。</p>
<p>这里之前的 version 号就很重要了，因为各种消息都是通过一个 channel 去发布和监听的，所以一个哨兵完成一次新的切换之后，新的 master 配置是跟着新的 version 号的。其他的哨兵都是根据版本号的大小来更新自己的 master 配置的。</p>
<h2 id="面试题-26"><a href="#面试题-26" class="headerlink" title="面试题"></a>面试题</h2><p>redis 和 memcached 有什么区别？redis 的线程模型是什么？为什么 redis 单线程却能支撑高并发？</p>
<h2 id="面试官心理分析-27"><a href="#面试官心理分析-27" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>这个是问 redis 的时候，最基本的问题吧，redis 最基本的一个内部原理和特点，就是 redis 实际上是个<strong>单线程工作模型</strong>，你要是这个都不知道，那后面玩儿 redis 的时候，出了问题岂不是什么都不知道？</p>
<p>还有可能面试官会问问你 redis 和 memcached 的区别，但是 memcached 是早些年各大互联网公司常用的缓存方案，但是现在近几年基本都是 redis，没什么公司用 memcached 了。</p>
<h2 id="面试题剖析-27"><a href="#面试题剖析-27" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><h3 id="redis-和-memcached-有啥区别？"><a href="#redis-和-memcached-有啥区别？" class="headerlink" title="redis 和 memcached 有啥区别？"></a>redis 和 memcached 有啥区别？</h3><h4 id="redis-支持复杂的数据结构"><a href="#redis-支持复杂的数据结构" class="headerlink" title="redis 支持复杂的数据结构"></a>redis 支持复杂的数据结构</h4><p>redis 相比 memcached 来说，拥有<a href="/docs/high-concurrency/redis-data-types.md">更多的数据结构</a>，能支持更丰富的数据操作。如果需要缓存能够支持更复杂的结构和操作， redis 会是不错的选择。</p>
<h4 id="redis-原生支持集群模式"><a href="#redis-原生支持集群模式" class="headerlink" title="redis 原生支持集群模式"></a>redis 原生支持集群模式</h4><p>在 redis3.x 版本中，便能支持 cluster 模式，而 memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据。</p>
<h4 id="性能对比"><a href="#性能对比" class="headerlink" title="性能对比"></a>性能对比</h4><p>由于 redis 只使用<strong>单核</strong>，而 memcached 可以使用<strong>多核</strong>，所以平均每一个核上 redis 在存储小数据时比 memcached 性能更高。而在 100k 以上的数据中，memcached 性能要高于 redis。虽然 redis 最近也在存储大数据的性能上进行优化，但是比起 memcached，还是稍有逊色。</p>
<h3 id="redis-的线程模型"><a href="#redis-的线程模型" class="headerlink" title="redis 的线程模型"></a>redis 的线程模型</h3><p>redis 内部使用文件事件处理器 <code>file event handler</code>，这个文件事件处理器是单线程的，所以 redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 socket，将产生事件的 socket 压入内存队列中，事件分派器根据 socket 上的事件类型来选择对应的事件处理器进行处理。</p>
<p>文件事件处理器的结构包含 4 个部分：</p>
<ul>
<li>多个 socket</li>
<li>IO 多路复用程序</li>
<li>文件事件分派器</li>
<li>事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）</li>
</ul>
<p>多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将产生事件的 socket 放入队列中排队，事件分派器每次从队列中取出一个 socket，根据 socket 的事件类型交给对应的事件处理器进行处理。</p>
<p>来看客户端与 redis 的一次通信过程：</p>
<p><img src="/blog4/2019/10/20/javaInterview2/redis-single-thread-model.png" alt="redis-single-thread-model"></p>
<p>要明白，通信是通过 socket 来完成的，不懂的同学可以先去看一看 socket 网络编程。</p>
<p>首先，redis 服务端进程初始化的时候，会将 server socket 的 <code>AE_READABLE</code> 事件与连接应答处理器关联。</p>
<p>客户端 socket01 向 redis 进程的 server socket 请求建立连接，此时 server socket 会产生一个 <code>AE_READABLE</code> 事件，IO 多路复用程序监听到 server socket 产生的事件后，将该 socket 压入队列中。文件事件分派器从队列中获取 socket，交给<strong>连接应答处理器</strong>。连接应答处理器会创建一个能与客户端通信的 socket01，并将该 socket01 的 <code>AE_READABLE</code> 事件与命令请求处理器关联。</p>
<p>假设此时客户端发送了一个 <code>set key value</code> 请求，此时 redis 中的 socket01 会产生 <code>AE_READABLE</code> 事件，IO 多路复用程序将 socket01 压入队列，此时事件分派器从队列中获取到 socket01 产生的 <code>AE_READABLE</code> 事件，由于前面 socket01 的 <code>AE_READABLE</code> 事件已经与命令请求处理器关联，因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取 socket01 的 <code>key value</code> 并在自己内存中完成 <code>key value</code> 的设置。操作完成后，它会将 socket01 的 <code>AE_WRITABLE</code> 事件与命令回复处理器关联。</p>
<p>如果此时客户端准备好接收返回结果了，那么 redis 中的 socket01 会产生一个 <code>AE_WRITABLE</code> 事件，同样压入队列中，事件分派器找到相关联的命令回复处理器，由命令回复处理器对 socket01 输入本次操作的一个结果，比如 <code>ok</code>，之后解除 socket01 的 <code>AE_WRITABLE</code> 事件与命令回复处理器的关联。</p>
<p>这样便完成了一次通信。关于 Redis 的一次通信过程，推荐读者阅读《<a href="https://github.com/doocs/technical-books#database" target="_blank" rel="noopener">Redis 设计与实现——黄健宏</a>》进行系统学习。</p>
<h3 id="为啥-redis-单线程模型也能效率这么高？"><a href="#为啥-redis-单线程模型也能效率这么高？" class="headerlink" title="为啥 redis 单线程模型也能效率这么高？"></a>为啥 redis 单线程模型也能效率这么高？</h3><ul>
<li>纯内存操作。</li>
<li>核心是基于非阻塞的 IO 多路复用机制。</li>
<li>C 语言实现，一般来说，C 语言实现的程序“距离”操作系统更近，执行速度相对会更快。</li>
<li>单线程反而避免了多线程的频繁上下文切换问题，预防了多线程可能产生的竞争问题。</li>
</ul>

      
    </div>
    
    
    

    
      <div>
        <div id="wechat_subscriber" style="display: block; padding: 10px 0; margin: 20px auto; width: 100%; text-align: center">
    <img id="wechat_subscriber_qcode" src="/blog4/images/pp.png" alt="MaLingZhao wechat" style="width: 200px; max-width: 100%;">
    <div>扫一扫上面的二维码 加qq群共同学习</div>
</div>

      </div>
    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>坚持原创技术分享，您的支持将鼓励我继续创作！</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/blog4/images/zf.png
" alt="MaLingZhao 微信支付">
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/blog4/images/zfb.png" alt="MaLingZhao 支付宝">
        <p>支付宝</p>
      </div>
    

    
      <div id="bitcoin" style="display: inline-block">
        <img id="bitcoin_qr" src="/images/bitcoin.png" alt="MaLingZhao 比特币">
        <p>比特币</p>
      </div>
    

  </div>
</div>

      </div>
    

    
      <div>
        <ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者：</strong>
    MaLingZhao
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/" title="面试突击">https://malingzhao.github.io/blog4/2019/10/20/javaInterview2/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>
    本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> 许可协议。转载请注明出处！
  </li>
</ul>

      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/blog4/tags/面试/" rel="tag"># 面试</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/blog4/2019/10/19/qianduanshanghceng/" rel="next" title="前端商城项目实战">
                <i class="fa fa-chevron-left"></i> 前端商城项目实战
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/blog4/2019/10/21/vue/" rel="prev" title="vue">
                vue <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
        <!-- JiaThis Button BEGIN -->
<div class="jiathis_style">
<span class="jiathis_txt">分享到：</span>
<a class="jiathis_button_fav">收藏夹</a>
<a class="jiathis_button_copy">复制网址</a>
<a class="jiathis_button_email">邮件</a>
<a class="jiathis_button_weixin">微信</a>
<a class="jiathis_button_qzone">QQ空间</a>
<a class="jiathis_button_tqq">腾讯微博</a>
<a class="jiathis_button_douban">豆瓣</a>
<a class="jiathis_button_share">一键分享</a>

<a href="http://www.jiathis.com/share?uid=2140465" class="jiathis jiathis_txt jiathis_separator jtico jtico_jiathis" target="_blank">更多</a>
<a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript">
var jiathis_config={
  data_track_clickback:true,
  summary:"",
  shortUrl:false,
  hideMore:false
}
</script>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=" charset="utf-8"></script>
<!-- JiaThis Button END -->
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
    </div>
  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      



      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/blog4/images/dongman.png" alt="MaLingZhao">
            
              <p class="site-author-name" itemprop="name">MaLingZhao</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/blog4/archives/">
              
                  <span class="site-state-item-count">44</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/blog4/categories/index.html">
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/blog4/tags/index.html">
                  <span class="site-state-item-count">33</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          




          


            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/malingzhao" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://weibo.com/u/7279469056/home" target="_blank" title="weibo">
                      
                        <i class="fa fa-fw fa-weibo"></i>weibo</a>
                  </span>
                
            </div>

          




          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="http://malingzhao.github.io/blog4" title="Title" target="_blank">Title</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://malingzhao.github.io/blog4" title="我的博客" target="_blank">我的博客</a>
                  </li>
                
              </ul>
            </div>
          



          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#了解自己的技术水平"><span class="nav-number">1.</span> <span class="nav-text">了解自己的技术水平</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#回顾"><span class="nav-number">2.</span> <span class="nav-text">回顾</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#SpringCloud基础"><span class="nav-number">3.</span> <span class="nav-text">SpringCloud基础</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#dubbo的基础架构"><span class="nav-number">4.</span> <span class="nav-text">dubbo的基础架构</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#你对dubbo真的熟悉吗"><span class="nav-number">4.1.</span> <span class="nav-text">你对dubbo真的熟悉吗</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#dubbo-负载均衡策略"><span class="nav-number">4.1.1.</span> <span class="nav-text">dubbo 负载均衡策略</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-random-loadbalance"><span class="nav-number">4.1.1.1.</span> <span class="nav-text">1 random loadbalance</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#leastactive-loadbalance"><span class="nav-number">4.1.1.2.</span> <span class="nav-text">leastactive loadbalance</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#consistanthash-loadbalance"><span class="nav-number">4.1.1.3.</span> <span class="nav-text">consistanthash loadbalance</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#dubbo-集群容错策略"><span class="nav-number">4.1.2.</span> <span class="nav-text">dubbo 集群容错策略</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#failover-cluster-模式"><span class="nav-number">4.1.2.1.</span> <span class="nav-text">failover cluster 模式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#failfast-cluster-模式"><span class="nav-number">4.1.2.2.</span> <span class="nav-text">failfast cluster 模式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#failsafe-cluster-模式"><span class="nav-number">4.1.2.3.</span> <span class="nav-text">failsafe cluster 模式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#broadcacst-cluster"><span class="nav-number">4.1.2.4.</span> <span class="nav-text">broadcacst cluster</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#dubbo动态代理策略"><span class="nav-number">4.1.3.</span> <span class="nav-text">dubbo动态代理策略</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#幂等性"><span class="nav-number">5.</span> <span class="nav-text">幂等性</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Dubbo，Spring-Cloud，服务注册中心，你们当时是怎么选型和调研的，你们最终是选择了哪块技术呢？你选择这块技术的原因和理由是什么呢？"><span class="nav-number">5.0.1.</span> <span class="nav-text">Dubbo，Spring Cloud，服务注册中心，你们当时是怎么选型和调研的，你们最终是选择了哪块技术呢？你选择这块技术的原因和理由是什么呢？</span></a></li></ol></li></ol><li class="nav-item nav-level-1"><a class="nav-link" href="#为什么要进行系统拆分？如何进行系统拆分？拆分后不用-dubbo-可以吗？"><span class="nav-number">6.</span> <span class="nav-text">为什么要进行系统拆分？如何进行系统拆分？拆分后不用 dubbo 可以吗？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#为什么要将系统进行拆分？"><span class="nav-number">7.</span> <span class="nav-text">为什么要将系统进行拆分？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#如何进行系统拆分？"><span class="nav-number">8.</span> <span class="nav-text">如何进行系统拆分？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#拆分后不用-dubbo-可以吗？"><span class="nav-number">9.</span> <span class="nav-text">拆分后不用 dubbo 可以吗？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#zookeeper-都有哪些使用场景？"><span class="nav-number">10.</span> <span class="nav-text">zookeeper 都有哪些使用场景？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#高可用"><span class="nav-number">11.</span> <span class="nav-text">高可用</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#电商网站的商品详情页系统架构"><span class="nav-number">11.1.</span> <span class="nav-text">电商网站的商品详情页系统架构</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#小型电商网站的商品详情页系统架构"><span class="nav-number">11.1.1.</span> <span class="nav-text">小型电商网站的商品详情页系统架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#大型电商网站的商品详情页系统架构"><span class="nav-number">11.1.2.</span> <span class="nav-text">大型电商网站的商品详情页系统架构</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#深入-Hystrix-断路器执行原理"><span class="nav-number">11.2.</span> <span class="nav-text">深入 Hystrix 断路器执行原理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#RequestVolumeThreshold"><span class="nav-number">11.2.1.</span> <span class="nav-text">RequestVolumeThreshold</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ErrorThresholdPercentage"><span class="nav-number">11.2.2.</span> <span class="nav-text">ErrorThresholdPercentage</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SleepWindowInMilliseconds"><span class="nav-number">11.2.3.</span> <span class="nav-text">SleepWindowInMilliseconds</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Enabled"><span class="nav-number">11.2.4.</span> <span class="nav-text">Enabled</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ForceOpen"><span class="nav-number">11.2.5.</span> <span class="nav-text">ForceOpen</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ForceClosed"><span class="nav-number">11.2.6.</span> <span class="nav-text">ForceClosed</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#实例-Demo"><span class="nav-number">11.3.</span> <span class="nav-text">实例 Demo</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#HystrixCommand-配置参数"><span class="nav-number">11.3.1.</span> <span class="nav-text">HystrixCommand 配置参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#断路测试类"><span class="nav-number">11.3.2.</span> <span class="nav-text">断路测试类</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#测试结果"><span class="nav-number">11.3.3.</span> <span class="nav-text">测试结果</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hystrix-隔离策略细粒度控制"><span class="nav-number">11.4.</span> <span class="nav-text">Hystrix 隔离策略细粒度控制</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#execution-isolation-strategy"><span class="nav-number">11.4.1.</span> <span class="nav-text">execution.isolation.strategy</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#command-key-amp-command-group"><span class="nav-number">11.4.2.</span> <span class="nav-text">command key &amp; command group</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#command-thread-pool"><span class="nav-number">11.4.3.</span> <span class="nav-text">command thread pool</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#command-key-amp-command-group-amp-command-thread-pool"><span class="nav-number">11.4.4.</span> <span class="nav-text">command key &amp; command group &amp; command thread pool</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#coreSize"><span class="nav-number">11.4.5.</span> <span class="nav-text">coreSize</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#queueSizeRejectionThreshold"><span class="nav-number">11.4.6.</span> <span class="nav-text">queueSizeRejectionThreshold</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#execution-isolation-semaphore-maxConcurrentRequests"><span class="nav-number">11.4.7.</span> <span class="nav-text">execution.isolation.semaphore.maxConcurrentRequests</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基于本地缓存的-fallback-降级机制"><span class="nav-number">11.5.</span> <span class="nav-text">基于本地缓存的 fallback 降级机制</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#两种最经典的降级机制"><span class="nav-number">11.5.1.</span> <span class="nav-text">两种最经典的降级机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#步骤一：本地缓存获取数据"><span class="nav-number">11.5.2.</span> <span class="nav-text">步骤一：本地缓存获取数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#步骤二：实现-GetBrandNameCommand"><span class="nav-number">11.5.3.</span> <span class="nav-text">步骤二：实现 GetBrandNameCommand</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#步骤三：CacheController-调用接口"><span class="nav-number">11.5.4.</span> <span class="nav-text">步骤三：CacheController 调用接口</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#用-Hystrix-构建高可用服务架构"><span class="nav-number">11.6.</span> <span class="nav-text">用 Hystrix 构建高可用服务架构</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Hystrix-是什么？"><span class="nav-number">11.6.1.</span> <span class="nav-text">Hystrix 是什么？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hystrix-的历史"><span class="nav-number">11.6.2.</span> <span class="nav-text">Hystrix 的历史</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hystrix-的设计原则"><span class="nav-number">11.6.3.</span> <span class="nav-text">Hystrix 的设计原则</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hystrix-更加细节的设计原则"><span class="nav-number">11.6.4.</span> <span class="nav-text">Hystrix 更加细节的设计原则</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#深入-Hystrix-执行时内部原理"><span class="nav-number">11.7.</span> <span class="nav-text">深入 Hystrix 执行时内部原理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#步骤一：创建-command"><span class="nav-number">11.7.1.</span> <span class="nav-text">步骤一：创建 command</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#步骤二：调用-command-执行方法"><span class="nav-number">11.7.2.</span> <span class="nav-text">步骤二：调用 command 执行方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#步骤三：检查是否开启缓存"><span class="nav-number">11.7.3.</span> <span class="nav-text">步骤三：检查是否开启缓存</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#步骤四：检查是否开启了断路器"><span class="nav-number">11.7.4.</span> <span class="nav-text">步骤四：检查是否开启了断路器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#步骤五：检查线程池-队列-信号量是否已满"><span class="nav-number">11.7.5.</span> <span class="nav-text">步骤五：检查线程池/队列/信号量是否已满</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#步骤六：执行-command"><span class="nav-number">11.7.6.</span> <span class="nav-text">步骤六：执行 command</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#步骤七：断路健康检查"><span class="nav-number">11.7.7.</span> <span class="nav-text">步骤七：断路健康检查</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#步骤八：调用-fallback-降级机制"><span class="nav-number">11.7.8.</span> <span class="nav-text">步骤八：调用 fallback 降级机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#不同的执行方式"><span class="nav-number">11.7.9.</span> <span class="nav-text">不同的执行方式</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基于-request-cache-请求缓存技术优化批量商品数据查询接口"><span class="nav-number">11.8.</span> <span class="nav-text">基于 request cache 请求缓存技术优化批量商品数据查询接口</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#实现-Hystrix-请求上下文过滤器并注册"><span class="nav-number">11.8.1.</span> <span class="nav-text">实现 Hystrix 请求上下文过滤器并注册</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#command-重写-getCacheKey-方法"><span class="nav-number">11.8.2.</span> <span class="nav-text">command 重写 getCacheKey() 方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#controller-调用-command-查询商品信息"><span class="nav-number">11.8.3.</span> <span class="nav-text">controller 调用 command 查询商品信息</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#发起请求"><span class="nav-number">11.8.4.</span> <span class="nav-text">发起请求</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#删除缓存"><span class="nav-number">11.8.5.</span> <span class="nav-text">删除缓存</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基于-Hystrix-线程池技术实现资源隔离"><span class="nav-number">11.9.</span> <span class="nav-text">基于 Hystrix 线程池技术实现资源隔离</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#利用-HystrixCommand-获取单条数据"><span class="nav-number">11.9.1.</span> <span class="nav-text">利用 HystrixCommand 获取单条数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#利用-HystrixObservableCommand-批量获取数据"><span class="nav-number">11.9.2.</span> <span class="nav-text">利用 HystrixObservableCommand 批量获取数据</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基于-timeout-机制为服务接口调用超时提供安全保护"><span class="nav-number">11.10.</span> <span class="nav-text">基于 timeout 机制为服务接口调用超时提供安全保护</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#TimeoutMilliseconds"><span class="nav-number">11.10.1.</span> <span class="nav-text">TimeoutMilliseconds</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#TimeoutEnabled"><span class="nav-number">11.10.2.</span> <span class="nav-text">TimeoutEnabled</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#实例-Demo-1"><span class="nav-number">11.11.</span> <span class="nav-text">实例 Demo</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#高并发架构"><span class="nav-number">12.</span> <span class="nav-text">高并发架构</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题"><span class="nav-number">12.1.</span> <span class="nav-text">面试题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试官心理分析"><span class="nav-number">12.2.</span> <span class="nav-text">面试官心理分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题剖析"><span class="nav-number">12.3.</span> <span class="nav-text">面试题剖析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#为什么要分库分表？（设计高并发系统的时候，数据库层面该如何设计？）"><span class="nav-number">12.3.1.</span> <span class="nav-text">为什么要分库分表？（设计高并发系统的时候，数据库层面该如何设计？）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#分表"><span class="nav-number">12.3.1.1.</span> <span class="nav-text">分表</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#分库"><span class="nav-number">12.3.1.2.</span> <span class="nav-text">分库</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？"><span class="nav-number">12.3.2.</span> <span class="nav-text">用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Cobar"><span class="nav-number">12.3.2.1.</span> <span class="nav-text">Cobar</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#TDDL"><span class="nav-number">12.3.2.2.</span> <span class="nav-text">TDDL</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Atlas"><span class="nav-number">12.3.2.3.</span> <span class="nav-text">Atlas</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Sharding-jdbc"><span class="nav-number">12.3.2.4.</span> <span class="nav-text">Sharding-jdbc</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Mycat"><span class="nav-number">12.3.2.5.</span> <span class="nav-text">Mycat</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#总结"><span class="nav-number">12.3.2.6.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#你们具体是如何对数据库如何进行垂直拆分或水平拆分的？"><span class="nav-number">12.3.3.</span> <span class="nav-text">你们具体是如何对数据库如何进行垂直拆分或水平拆分的？</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题-1"><span class="nav-number">12.4.</span> <span class="nav-text">面试题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试官心理分析-1"><span class="nav-number">12.5.</span> <span class="nav-text">面试官心理分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题剖析-1"><span class="nav-number">12.6.</span> <span class="nav-text">面试题剖析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#停机扩容（不推荐）"><span class="nav-number">12.6.1.</span> <span class="nav-text">停机扩容（不推荐）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#优化后的方案"><span class="nav-number">12.6.2.</span> <span class="nav-text">优化后的方案</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题-2"><span class="nav-number">12.7.</span> <span class="nav-text">面试题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试官心理分析-2"><span class="nav-number">12.8.</span> <span class="nav-text">面试官心理分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题剖析-2"><span class="nav-number">12.9.</span> <span class="nav-text">面试题剖析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#基于数据库的实现方案"><span class="nav-number">12.9.1.</span> <span class="nav-text">基于数据库的实现方案</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#数据库自增-id"><span class="nav-number">12.9.1.1.</span> <span class="nav-text">数据库自增 id</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#设置数据库-sequence-或者表自增字段步长"><span class="nav-number">12.9.1.2.</span> <span class="nav-text">设置数据库 sequence 或者表自增字段步长</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#UUID"><span class="nav-number">12.9.2.</span> <span class="nav-text">UUID</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#获取系统当前时间"><span class="nav-number">12.9.3.</span> <span class="nav-text">获取系统当前时间</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#snowflake-算法"><span class="nav-number">12.9.4.</span> <span class="nav-text">snowflake 算法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题-3"><span class="nav-number">12.10.</span> <span class="nav-text">面试题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试官心理分析-3"><span class="nav-number">12.11.</span> <span class="nav-text">面试官心理分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题剖析-3"><span class="nav-number">12.12.</span> <span class="nav-text">面试题剖析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#停机迁移方案"><span class="nav-number">12.12.1.</span> <span class="nav-text">停机迁移方案</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#双写迁移方案"><span class="nav-number">12.12.2.</span> <span class="nav-text">双写迁移方案</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#lucene-和-es-的前世今生"><span class="nav-number">12.13.</span> <span class="nav-text">lucene 和 es 的前世今生</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#es-的核心概念"><span class="nav-number">12.14.</span> <span class="nav-text">es 的核心概念</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Near-Realtime"><span class="nav-number">12.14.1.</span> <span class="nav-text">Near Realtime</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Cluster-集群"><span class="nav-number">12.14.2.</span> <span class="nav-text">Cluster 集群</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Node-节点"><span class="nav-number">12.14.3.</span> <span class="nav-text">Node 节点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Document-amp-field"><span class="nav-number">12.14.4.</span> <span class="nav-text">Document &amp; field</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Index"><span class="nav-number">12.14.5.</span> <span class="nav-text">Index</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Type"><span class="nav-number">12.14.6.</span> <span class="nav-text">Type</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#shard"><span class="nav-number">12.14.7.</span> <span class="nav-text">shard</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#replica"><span class="nav-number">12.14.8.</span> <span class="nav-text">replica</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#es-核心概念-vs-db-核心概念"><span class="nav-number">12.15.</span> <span class="nav-text">es 核心概念 vs. db 核心概念</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题-4"><span class="nav-number">12.16.</span> <span class="nav-text">面试题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试官心理分析-4"><span class="nav-number">12.17.</span> <span class="nav-text">面试官心理分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题剖析-4"><span class="nav-number">12.18.</span> <span class="nav-text">面试题剖析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题-5"><span class="nav-number">12.19.</span> <span class="nav-text">面试题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试官心理分析-5"><span class="nav-number">12.20.</span> <span class="nav-text">面试官心理分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题剖析-5"><span class="nav-number">12.21.</span> <span class="nav-text">面试题剖析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#性能优化的杀手锏——filesystem-cache"><span class="nav-number">12.21.1.</span> <span class="nav-text">性能优化的杀手锏——filesystem cache</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#数据预热"><span class="nav-number">12.21.2.</span> <span class="nav-text">数据预热</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#冷热分离"><span class="nav-number">12.21.3.</span> <span class="nav-text">冷热分离</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#document-模型设计"><span class="nav-number">12.21.4.</span> <span class="nav-text">document 模型设计</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分页性能优化"><span class="nav-number">12.21.5.</span> <span class="nav-text">分页性能优化</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#不允许深度分页（默认深度分页性能很差）"><span class="nav-number">12.21.5.1.</span> <span class="nav-text">不允许深度分页（默认深度分页性能很差）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#类似于-app-里的推荐商品不断下拉出来一页一页的"><span class="nav-number">12.21.5.2.</span> <span class="nav-text">类似于 app 里的推荐商品不断下拉出来一页一页的</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题-6"><span class="nav-number">12.22.</span> <span class="nav-text">面试题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试官心理分析-6"><span class="nav-number">12.23.</span> <span class="nav-text">面试官心理分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题剖析-6"><span class="nav-number">12.24.</span> <span class="nav-text">面试题剖析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题-7"><span class="nav-number">12.25.</span> <span class="nav-text">面试题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试官心理分析-7"><span class="nav-number">12.26.</span> <span class="nav-text">面试官心理分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题剖析-7"><span class="nav-number">12.27.</span> <span class="nav-text">面试题剖析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#es-写数据过程"><span class="nav-number">12.27.1.</span> <span class="nav-text">es 写数据过程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#es-读数据过程"><span class="nav-number">12.27.2.</span> <span class="nav-text">es 读数据过程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#es-搜索数据过程"><span class="nav-number">12.27.3.</span> <span class="nav-text">es 搜索数据过程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#写数据底层原理"><span class="nav-number">12.27.4.</span> <span class="nav-text">写数据底层原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#删除-更新数据底层原理"><span class="nav-number">12.27.5.</span> <span class="nav-text">删除/更新数据底层原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#底层-lucene"><span class="nav-number">12.27.6.</span> <span class="nav-text">底层 lucene</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#倒排索引"><span class="nav-number">12.27.7.</span> <span class="nav-text">倒排索引</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题-8"><span class="nav-number">12.28.</span> <span class="nav-text">面试题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试官心理分析-8"><span class="nav-number">12.29.</span> <span class="nav-text">面试官心理分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题剖析-8"><span class="nav-number">12.30.</span> <span class="nav-text">面试题剖析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#为什么使用消息队列"><span class="nav-number">12.30.1.</span> <span class="nav-text">为什么使用消息队列</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#解耦"><span class="nav-number">12.30.1.1.</span> <span class="nav-text">解耦</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#异步"><span class="nav-number">12.30.1.2.</span> <span class="nav-text">异步</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#削峰"><span class="nav-number">12.30.1.3.</span> <span class="nav-text">削峰</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#消息队列有什么优缺点"><span class="nav-number">12.30.2.</span> <span class="nav-text">消息队列有什么优缺点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka、ActiveMQ、RabbitMQ、RocketMQ-有什么优缺点？"><span class="nav-number">12.30.3.</span> <span class="nav-text">Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点？</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题-9"><span class="nav-number">12.31.</span> <span class="nav-text">面试题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试官心理分析-9"><span class="nav-number">12.32.</span> <span class="nav-text">面试官心理分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题剖析-9"><span class="nav-number">12.33.</span> <span class="nav-text">面试题剖析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#系统拆分"><span class="nav-number">12.33.1.</span> <span class="nav-text">系统拆分</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#缓存"><span class="nav-number">12.33.2.</span> <span class="nav-text">缓存</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MQ"><span class="nav-number">12.33.3.</span> <span class="nav-text">MQ</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分库分表"><span class="nav-number">12.33.4.</span> <span class="nav-text">分库分表</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#读写分离"><span class="nav-number">12.33.5.</span> <span class="nav-text">读写分离</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ElasticSearch"><span class="nav-number">12.33.6.</span> <span class="nav-text">ElasticSearch</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题-10"><span class="nav-number">12.34.</span> <span class="nav-text">面试题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试官心理分析-10"><span class="nav-number">12.35.</span> <span class="nav-text">面试官心理分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题剖析-10"><span class="nav-number">12.36.</span> <span class="nav-text">面试题剖析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#RabbitMQ-的高可用性"><span class="nav-number">12.36.1.</span> <span class="nav-text">RabbitMQ 的高可用性</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#单机模式"><span class="nav-number">12.36.1.1.</span> <span class="nav-text">单机模式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#普通集群模式（无高可用性）"><span class="nav-number">12.36.1.2.</span> <span class="nav-text">普通集群模式（无高可用性）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#镜像集群模式（高可用性）"><span class="nav-number">12.36.1.3.</span> <span class="nav-text">镜像集群模式（高可用性）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-的高可用性"><span class="nav-number">12.36.2.</span> <span class="nav-text">Kafka 的高可用性</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题-11"><span class="nav-number">12.37.</span> <span class="nav-text">面试题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试官心理分析-11"><span class="nav-number">12.38.</span> <span class="nav-text">面试官心理分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题剖析-11"><span class="nav-number">12.39.</span> <span class="nav-text">面试题剖析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题-12"><span class="nav-number">12.40.</span> <span class="nav-text">面试题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试官心理分析-12"><span class="nav-number">12.41.</span> <span class="nav-text">面试官心理分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题剖析-12"><span class="nav-number">12.42.</span> <span class="nav-text">面试题剖析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题-13"><span class="nav-number">12.43.</span> <span class="nav-text">面试题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试官心理分析-13"><span class="nav-number">12.44.</span> <span class="nav-text">面试官心理分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题剖析-13"><span class="nav-number">12.45.</span> <span class="nav-text">面试题剖析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#解决方案"><span class="nav-number">12.45.1.</span> <span class="nav-text">解决方案</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#RabbitMQ"><span class="nav-number">12.45.1.1.</span> <span class="nav-text">RabbitMQ</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Kafka"><span class="nav-number">12.45.1.2.</span> <span class="nav-text">Kafka</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试官心理分析-14"><span class="nav-number">12.46.</span> <span class="nav-text">面试官心理分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题剖析-14"><span class="nav-number">12.47.</span> <span class="nav-text">面试题剖析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#解决方案-1"><span class="nav-number">12.47.1.</span> <span class="nav-text">解决方案</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#RabbitMQ-1"><span class="nav-number">12.47.1.1.</span> <span class="nav-text">RabbitMQ</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Kafka-1"><span class="nav-number">12.47.1.2.</span> <span class="nav-text">Kafka</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题-14"><span class="nav-number">12.48.</span> <span class="nav-text">面试题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试官心理分析-15"><span class="nav-number">12.49.</span> <span class="nav-text">面试官心理分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题剖析-15"><span class="nav-number">12.50.</span> <span class="nav-text">面试题剖析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题-15"><span class="nav-number">12.51.</span> <span class="nav-text">面试题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试官心理分析-16"><span class="nav-number">12.52.</span> <span class="nav-text">面试官心理分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题剖析-16"><span class="nav-number">12.53.</span> <span class="nav-text">面试题剖析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#大量消息在-mq-里积压了几个小时了还没解决"><span class="nav-number">12.53.1.</span> <span class="nav-text">大量消息在 mq 里积压了几个小时了还没解决</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#mq-中的消息过期失效了"><span class="nav-number">12.53.2.</span> <span class="nav-text">mq 中的消息过期失效了</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#mq-都快写满了"><span class="nav-number">12.53.3.</span> <span class="nav-text">mq 都快写满了</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题-16"><span class="nav-number">12.54.</span> <span class="nav-text">面试题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试官心理分析-17"><span class="nav-number">12.55.</span> <span class="nav-text">面试官心理分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题剖析-17"><span class="nav-number">12.56.</span> <span class="nav-text">面试题剖析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#如何实现-MySQL-的读写分离？"><span class="nav-number">12.56.1.</span> <span class="nav-text">如何实现 MySQL 的读写分离？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MySQL-主从复制原理的是啥？"><span class="nav-number">12.56.2.</span> <span class="nav-text">MySQL 主从复制原理的是啥？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MySQL-主从同步延时问题（精华）"><span class="nav-number">12.56.3.</span> <span class="nav-text">MySQL 主从同步延时问题（精华）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题-17"><span class="nav-number">12.57.</span> <span class="nav-text">面试题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试官心理分析-18"><span class="nav-number">12.58.</span> <span class="nav-text">面试官心理分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题剖析-18"><span class="nav-number">12.59.</span> <span class="nav-text">面试题剖析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#缓存雪崩"><span class="nav-number">12.59.1.</span> <span class="nav-text">缓存雪崩</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#缓存穿透"><span class="nav-number">12.59.2.</span> <span class="nav-text">缓存穿透</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#缓存击穿"><span class="nav-number">12.59.3.</span> <span class="nav-text">缓存击穿</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题-18"><span class="nav-number">12.60.</span> <span class="nav-text">面试题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试官心理分析-19"><span class="nav-number">12.61.</span> <span class="nav-text">面试官心理分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题剖析-19"><span class="nav-number">12.62.</span> <span class="nav-text">面试题剖析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题-19"><span class="nav-number">12.63.</span> <span class="nav-text">面试题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试官心理分析-20"><span class="nav-number">12.64.</span> <span class="nav-text">面试官心理分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题剖析-20"><span class="nav-number">12.65.</span> <span class="nav-text">面试题剖析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#redis-cluster-介绍"><span class="nav-number">12.65.1.</span> <span class="nav-text">redis cluster 介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#节点间的内部通信机制"><span class="nav-number">12.65.2.</span> <span class="nav-text">节点间的内部通信机制</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#基本通信原理"><span class="nav-number">12.65.2.1.</span> <span class="nav-text">基本通信原理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#gossip-协议"><span class="nav-number">12.65.2.2.</span> <span class="nav-text">gossip 协议</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ping-消息深入"><span class="nav-number">12.65.2.3.</span> <span class="nav-text">ping 消息深入</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分布式寻址算法"><span class="nav-number">12.65.3.</span> <span class="nav-text">分布式寻址算法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#hash-算法"><span class="nav-number">12.65.3.1.</span> <span class="nav-text">hash 算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#一致性-hash-算法"><span class="nav-number">12.65.3.2.</span> <span class="nav-text">一致性 hash 算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#redis-cluster-的-hash-slot-算法"><span class="nav-number">12.65.3.3.</span> <span class="nav-text">redis cluster 的 hash slot 算法</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#redis-cluster-的高可用与主备切换原理"><span class="nav-number">12.65.4.</span> <span class="nav-text">redis cluster 的高可用与主备切换原理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#判断节点宕机"><span class="nav-number">12.65.4.1.</span> <span class="nav-text">判断节点宕机</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#从节点过滤"><span class="nav-number">12.65.4.2.</span> <span class="nav-text">从节点过滤</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#从节点选举"><span class="nav-number">12.65.4.3.</span> <span class="nav-text">从节点选举</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#与哨兵比较"><span class="nav-number">12.65.4.4.</span> <span class="nav-text">与哨兵比较</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题-20"><span class="nav-number">12.66.</span> <span class="nav-text">面试题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试官心理分析-21"><span class="nav-number">12.67.</span> <span class="nav-text">面试官心理分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题剖析-21"><span class="nav-number">12.68.</span> <span class="nav-text">面试题剖析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Cache-Aside-Pattern"><span class="nav-number">12.68.1.</span> <span class="nav-text">Cache Aside Pattern</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#最初级的缓存不一致问题及解决方案"><span class="nav-number">12.68.2.</span> <span class="nav-text">最初级的缓存不一致问题及解决方案</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#比较复杂的数据不一致问题分析"><span class="nav-number">12.68.3.</span> <span class="nav-text">比较复杂的数据不一致问题分析</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题-21"><span class="nav-number">12.69.</span> <span class="nav-text">面试题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试官心理分析-22"><span class="nav-number">12.70.</span> <span class="nav-text">面试官心理分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题剖析-22"><span class="nav-number">12.71.</span> <span class="nav-text">面试题剖析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#项目中缓存是如何使用的？"><span class="nav-number">12.71.1.</span> <span class="nav-text">项目中缓存是如何使用的？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#为什么要用缓存？"><span class="nav-number">12.71.2.</span> <span class="nav-text">为什么要用缓存？</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#高性能"><span class="nav-number">12.71.2.1.</span> <span class="nav-text">高性能</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#高并发"><span class="nav-number">12.71.2.2.</span> <span class="nav-text">高并发</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#用了缓存之后会有什么不良后果？"><span class="nav-number">12.71.3.</span> <span class="nav-text">用了缓存之后会有什么不良后果？</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题-22"><span class="nav-number">12.72.</span> <span class="nav-text">面试题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试官心理分析-23"><span class="nav-number">12.73.</span> <span class="nav-text">面试官心理分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题剖析-23"><span class="nav-number">12.74.</span> <span class="nav-text">面试题剖析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#string"><span class="nav-number">12.74.1.</span> <span class="nav-text">string</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hash"><span class="nav-number">12.74.2.</span> <span class="nav-text">hash</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#list"><span class="nav-number">12.74.3.</span> <span class="nav-text">list</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#set"><span class="nav-number">12.74.4.</span> <span class="nav-text">set</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sorted-set"><span class="nav-number">12.74.5.</span> <span class="nav-text">sorted set</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题-23"><span class="nav-number">12.75.</span> <span class="nav-text">面试题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试官心理分析-24"><span class="nav-number">12.76.</span> <span class="nav-text">面试官心理分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题剖析-24"><span class="nav-number">12.77.</span> <span class="nav-text">面试题剖析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#redis-过期策略"><span class="nav-number">12.77.1.</span> <span class="nav-text">redis 过期策略</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#内存淘汰机制"><span class="nav-number">12.77.2.</span> <span class="nav-text">内存淘汰机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#手写一个-LRU-算法"><span class="nav-number">12.77.3.</span> <span class="nav-text">手写一个 LRU 算法</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Redis-主从架构"><span class="nav-number">13.</span> <span class="nav-text">Redis 主从架构</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#redis-replication-的核心机制"><span class="nav-number">13.1.</span> <span class="nav-text">redis replication 的核心机制</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#redis-主从复制的核心原理"><span class="nav-number">13.2.</span> <span class="nav-text">redis 主从复制的核心原理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#主从复制的断点续传"><span class="nav-number">13.2.1.</span> <span class="nav-text">主从复制的断点续传</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#无磁盘化复制"><span class="nav-number">13.2.2.</span> <span class="nav-text">无磁盘化复制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#过期-key-处理"><span class="nav-number">13.2.3.</span> <span class="nav-text">过期 key 处理</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#复制的完整流程"><span class="nav-number">13.3.</span> <span class="nav-text">复制的完整流程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#全量复制"><span class="nav-number">13.3.1.</span> <span class="nav-text">全量复制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#增量复制"><span class="nav-number">13.3.2.</span> <span class="nav-text">增量复制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#heartbeat"><span class="nav-number">13.3.3.</span> <span class="nav-text">heartbeat</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#异步复制"><span class="nav-number">13.3.4.</span> <span class="nav-text">异步复制</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#redis-如何才能做到高可用"><span class="nav-number">13.4.</span> <span class="nav-text">redis 如何才能做到高可用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题-24"><span class="nav-number">13.5.</span> <span class="nav-text">面试题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试官心理分析-25"><span class="nav-number">13.6.</span> <span class="nav-text">面试官心理分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题剖析-25"><span class="nav-number">13.7.</span> <span class="nav-text">面试题剖析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#redis-持久化的两种方式"><span class="nav-number">13.7.1.</span> <span class="nav-text">redis 持久化的两种方式</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#RDB-优缺点"><span class="nav-number">13.7.1.1.</span> <span class="nav-text">RDB 优缺点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#AOF-优缺点"><span class="nav-number">13.7.1.2.</span> <span class="nav-text">AOF 优缺点</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RDB-和-AOF-到底该如何选择"><span class="nav-number">13.7.2.</span> <span class="nav-text">RDB 和 AOF 到底该如何选择</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题-25"><span class="nav-number">13.8.</span> <span class="nav-text">面试题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试官心理分析-26"><span class="nav-number">13.9.</span> <span class="nav-text">面试官心理分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题剖析-26"><span class="nav-number">13.10.</span> <span class="nav-text">面试题剖析</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Redis-哨兵集群实现高可用"><span class="nav-number">14.</span> <span class="nav-text">Redis 哨兵集群实现高可用</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#哨兵的介绍"><span class="nav-number">14.1.</span> <span class="nav-text">哨兵的介绍</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#哨兵的核心知识"><span class="nav-number">14.2.</span> <span class="nav-text">哨兵的核心知识</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#redis-哨兵主备切换的数据丢失问题"><span class="nav-number">14.3.</span> <span class="nav-text">redis 哨兵主备切换的数据丢失问题</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#两种情况和导致数据丢失"><span class="nav-number">14.3.1.</span> <span class="nav-text">两种情况和导致数据丢失</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#数据丢失问题的解决方案"><span class="nav-number">14.3.2.</span> <span class="nav-text">数据丢失问题的解决方案</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#sdown-和-odown-转换机制"><span class="nav-number">14.4.</span> <span class="nav-text">sdown 和 odown 转换机制</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#哨兵集群的自动发现机制"><span class="nav-number">14.5.</span> <span class="nav-text">哨兵集群的自动发现机制</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#slave-配置的自动纠正"><span class="nav-number">14.6.</span> <span class="nav-text">slave 配置的自动纠正</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#slave-gt-master-选举算法"><span class="nav-number">14.7.</span> <span class="nav-text">slave-&gt;master 选举算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#quorum-和-majority"><span class="nav-number">14.8.</span> <span class="nav-text">quorum 和 majority</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#configuration-epoch"><span class="nav-number">14.9.</span> <span class="nav-text">configuration epoch</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#configuration-传播"><span class="nav-number">14.10.</span> <span class="nav-text">configuration 传播</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题-26"><span class="nav-number">14.11.</span> <span class="nav-text">面试题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试官心理分析-27"><span class="nav-number">14.12.</span> <span class="nav-text">面试官心理分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#面试题剖析-27"><span class="nav-number">14.13.</span> <span class="nav-text">面试题剖析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#redis-和-memcached-有啥区别？"><span class="nav-number">14.13.1.</span> <span class="nav-text">redis 和 memcached 有啥区别？</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#redis-支持复杂的数据结构"><span class="nav-number">14.13.1.1.</span> <span class="nav-text">redis 支持复杂的数据结构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#redis-原生支持集群模式"><span class="nav-number">14.13.1.2.</span> <span class="nav-text">redis 原生支持集群模式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#性能对比"><span class="nav-number">14.13.1.3.</span> <span class="nav-text">性能对比</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#redis-的线程模型"><span class="nav-number">14.13.2.</span> <span class="nav-text">redis 的线程模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#为啥-redis-单线程模型也能效率这么高？"><span class="nav-number">14.13.3.</span> <span class="nav-text">为啥 redis 单线程模型也能效率这么高？</span></a></li></ol></li></ol></li></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2018 &mdash; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">MaLingZhao</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">205.7k</span>
  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  









  
  
    <script type="text/javascript" src="/blog4/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/blog4/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/blog4/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/blog4/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/blog4/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/blog4/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/blog4/lib/three/three.min.js"></script>
  

  
  
    <script type="text/javascript" src="/blog4/lib/three/three-waves.min.js"></script>
  


  


  <script type="text/javascript" src="/blog4/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/blog4/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/blog4/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/blog4/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/blog4/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/blog4/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/blog4/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  










  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: false,
        appId: '8TOqOwTzIDHvfpCddf1zIWum-gzGzoHsz',
        appKey: 'EQrtySSrAvcKm4R7okLaXIIP',
        placeholder: 'Just go go',
        avatar:'mm',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/blog4/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

</body>
</html>
